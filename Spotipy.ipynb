{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "import time\n",
    "import ast\n",
    "import random\n",
    "\n",
    "# Spotipy\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56660, 13): df_uk_masters\n",
      "(48690, 13): df_us_masters\n",
      "(37597, 13): df_us_new_masters\n",
      "(51222, 5): df_ratings_20\n",
      "(79625, 5): df_ratings_10\n",
      "(11429, 13): df_masters_blended\n"
     ]
    }
   ],
   "source": [
    "# import the dataframes\n",
    "df_uk_masters = pd.read_csv('Datasets/df_uk_masters.csv')                         # all the albums from the UK\n",
    "df_us_masters = pd.read_csv('Datasets/df_us_masters.csv')                         # albums from the US until 1996, 1998 and 2000\n",
    "df_us_new_masters = pd.read_csv('Datasets/df_us_new_masters.csv')                         # albums from the US from 1997, 1999 and 2001\n",
    "df_ratings_20 = pd.read_csv('Datasets/df_ratings_20.csv', keep_default_na=False)  # albums with >= 20 votes, mostly from rock, worldwide\n",
    "df_ratings_10 = pd.read_csv('Datasets/df_ratings_10.csv', keep_default_na=False)  # albums with >= 10 votes, mostly from rock, worldwide\n",
    "df_masters_blended = pd.read_csv('Datasets/df_masters_blended.csv')               # albums from the UK and US (until 2000) with >= 20 votes \n",
    "\n",
    "# print information\n",
    "print(f'{df_uk_masters.shape}: df_uk_masters')\n",
    "print(f'{df_us_masters.shape}: df_us_masters')\n",
    "print(f'{df_us_new_masters.shape}: df_us_new_masters')\n",
    "print(f'{df_ratings_20.shape}: df_ratings_20')\n",
    "print(f'{df_ratings_10.shape}: df_ratings_10')\n",
    "print(f'{df_masters_blended.shape}: df_masters_blended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **``album_length``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 640,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9667, 13)"
      ]
     },
     "execution_count": 640,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended = pd.read_csv('Datasets/df_masters_blended.csv')               # albums from the UK and US (until 2000) with >= 20 votes \n",
    "df = df_masters_blended\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 641,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "albums missing album_length: 2234 \n",
      "% missing album_length: 23.11%\n"
     ]
    }
   ],
   "source": [
    "percentage_album_length_missing = round((df['album_length']==0).sum() / df.shape[0] * 100, 2)\n",
    "\n",
    "print(f\"albums missing album_length: {(df['album_length']==0).sum()} \")\n",
    "print(f'% missing album_length: {percentage_album_length_missing}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2234, 13)"
      ]
     },
     "execution_count": 657,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_length_0 = df[df['album_length']==0].sort_values(['artist', 'year', 'title'])\n",
    "df_length_0.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **``Spotipy`` (Spotify API)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 643,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 643,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 933,
   "metadata": {},
   "outputs": [],
   "source": [
    "user = os.getenv('client_id')\n",
    "password = os.getenv('client_secret')\n",
    "\n",
    "# Initialize Spotipy with user credentials\n",
    "sp = spotipy.Spotify(auth_manager=SpotifyClientCredentials(client_id = user,\n",
    "                                                           client_secret = password), requests_timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 836,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 ...And You Will Know Us by the Trail of Dead Madonna\n",
      "2 108 Songs of Separation\n",
      "3 10cc 10cc\n",
      "4 10cc Sheet Music\n",
      "5 10cc Deceptive Bends\n",
      "6 23 Skidoo Seven Songs\n",
      "7 2:54 2:54\n",
      "8 7 Seconds The Crew\n",
      "9 7 Seconds New Wind\n",
      "10 A Certain Ratio The Graveyard and The Ballroom\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for artist, title in df_length_0[['artist', 'title']][:10].values:\n",
    "    count+=1\n",
    "\n",
    "    print(count, artist, title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist found: Agent Orange\n"
     ]
    }
   ],
   "source": [
    "artist = 'Agent Orange'\n",
    "\n",
    "results = sp.search(q = artist\n",
    "                    , type = 'artist'\n",
    "                    , limit = 5)\n",
    "\n",
    "# theorically the artist should be the first result\n",
    "artist_name = results['artists']['items'][0]['name']\n",
    "artist_id = results['artists']['items'][0]['id'] # get the artist_id\n",
    "\n",
    "if artist_name.lower() == artist.lower():\n",
    "    print(f'artist found: {artist_name}')\n",
    "else:\n",
    "    print(f\"Cannot find '{artist}', try some other one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1025,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_albums(artist_id):\n",
    "    albums = []\n",
    "    results = sp.artist_albums(artist_id, limit=50)  # First request\n",
    "\n",
    "    while results:\n",
    "        albums.extend(results['items'])  # Store the albums\n",
    "        if results['next']:  # Check if there's another page\n",
    "            results = sp.next(results)  # Fetch next page\n",
    "        else:\n",
    "            break  # Stop when no more pages\n",
    "\n",
    "    return albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "artist found\n",
      "Adam and the Ants\n",
      "Kings of the Wild Frontier (Deluxe Edition)\n",
      "Dirk Wears White Sox (Remastered)\n",
      "Prince Charming (Remastered)\n",
      "B-Side Babies\n",
      "Young Parisians / Lady\n",
      "Young Parisians\n",
      "Lady\n",
      "80s 100 Hits\n",
      "The Best Of The 80's\n",
      "80s 100 Hits - Volume 2\n",
      "80s: 100 Remixes\n",
      "On Your 80's Radio\n",
      "Pure... Alternative 80s\n",
      "The Definitive 80's (eighties)\n",
      "Ultimate 80's Number 1's\n",
      "Pure... 80's Dance Party\n",
      "Essential - One For The Lads\n",
      "The Very Best Of\n",
      "The Supreme Record Company\n",
      "Hits of the 80s\n",
      "Heroic Hits\n",
      "Rock Classics\n",
      "Haynes Ultimate Guide to 80s\n",
      "Party On!\n",
      "The Essential 80s Rock\n",
      "Dig'Hits All 80'S\n",
      "The Best Year Of My Life: 1981G010004775674D\n",
      "Go Boys Go\n",
      "Ultimate No 2 Hits Of The 80's\n",
      "The Best Year Of My Life: 1980\n",
      "Haynes Ultimate Guide to Classic Anthems\n"
     ]
    }
   ],
   "source": [
    "artist = 'Adam and the Ants'\n",
    "title = 'Dirk Wears White Sox'\n",
    "# other albums by the same artist:\n",
    "# Kings of the Wild Frontier\n",
    "# Prince Charming\n",
    "\n",
    "results = sp.search(q = artist\n",
    "                    , type = 'artist'\n",
    "                    , limit = 5)\n",
    "\n",
    "artists = results['artists']['items']\n",
    "artists_ids = results['artists']['items'] # get the artist_id\n",
    "\n",
    "for i in range(len(artists)):\n",
    "    # artist = artists[i]['name']\n",
    "    try:\n",
    "        # look for my artist\n",
    "        if artist.lower().replace('and', '&') == artists[i]['name'].lower():\n",
    "            # if it finds my artist:\n",
    "            artist_id = artists_ids[i]['id']\n",
    "            print('artist found')\n",
    "            print(artist)\n",
    "\n",
    "            artist_albums = get_all_albums(artist_id)\n",
    "\n",
    "            for album in artist_albums:\n",
    "\n",
    "                print(album['name'])\n",
    "\n",
    "                # look for my album\n",
    "                if album['name'].lower().replace('and', '&') == (title.lower().replace('and', '&')):\n",
    "                    print('album found')\n",
    "                    album_id = album['id']\n",
    "                    results = sp.album(album_id)\n",
    "                    tracks = results['tracks']['items']\n",
    "                    song_durations = [song['duration_ms']/60000 for song in tracks]\n",
    "                    \n",
    "                    album_length = round(sum(song_durations), 2)\n",
    "\n",
    "                    break   # once it finds the album, stop\n",
    "    except:\n",
    "        print('error')            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that the album is found, though not on the exact same name, it doesn't do an exact match because there are other parts in the title, such as **'Deluxe Edition'** or **'Remastered'**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31"
      ]
     },
     "execution_count": 1078,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(artist_albums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Kings of the Wild Frontier (Deluxe Edition)'"
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_albums[0]['name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 952,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2jK54ZlZhTF1TxygsVeR05'"
      ]
     },
     "execution_count": 952,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist_id"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **define the function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 973,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album_length(df):\n",
    "    count = 0\n",
    "    scrapped = 0\n",
    "\n",
    "    # create empty lists\n",
    "    artists_list = []\n",
    "    albums_list = []\n",
    "    albums_lengths = []\n",
    "    tracks_list = []\n",
    "\n",
    "    for artist, title in df[['artist', 'title']].values:\n",
    "        time.sleep(2)\n",
    "        count+=1\n",
    "\n",
    "        artists_list.append(artist)\n",
    "        albums_list.append(title)\n",
    "\n",
    "        results = sp.search(q = artist\n",
    "                            , type = 'artist'\n",
    "                            , limit = 5)\n",
    "\n",
    "        artists = results['artists']['items']\n",
    "        artists_ids = results['artists']['items'] # get the artist_id\n",
    "\n",
    "        for i in range(len(artists)):\n",
    "            try:\n",
    "                # look for my artist\n",
    "                if artist == artists[i]['name']:\n",
    "                    # if it finds my artist:\n",
    "                    artist_id = artists_ids[i]['id']\n",
    "\n",
    "                    # get the albums of the artist\n",
    "                    results = sp.artist_albums(artist_id, limit=50)\n",
    "                    data = results['items']\n",
    "\n",
    "                    # examine all the albums\n",
    "                    for j in range(len(data)):\n",
    "                        album = data[j]['name']\n",
    "                        album_id = data[j]['id']\n",
    "\n",
    "                    # for album in artist_albums:\n",
    "                    for j in range(len(data)):\n",
    "                        album = data[j]['name']\n",
    "                        album_id = data[j]['id']\n",
    "\n",
    "                        # look for my album\n",
    "                        if album.lower() == title.lower():\n",
    "                            results = sp.album(album_id)\n",
    "                            tracks = results['tracks']['items']\n",
    "                            tracks_list.append(len(tracks))\n",
    "                            song_durations = [song['duration_ms']/60000 for song in tracks]\n",
    "                            \n",
    "                            album_length = round(sum(song_durations), 2)\n",
    "                            albums_lengths.append(album_length)\n",
    "                            scrapped+=1\n",
    "                            break   # once it finds the album, stop\n",
    "                    else:\n",
    "                        continue\n",
    "                    break   \n",
    "            except:\n",
    "                print('error')\n",
    "                break\n",
    "        \n",
    "        else:\n",
    "            albums_lengths.append(np.nan)\n",
    "            tracks_list.append(np.nan)\n",
    "\n",
    "        print(f\"{scrapped}/{count}: {artist} - {title}\")\n",
    "\n",
    "        lists = [artists_list, albums_list, albums_lengths, tracks_list]\n",
    "        # for lst in lists:\n",
    "        #     print(len(lst))\n",
    "\n",
    "    # Check if all lists have the same length\n",
    "        lengths = [len(lst) for lst in lists]\n",
    "        if len(set(lengths)) != 1:\n",
    "            print(\"Lengths are not the same.\")\n",
    "            break # stop the loop, I won't be able to store the data if I have one value missing\n",
    "\n",
    "    df_lengths_missing = pd.DataFrame({'artist': artists_list,\n",
    "                                    'title': albums_list,\n",
    "                                    'album_length': albums_lengths,\n",
    "                                    'tracks': tracks_list})\n",
    "    return df_lengths_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 960,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_albums(artist_id):\n",
    "    albums = []\n",
    "    results = sp.artist_albums(artist_id, limit=50)  # First request\n",
    "\n",
    "    while results:\n",
    "        albums.extend(results['items'])  # Store the albums\n",
    "        if results['next']:  # Check if there's another page\n",
    "            results = sp.next(results)  # Fetch next page\n",
    "        else:\n",
    "            break  # Stop when no more pages\n",
    "\n",
    "    return albums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1090,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "album = 'Dirk Wears White Sox'\n",
    "\n",
    "title = 'Dirk Wears White Sox (Remastered)'\n",
    "\n",
    "album in title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_album_length(df):\n",
    "    count = 0\n",
    "    scraped = 0\n",
    "\n",
    "    # create empty lists\n",
    "    artists_list = []\n",
    "    albums_list = []\n",
    "    albums_lengths = []\n",
    "    tracks_list = []\n",
    "\n",
    "    for artist, title in df[['artist', 'title']].values:\n",
    "        time.sleep(1)\n",
    "        count+=1\n",
    "\n",
    "        artists_list.append(artist)\n",
    "        albums_list.append(title)\n",
    "\n",
    "        results = sp.search(q = artist\n",
    "                            , type = 'artist'\n",
    "                            , limit = 5)\n",
    "\n",
    "        artists = results['artists']['items']\n",
    "        artists_ids = results['artists']['items'] # get the artist_id\n",
    "\n",
    "        for i in range(len(artists)):\n",
    "            artist_name = artists[i]['name'].lower()\n",
    "            artist_name_and = artist.replace('and', '&').lower()\n",
    "            try:\n",
    "                # look for my artist\n",
    "                if artist_name == artist.lower() or artist_name == artist_name_and:\n",
    "                    # if it finds my artist:\n",
    "                    artist_id = artists_ids[i]['id']\n",
    "\n",
    "                    artist_albums = get_all_albums(artist_id)\n",
    "\n",
    "                    for album in artist_albums:\n",
    "                        album_name = album['name'].lower()        \n",
    "                        title_name_and = title.replace('and', '&').lower()\n",
    "                        if title.lower() in album_name or title_name_and in album_name:\n",
    "                            album_id = album['id']\n",
    "                            results = sp.album(album_id)\n",
    "                            tracks = results['tracks']['items']\n",
    "                            tracks_list.append(len(tracks))\n",
    "                            song_durations = [song['duration_ms']/60000 for song in tracks]\n",
    "                            \n",
    "                            album_length = round(sum(song_durations), 2)\n",
    "                            albums_lengths.append(album_length)\n",
    "                            scraped+=1\n",
    "                            break   # once it finds the album, stop\n",
    "                    else:\n",
    "                        continue\n",
    "                    break \n",
    "            except:\n",
    "                print('error')\n",
    "                albums_lengths.append(np.nan)\n",
    "                tracks_list.append(np.nan)\n",
    "                break\n",
    "        \n",
    "        else:\n",
    "            albums_lengths.append(np.nan)\n",
    "            tracks_list.append(np.nan)\n",
    "\n",
    "        print(f\"{scraped}/{count}: {artist} - {title}\")\n",
    "\n",
    "        lists = [artists_list, albums_list, albums_lengths, tracks_list]\n",
    "\n",
    "    # Check if all lists have the same length\n",
    "        lengths = [len(lst) for lst in lists]\n",
    "        if len(set(lengths)) != 1:\n",
    "            print(\"Lengths are not the same.\")\n",
    "            break # stop the loop, I won't be able to store the data if I have one value missing\n",
    "\n",
    "    df_lengths_missing = pd.DataFrame({'artist': artists_list,\n",
    "                                    'title': albums_list,\n",
    "                                    'album_length': albums_lengths,\n",
    "                                    'tracks': tracks_list})\n",
    "    return df_lengths_missing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Get the ``album_length`` from Spotipy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1: At the Skylines - The Secrets To Life\n",
      "1/2: Atomic Rooster - Atomic Roooster\n",
      "2/3: Atomic Rooster - Death Walks Behind You\n",
      "3/4: Atomic Rooster - Nice 'N' Greasy\n",
      "4/5: Atoms for Peace - Amok\n",
      "5/6: Atreyu - In Our Wake\n",
      "6/7: Atreyu - The Beautiful Dark of Life\n",
      "7/8: Atrophy - Socialized Hate\n",
      "8/9: Atvm - Famine, Putrid and Fucking Endless\n",
      "9/10: Au Pairs - Playing With A Different Sex\n",
      "9/11: Aus-Rotten - ...And Now Back To Our Programming\n",
      "10/12: Autopsy - Severed Survival\n",
      "11/13: Autopsy - Skull Grinder\n",
      "12/14: Autopsy - Puncturing the Grotesque\n",
      "13/15: Avail - Dixie\n",
      "14/16: Avail - 4am Friday\n",
      "15/17: Avail - Over the James\n",
      "16/18: Azure Ray - Hold On Love\n",
      "17/19: Bachelor - Doomin' Sun\n",
      "18/20: Bad Brains - Bad Brains\n",
      "19/21: Bad Brains - Quickness\n",
      "20/22: Bad Brains - Black Dots\n",
      "21/23: Bad Omens - Finding God Before God Finds Me\n",
      "22/24: Bad Omens - The Death of Peace of Mind\n",
      "23/25: Bad Religion - How Could Hell Be Any Worse?\n",
      "24/26: Bad Religion - Recipe for Hate\n",
      "25/27: Badfinger - No Dice\n",
      "25/28: Badly Drawn Boy - Have You Fed The Fish?\n",
      "26/29: Balance and Composure - Light We Made\n",
      "27/30: Balkans - Balkans\n",
      "28/31: Bambara - Shadow on Everything\n",
      "29/32: Band of Horses - Mirage Rock\n",
      "30/33: Band of Susans - Love Agenda\n",
      "31/34: Barclay James Harvest - Once Again\n",
      "32/35: Barclay James Harvest - Everyone Is Everybody Else\n",
      "33/36: Bark Psychosis - Codename: Dustsucker\n",
      "34/37: Baroness - Yellow and Green\n",
      "35/38: Baroness - Gold and Grey\n",
      "36/39: Baroness - Stone\n",
      "37/40: Basement - I Wish I Could Stay Here\n",
      "38/41: Bastille - Wild World\n",
      "38/42: Bastro - Diablo Guapo\n",
      "39/43: Bauhaus - Mask\n",
      "40/44: Beach Fossils - Clash the Truth\n",
      "41/45: Beach Fossils - Somersault\n",
      "42/46: Beach House - Depression Cherry\n",
      "43/47: Beach House - 7\n",
      "44/48: Beach Slang - A Loud Bash of Teenage Feelings\n",
      "45/49: Bear's Den - Red Earth and Pouring Rain\n",
      "46/50: Beastie Boys - Check Your Head\n",
      "47/51: Beat Happening - Beat Happening\n",
      "48/52: Beat Happening - Jamboree\n",
      "49/53: Beat Happening - Black Candy\n",
      "50/54: Beat Happening - Dreamy\n",
      "50/55: Beck - Golden Feelings\n",
      "51/56: Beck - One Foot In The Grave\n",
      "52/57: Beirut - No No No\n",
      "53/58: Belle and Sebastian - Fold Your Hands Child, You Walk Like A Peasant\n",
      "54/59: Belle and Sebastian - Storytelling\n",
      "55/60: Belle and Sebastian - Late Developers\n",
      "56/61: Belmont - Aftermath\n",
      "57/62: Ben Folds - Rockin' The Suburbs\n",
      "58/63: Ben Howard - Is It?\n",
      "59/64: Ben Kweller - Sha Sha\n",
      "60/65: Ben Kweller - Ben Kweller\n",
      "61/66: Benediction - Killing Music\n",
      "62/67: Benjamin Booker - Benjamin Booker\n",
      "62/68: Berlin - Pleasure Victim\n",
      "63/69: Beth Gibbons - Lives Outgrown\n",
      "64/70: Beth Orton - Trailer Park\n",
      "65/71: Beth Orton - Weather Alive\n",
      "66/72: Bibio - Ambivalence Avenue\n",
      "67/73: Bibio - Ribbons\n",
      "68/74: Big Black - Atomizer\n",
      "69/75: Big Black - Songs About Fucking\n",
      "69/76: Big Black - Pigpile\n",
      "70/77: Big Business - Command Your Weather\n",
      "71/78: Big Thief - Masterpiece\n",
      "72/79: Big Thief - Two Hands\n",
      "73/80: Big Ups - Eighteen Hours of Static\n",
      "74/81: Big Ups - Before a Million Universes\n",
      "74/82: Bill Fay - Time of the Last Persecution\n",
      "74/83: Billy Bragg - Brewing Up With Billy Bragg\n",
      "75/84: Biomechanical - Cannibalised\n",
      "76/85: Birdy - Fire Within\n",
      "77/86: Bitch Magnet - Umber\n",
      "78/87: Black Breath - Heavy Breathing\n",
      "79/88: Black Country, New Road - For the first time\n",
      "80/89: Black Dice - Broken Ear Record\n",
      "81/90: Black Foxxes - reiÃ°i\n",
      "82/91: Black Foxxes - Black Foxxes\n",
      "83/92: Black Marble - Fast Idol\n",
      "84/93: Black Midi - Schlagenheim\n",
      "85/94: Black Midi - Hellfire\n",
      "86/95: Black Moth - Condemned To Hope\n",
      "87/96: Black Peaks - All That Divides\n",
      "88/97: Black Sabbath - Paranoid\n",
      "89/98: Black Sabbath - Master Of Reality\n",
      "90/99: Black Sabbath - Sabbath Bloody Sabbath\n",
      "91/100: Black Sabbath - Technical Ecstasy\n",
      "92/101: Black Sabbath - Never Say Die!\n",
      "93/102: Black Sabbath - Mob Rules\n",
      "94/103: Black Sabbath - Seventh Star\n",
      "95/104: Black Sabbath - The Eternal Idol\n",
      "96/105: Black Stone Cherry - The Human Condition\n",
      "97/106: Black Widow - Sacrifice\n",
      "98/107: Blackhole - Dead Hearts\n",
      "99/108: Blakfish - Champions\n",
      "100/109: Blakroc - Blakroc\n",
      "101/110: Blanket - Modern Escapism\n",
      "102/111: Blanket - Ceremonia\n",
      "103/112: Blaze Bayley - War Within Me\n",
      "104/113: Bleachers - Bleachers\n",
      "105/114: Bleed from Within - Era\n",
      "106/115: Blind Faith - Blind Faith\n",
      "107/116: Blind Idiot God - Blind Idiot God\n",
      "108/117: Blitz - Voice Of A Generation\n",
      "108/118: Blitzkrieg - A Time Of Changes\n",
      "109/119: Bloc Party - Hymns\n",
      "110/120: Bloc Party - Alpha Games\n",
      "111/121: Blondie - Panic of Girls\n",
      "112/122: Blondshell - Blondshell\n",
      "113/123: Blood, Sweat and Tears - Blood, Sweat and Tears\n",
      "114/124: Bloodhound Gang - One Fierce Beer Coaster\n",
      "114/125: Blue Cheer - What Doesn't Kill You...\n",
      "115/126: Blur - Parklife\n",
      "116/127: Blur - The Great Escape\n",
      "117/128: Blur - Blur\n",
      "118/129: Blur - 13\n",
      "119/130: Blur - Parklive\n",
      "120/131: Bo Diddley - Bo Diddley\n",
      "121/132: Bob Dylan - Blonde on Blonde\n",
      "122/133: Bob Dylan - Nashville Skyline\n",
      "123/134: Bodysnatcher - Bleed-Abide\n",
      "124/135: Bolt Thrower - War Master\n",
      "124/136: Bolt Thrower - ...For Victory\n",
      "125/137: Bomb the Music Industry! - Get Warmer\n",
      "126/138: Bomb the Music Industry! - Vacation\n",
      "127/139: Bombay Bicycle Club - I Had The Blues But I Shook Them Loose\n",
      "128/140: Bombay Bicycle Club - Everything Else Has Gone Wrong\n",
      "129/141: Bon Jovi - What About Now\n",
      "130/142: Bong - Mana-Yood-Sushai\n",
      "131/143: Bong - Stoner Rock\n",
      "131/144: Born Against - Nine Patriotic Hymns For Children\n",
      "132/145: Bosnian Rainbows - Bosnian Rainbows\n",
      "133/146: Boss Keloid - Melted on the Inch\n",
      "134/147: Boston Manor - Welcome to the Neighbourhood\n",
      "135/148: Bowling for Soup - Bowling for Soup\n",
      "136/149: Bowling for Soup - The Great Burrito Extortion Case\n",
      "137/150: Bowling for Soup - Lunch. Drunk. Love.\n",
      "138/151: Boys Life - Boys Life\n",
      "139/152: Boys Life - Departures and Landfalls\n",
      "140/153: Braid - The Age of Octeen\n",
      "141/154: Braid - No Coast\n",
      "142/155: Brainiac - Bonsai Superstar\n",
      "143/156: Brand X - Product\n",
      "144/157: Bright Eyes - Letting Off the Happiness\n",
      "145/158: Bright Eyes - Cassadaga\n",
      "146/159: Bright Eyes - Five Dice, All Threes\n",
      "146/160: British Theatre - Mastery\n",
      "147/161: Broken Hearts Are Blue - The Truth About Love\n",
      "148/162: Brutality Will Prevail - Root of All Evil\n",
      "149/163: Brutality Will Prevail - Suspension of Consciousness\n",
      "150/164: Buckcherry - Time Bomb\n",
      "151/165: Buddy Holly - Buddy Holly\n",
      "152/166: Budgie - Squawk\n",
      "152/167: Budgie - Never Turn Your Back on a Friend\n",
      "152/168: Budgie - In for the Kill!\n",
      "152/169: Budgie - Bandolier\n",
      "152/170: Budgie - Power Supply\n",
      "152/171: Budgie - Nightflight\n",
      "152/172: Budgie - You're All Living in Cuckooland\n",
      "153/173: Built to Spill - When The Wind Forgets Your Name\n",
      "154/174: Bully - Losing\n",
      "155/175: Bully - Sugaregg\n",
      "156/176: Bully - Lucky For You\n",
      "156/177: Butthole Surfers - Psychic... Powerless... Another Man's Sac\n",
      "157/178: Butthole Surfers - Rembrandt Pussyhorse\n",
      "158/179: CKY - Carver City\n",
      "159/180: Calabrese - The Traveling Vampire Show\n",
      "159/181: California X - Nights In The Dark\n",
      "160/182: Calligram - The Eye Is the First Circle\n",
      "161/183: Camel - Camel\n",
      "162/184: Camel - The Snow Goose\n",
      "163/185: Camel - Moonmadness\n",
      "164/186: Camel - A Live Record\n",
      "165/187: Camel - Breathless\n",
      "166/188: Camel - I Can See Your House From Here\n",
      "167/189: Camel - Nude\n",
      "168/190: Cancer - To the Gory End\n",
      "169/191: Cannibal Corpse - Gore Obsessed\n",
      "170/192: Cannibal Corpse - Violence Unimagined\n",
      "171/193: Car Bomb - Mordial\n",
      "172/194: Car Seat Headrest - Teens of Denial\n",
      "173/195: Car Seat Headrest - Making a Door Less Open\n",
      "174/196: Caravan - If I Could Do It All Over Again, I'd Do It All Over You\n",
      "175/197: Caravan - Waterloo Lily\n",
      "176/198: Caravan - Cunning Stunts\n",
      "177/199: Cardiacs - A Little Man and a House and the Whole World Window\n",
      "178/200: Cardiacs - On Land and in the Sea\n",
      "179/201: Cardiacs - The Seaside\n",
      "179/202: Carmen - Fandangos in Space\n",
      "180/203: Caroline - Caroline\n",
      "181/204: Caskets - Lost Souls\n",
      "182/205: Caskets - Reflections\n",
      "183/206: Cass McCombs - Catacombs\n",
      "184/207: Cassus - Separation Anxiety\n",
      "185/208: Cat Power - What Would the Community Think\n",
      "186/209: Cat Power - Wanderer\n",
      "186/210: Cat Stevens - Teaser and the Firecat\n",
      "186/211: Cat Stevens - Catch Bull at Four\n",
      "186/212: Catapilla - Changes\n",
      "187/213: Cate Le Bon - Reward\n",
      "188/214: Celestial Sanctuary - Insatiable Thirst For Torment\n",
      "189/215: Cerebral Ballzy - Cerebral Ballzy\n",
      "190/216: Ceremony - The L-Shaped Man\n",
      "191/217: Charli XCX - Sucker\n",
      "192/218: Chat Pile - Cool World\n",
      "193/219: Chavez - Gone Glimmering\n",
      "193/220: Cheap Trick - Cheap Trick At Budokan\n",
      "194/221: Chelsea Light Moving - Chelsea Light Moving\n",
      "195/222: Chelsea Wolfe - The Grime And The Glow\n",
      "196/223: Chelsea Wolfe - Unknown Rooms: A Collection of Acoustic Songs\n",
      "197/224: Chelsea Wolfe - Hiss Spun\n",
      "198/225: Chelsea Wolfe - Birth of Violence\n",
      "199/226: Chicago - Chicago X\n",
      "200/227: Chicago - Chicago XI\n",
      "201/228: Christian Death - Only Theatre of Pain\n",
      "202/229: Christian Death - Catastrophe Ballet\n",
      "203/230: Chrome - Red Exposure\n",
      "204/231: Chuck Berry - After School Session\n",
      "204/232: Chuck Berry - One Dozen Berrys\n",
      "205/233: Chuck Berry - Chuck\n",
      "206/234: Chumbawamba - Never Mind The Ballots\n",
      "207/235: Chumbawamba - Anarchy\n",
      "208/236: Chumbawamba - WYSIWYG\n",
      "209/237: Cigarettes After Sex - Cry\n",
      "210/238: Cigarettes After Sex - X's\n",
      "211/239: Circa Waves - Young Chasers\n",
      "212/240: Circa Waves - Different Creatures\n",
      "213/241: Circus Lupus - Super Genius\n",
      "214/242: Clikatat Ikatowi - Orchestrated and Conducted By\n",
      "215/243: Cloakroom - Further Out\n",
      "216/244: Cloud Nothings - Turning On\n",
      "217/245: Cloud Nothings - Cloud Nothings\n",
      "218/246: Cloud Nothings - Final Summer\n",
      "218/247: Clouds - Doliu\n",
      "219/248: Clutch - Psychic Warfare\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Your application has reached a rate/request limit. Retry will occur after: 65581\n"
     ]
    }
   ],
   "source": [
    "start_index = 100\n",
    "end_index = start_index + 100\n",
    "\n",
    "df_lengths_missing = get_album_length(df_length_0.iloc[start_index:end_index])\n",
    "df_lengths_missing.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 919,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.47"
      ]
     },
     "execution_count": 919,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minutes = 12.25\n",
    "attempts = 500\n",
    "\n",
    "seconds_per_attempt = minutes*60/attempts\n",
    "seconds_per_attempt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df_lengths_missing' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df_lengths_missing\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df_lengths_missing' is not defined"
     ]
    }
   ],
   "source": [
    "df_lengths_missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_lengths_missing.to_csv('Datasets/df_lengths_missing_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I don't want to get rid of these albums, because they have been released so dropping them would be deleting information, but they affect the average of ``album_length``, so I will just convert them to null values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace it with a nan\n",
    "df_masters_concat.loc[28, 'album_length'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>year</th>\n",
       "      <th>country</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>master_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Hyper On Experience</td>\n",
       "      <td>Keep It In The Family E.P.</td>\n",
       "      <td>1993</td>\n",
       "      <td>UK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>['Electronic']</td>\n",
       "      <td>['Breakbeat', 'Hardcore']</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Mixrace</td>\n",
       "      <td>The Future Is Before Your Eyes</td>\n",
       "      <td>1992</td>\n",
       "      <td>UK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>['Electronic']</td>\n",
       "      <td>['Hardcore', 'Breakbeat']</td>\n",
       "      <td>121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Mixrace</td>\n",
       "      <td>Organized Chaos E.P.</td>\n",
       "      <td>1993</td>\n",
       "      <td>UK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6</td>\n",
       "      <td>['Electronic']</td>\n",
       "      <td>['Breakbeat', 'Hardcore', 'Jungle']</td>\n",
       "      <td>122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Mixrace</td>\n",
       "      <td>The Endless Skies / True Jungle</td>\n",
       "      <td>1994</td>\n",
       "      <td>UK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>['Electronic']</td>\n",
       "      <td>['Drum n Bass', 'Jungle']</td>\n",
       "      <td>123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Earth Leakage Trip</td>\n",
       "      <td>Neopolitan EP</td>\n",
       "      <td>1992</td>\n",
       "      <td>UK</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>['Electronic']</td>\n",
       "      <td>['Breakbeat', 'Hardcore', 'Techno', 'Bleep']</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist                            album  year country  \\\n",
       "6   Hyper On Experience       Keep It In The Family E.P.  1993      UK   \n",
       "8               Mixrace   The Future Is Before Your Eyes  1992      UK   \n",
       "9               Mixrace             Organized Chaos E.P.  1993      UK   \n",
       "10              Mixrace  The Endless Skies / True Jungle  1994      UK   \n",
       "13   Earth Leakage Trip                    Neopolitan EP  1992      UK   \n",
       "\n",
       "    album_length  tracks          genres  \\\n",
       "6            0.0       4  ['Electronic']   \n",
       "8            0.0       6  ['Electronic']   \n",
       "9            0.0       6  ['Electronic']   \n",
       "10           0.0       4  ['Electronic']   \n",
       "13           0.0       3  ['Electronic']   \n",
       "\n",
       "                                          styles  master_id  \n",
       "6                      ['Breakbeat', 'Hardcore']        119  \n",
       "8                      ['Hardcore', 'Breakbeat']        121  \n",
       "9            ['Breakbeat', 'Hardcore', 'Jungle']        122  \n",
       "10                     ['Drum n Bass', 'Jungle']        123  \n",
       "13  ['Breakbeat', 'Hardcore', 'Techno', 'Bleep']        126  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_masters_concat[df_masters_concat['album_length']==0].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Exporting to csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_masters_concat.to_csv('Datasets/df_masters.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
