{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import time\n",
    "import re\n",
    "\n",
    "# pip install geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from geopy_functions import *\n",
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56660, 13): df_uk_masters\n",
      "(48690, 13): df_us_masters\n",
      "(74652, 13): df_us_new_masters\n",
      "(6708, 13): df_us_new_masters_clean\n",
      "(51222, 5): df_ratings_20\n",
      "(9667, 13): df_masters_blended\n"
     ]
    }
   ],
   "source": [
    "# import the dataframes\n",
    "df_uk_masters = pd.read_csv('Datasets/df_uk_masters.csv')                         # all the albums from the UK\n",
    "df_us_masters = pd.read_csv('Datasets/df_us_masters.csv')                         # albums from the US until 1996, 1998 and 2000\n",
    "df_us_new_masters = pd.read_csv('Datasets/df_us_new_masters.csv')                         # albums from the US from 1997, 1999 and 2001\n",
    "df_us_new_masters_clean = pd.read_csv('Datasets/df_us_new_masters_clean.csv')             # albums from the US from 1997, 1999 and 2001, cleaned, merged with df_ratings_20\n",
    "df_ratings_20 = pd.read_csv('Datasets/df_ratings_20.csv', keep_default_na=False)  # albums with >= 20 votes, mostly from rock, worldwide\n",
    "df_masters_blended = pd.read_csv('Datasets/df_masters_blended.csv')               # albums from the UK and US (and others) with >= 20 votes until 2000 aprox\n",
    "df_artists_origins_coordinates = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')               # merge of df_masters_blended with their locations\n",
    "\n",
    "# print information\n",
    "print(f'{df_uk_masters.shape}: df_uk_masters')\n",
    "print(f'{df_us_masters.shape}: df_us_masters')\n",
    "print(f'{df_us_new_masters.shape}: df_us_new_masters')\n",
    "print(f'{df_us_new_masters_clean.shape}: df_us_new_masters_clean')\n",
    "print(f'{df_ratings_20.shape}: df_ratings_20')\n",
    "print(f'{df_masters_blended.shape}: df_masters_blended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15152368</td>\n",
       "      <td>3747909</td>\n",
       "      <td>31909420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Living Arrows</td>\n",
       "      <td>Hope and Ruin</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Post-Hardcore']</td>\n",
       "      <td>Post-screamo band from Brighton, UK\\r\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id  master_id  main_release_id release_country            artist  \\\n",
       "0   15152368    3747909         31909420             NaN  As Living Arrows   \n",
       "\n",
       "           title  year  album_length  tracks     release_type    genres  \\\n",
       "0  Hope and Ruin  2024           0.0       8  ['LP', 'Album']  ['Rock']   \n",
       "\n",
       "              styles                            artist_profile  \n",
       "0  ['Post-Hardcore']  Post-screamo band from Brighton, UK\\r\\n   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1441645</td>\n",
       "      <td>396963</td>\n",
       "      <td>3314361</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Devin Townsend Project</td>\n",
       "      <td>Contain Us</td>\n",
       "      <td>2011</td>\n",
       "      <td>1177.03</td>\n",
       "      <td>219</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Electronic', 'Rock', 'Pop']</td>\n",
       "      <td>['Alternative Rock', 'Industrial', 'Prog Rock'...</td>\n",
       "      <td>Rock/metal project of [a251249]. It was founde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id  master_id  main_release_id release_country  \\\n",
       "0    1441645     396963          3314361          Europe   \n",
       "\n",
       "                   artist       title  year  album_length  tracks  \\\n",
       "0  Devin Townsend Project  Contain Us  2011       1177.03     219   \n",
       "\n",
       "  release_type                         genres  \\\n",
       "0    ['Album']  ['Electronic', 'Rock', 'Pop']   \n",
       "\n",
       "                                              styles  \\\n",
       "0  ['Alternative Rock', 'Industrial', 'Prog Rock'...   \n",
       "\n",
       "                                      artist_profile  \n",
       "0  Rock/metal project of [a251249]. It was founde...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_new_masters_clean.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations Wikipedia scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Datasets/df_rock_ratings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets/df_rock_ratings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, keep_default_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m artists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m albums\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Datasets/df_rock_ratings.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/df_rock_ratings.csv', keep_default_na=False)\n",
    "\n",
    "print(f\"{df['artist'].nunique()} artists\")\n",
    "print(f\"{df.shape[0]} albums\")\n",
    "print(f\"Average of {round(df.shape[0] / df['artist'].nunique(), 2)} albums per artist in the subset with the (mostly UK) albums with more than 10 votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3823 artists\n",
      "9380 albums\n",
      "Average of 2.45 albums per artist in the subset with the (mostly UK) albums with more than 20 votes\n"
     ]
    }
   ],
   "source": [
    "df_20 = pd.read_csv('Datasets/df_rock_ratings_20.csv', keep_default_na=False)\n",
    "\n",
    "print(f\"{df_20['artist'].nunique()} artists\")\n",
    "print(f\"{df_20.shape[0]} albums\")\n",
    "print(f\"Average of {round(df_20.shape[0] / df_20['artist'].nunique(), 2)} albums per artist in the subset with the (mostly UK) albums with more than 20 votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51252, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ratings_20 = pd.read_csv('Datasets/df_ratings_20.csv')\n",
    "df_ratings_20.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10580</th>\n",
       "      <td>The 1975</td>\n",
       "      <td>A Brief Inquiry into Online Relationships</td>\n",
       "      <td>2018</td>\n",
       "      <td>58.43</td>\n",
       "      <td>15</td>\n",
       "      <td>['Rock', 'Pop']</td>\n",
       "      <td>['Indie Rock', 'Alternative Rock', 'Indie Pop']</td>\n",
       "      <td>UK &amp; Europe</td>\n",
       "      <td>British indie rock band. \\r\\n\\r\\nPop-rock band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>Le Butcherettes</td>\n",
       "      <td>A Raw Youth</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>Formed by Teri Gender Bender and Auryn Jolene ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>John Fogerty</td>\n",
       "      <td>Centerfield</td>\n",
       "      <td>1985</td>\n",
       "      <td>35.33</td>\n",
       "      <td>9</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Pop Rock', 'Folk Rock', 'Country Rock']</td>\n",
       "      <td>US</td>\n",
       "      <td>American musician, songwriter, and guitarist (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>L7</td>\n",
       "      <td>The Beauty Process: Triple Platinum</td>\n",
       "      <td>1997</td>\n",
       "      <td>41.57</td>\n",
       "      <td>12</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Punk', 'Grunge']</td>\n",
       "      <td>US</td>\n",
       "      <td>American grunge punk/alternative rock band fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>The Fall</td>\n",
       "      <td>Are You Are Missing Winner</td>\n",
       "      <td>2001</td>\n",
       "      <td>47.68</td>\n",
       "      <td>10</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Garage Rock', 'Punk', 'Rockabilly']</td>\n",
       "      <td>UK</td>\n",
       "      <td>Post-punk band from Greater Manchester, UK. 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist                                      title  year  \\\n",
       "10580         The 1975  A Brief Inquiry into Online Relationships  2018   \n",
       "9889   Le Butcherettes                                A Raw Youth  2015   \n",
       "6394      John Fogerty                                Centerfield  1985   \n",
       "4498                L7        The Beauty Process: Triple Platinum  1997   \n",
       "5742          The Fall                 Are You Are Missing Winner  2001   \n",
       "\n",
       "       album_length  tracks           genres  \\\n",
       "10580         58.43      15  ['Rock', 'Pop']   \n",
       "9889           0.00      12         ['Rock']   \n",
       "6394          35.33       9         ['Rock']   \n",
       "4498          41.57      12         ['Rock']   \n",
       "5742          47.68      10         ['Rock']   \n",
       "\n",
       "                                                styles release_country  \\\n",
       "10580  ['Indie Rock', 'Alternative Rock', 'Indie Pop']     UK & Europe   \n",
       "9889                                                []              US   \n",
       "6394         ['Pop Rock', 'Folk Rock', 'Country Rock']              US   \n",
       "4498                                ['Punk', 'Grunge']              US   \n",
       "5742             ['Garage Rock', 'Punk', 'Rockabilly']              UK   \n",
       "\n",
       "                                          artist_profile  \n",
       "10580  British indie rock band. \\r\\n\\r\\nPop-rock band...  \n",
       "9889   Formed by Teri Gender Bender and Auryn Jolene ...  \n",
       "6394   American musician, songwriter, and guitarist (...  \n",
       "4498   American grunge punk/alternative rock band fro...  \n",
       "5742   Post-punk band from Greater Manchester, UK. 19...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9616"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = df['artist'].unique()\n",
    "len(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Life at These Speeds'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[4155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aabsinthe'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist = \"AABSINTHE\"\n",
    "name_changed = artist.title().replace(' ', '_')\n",
    "name_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres\n"
     ]
    }
   ],
   "source": [
    "artist = \"John Grant\"\n",
    "name_changed = artist.replace(' ', '_')\n",
    "name_changed_band = artist.replace(' ', '_') + ('_(band)')\n",
    "name_changed_musician = name_changed + ('_(musician)')\n",
    "\n",
    "url = f\"https://en.wikipedia.org/wiki/{name_changed_musician}\"\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "try:\n",
    "    text = table[0].text\n",
    "\n",
    "    # Step 1: Extract the part after 'Born'\n",
    "    after_born = text.split(\"Born\", 1)[1]\n",
    "\n",
    "    text_age = re.search(\"aged\", after_born)\n",
    "\n",
    "    if text_age:\n",
    "        # This means the musician is dead\n",
    "        location = re.split(r'(19\\d{2})', after_born)[4].split('Died')[0].strip()\n",
    "    else:\n",
    "        try:\n",
    "            text = re.split(r'(19\\d{2})', after_born)[4].split(')')[1]\n",
    "\n",
    "            if \"Other\\xa0names\" in text:\n",
    "                location = text.split('Other\\xa0names')[0]\n",
    "            else:\n",
    "                if \"Citizenship\" in text:\n",
    "                    location = text.split('Citizenship')[0]\n",
    "                else:\n",
    "                    if \"Genres\" in text:\n",
    "                        location = text.split('Genres')[0]\n",
    "                        print('Genres')\n",
    "                    else:\n",
    "                        if \"Occupations\" in text:\n",
    "                            location = text.split('Occupations')[0]\n",
    "                            print('Occupations')\n",
    "                        else:\n",
    "                            location = np.nan\n",
    "        except:  \n",
    "            location = np.nan\n",
    "except:\n",
    "    print('fuck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buchanan, Michigan, U.S.'"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John_Grant_(musician)'"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_changed_musician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = \"Stone Gossard\"\n",
    "name_changed = artist.replace(' ', '_')\n",
    "name_changed_band = artist.replace(' ', '_') + ('_(band)')\n",
    "\n",
    "url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "try:\n",
    "    location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "\n",
    "# save info in lists\n",
    "    print('origin')\n",
    "\n",
    "except:\n",
    "    text = table[0].text\n",
    "\n",
    "    # Step 1: Extract the part after 'Born'\n",
    "    after_born = text.split(\"Born\", 1)[1]\n",
    "\n",
    "    text_age = re.search(\"aged\", after_born)\n",
    "\n",
    "    if text_age:\n",
    "        # This means the artist is dead\n",
    "        print('dead')\n",
    "        location = re.split(r'(19\\d{2})', after_born)[4].split('Died')[0].strip()\n",
    "    else:\n",
    "        try:\n",
    "            text = re.split(r'(19\\d{2})', after_born)[4].split(')')[1]\n",
    "\n",
    "            if \"Other\\xa0names\" in text:\n",
    "                location = text.split('Other\\xa0names')[0]\n",
    "            else:\n",
    "                if \"Citizenship\" in text:\n",
    "                    location = text.split('Citizenship')[0]\n",
    "                else:\n",
    "                    if \"Occupations\" in text:\n",
    "                        location = text.split('Occupations')[0]\n",
    "                    else:\n",
    "                        if \"Genres\" in text:\n",
    "                            location = text.split('Genres')[0]\n",
    "                            print(repr(location))\n",
    "                        else:\n",
    "                            location = np.nan\n",
    "        except:  \n",
    "            location = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seattle, Washington, U.S.GenresAlternative rockgrungeglam punkpunk rockhard rockheavy metalglam metalOccupationsMusiciansongwriterInstrumentsGuitarvocalsYears active'"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seattle, Washington, U.S.GenresAlternative rockgrungeglam punkpunk rockhard rockheavy metalglam metal'"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>Less Than Jake</td>\n",
       "      <td>Losing Streak</td>\n",
       "      <td>3.90</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Sparta</td>\n",
       "      <td>Wiretap Scars</td>\n",
       "      <td>3.79</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Muse</td>\n",
       "      <td>Absolution</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>Muse</td>\n",
       "      <td>Showbiz</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>Finch</td>\n",
       "      <td>What It Is to Burn</td>\n",
       "      <td>3.69</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   album_id          artist               album  rating  votes\n",
       "0        37  Less Than Jake       Losing Streak    3.90    414\n",
       "1        40          Sparta       Wiretap Scars    3.79    431\n",
       "2        41            Muse          Absolution    3.99   4411\n",
       "3        42            Muse             Showbiz    3.50   2181\n",
       "4        45           Finch  What It Is to Burn    3.69    864"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_artists_origins``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3251, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "df_artists_origins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sparta</td>\n",
       "      <td>El Paso, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muse</td>\n",
       "      <td>Teignmouth, Devon, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finch</td>\n",
       "      <td>Temecula, California, Estados Unidos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transplants</td>\n",
       "      <td>Los Angeles, California, United States[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rooney</td>\n",
       "      <td>Los Angeles, California, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist                                     origin\n",
       "0       Sparta                             El Paso, Texas\n",
       "1         Muse                 Teignmouth, Devon, England\n",
       "2        Finch       Temecula, California, Estados Unidos\n",
       "3  Transplants  Los Angeles, California, United States[1]\n",
       "4       Rooney              Los Angeles, California, U.S."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins[df_artists_origins['origin']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists = df_artists_origins[df_artists_origins['origin']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>Son of Dork</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Mojave 3</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>Crippled Black Phoenix</td>\n",
       "      <td>Bristol, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>This Mortal Coil</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>Jade Warrior</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>The Waterboys</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>Blackmore's Night</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>Atomic Rooster</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>The Nefilim</td>\n",
       "      <td>Lambeth, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>Black Spiders</td>\n",
       "      <td>Sheffield, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>Brontide</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>Gilgamesh</td>\n",
       "      <td>Hampstead, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>Young Legionnaire</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>The Deviants</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>Head of David</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>Quintessence</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      artist                                 origin\n",
       "1059             Son of Dork                        London, England\n",
       "1192                Mojave 3                        London, England\n",
       "1326  Crippled Black Phoenix                       Bristol, England\n",
       "1597        This Mortal Coil                    Wandsworth, England\n",
       "2191                 Arcadia                        London, England\n",
       "2300            Jade Warrior                        London, England\n",
       "2348           The Waterboys                        London, England\n",
       "2469       Blackmore's Night         Mount Sinai, NY, United States\n",
       "2556          Atomic Rooster                        London, England\n",
       "2609             The Nefilim                       Lambeth, England\n",
       "2715           Black Spiders                     Sheffield, England\n",
       "2822                Brontide                        London, England\n",
       "2878               Gilgamesh                     Hampstead, England\n",
       "2914       Young Legionnaire                        London, England\n",
       "2924            The Deviants        Ladbroke Grove, London, England\n",
       "2956           Head of David  Dudley, West Midlands, United Kingdom\n",
       "3157            Quintessence                        London, England"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Son of Dork\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Mojave 3\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Crippled Black Phoenix\", \"Bristol, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"This Mortal Coil\", \"Wandsworth, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Arcadia\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Jade Warrior\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Waterboys\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Blackmore's Night\", \"Mount Sinai, NY, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Atomic Rooster\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Nefilim\", \"Lambeth, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Black Spiders\", \"Sheffield, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Brontide\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Gilgamesh\", \"Hampstead, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Young Legionnaire\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Deviants\", \"Ladbroke Grove, London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Head of David\", \"Dudley, West Midlands, United Kingdom\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Quintessence\", \"London, England\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formed in 1969, they played a blend of jazz, progressive rock, Indian Music, and new age rock.   Members included:\n",
      "Sambhu Babaji : Bass  Dave Codling : Guitar  Shiva Shankar Jones : Keyboards, Vocals  Jake Milton : Drums  Alan Mostert\n",
      ": Guitar  Raja Ram : Flute, Piano, Vocals\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[8016]['artist_profile']\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>styles</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>1969</td>\n",
       "      <td>Quintessence</td>\n",
       "      <td>In Blissful Company</td>\n",
       "      <td>3.88</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['Psychedelic Rock']</td>\n",
       "      <td>UK</td>\n",
       "      <td>Formed in 1969, they played a blend of jazz, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year        artist                title  rating  votes  album_length  \\\n",
       "8016  1969  Quintessence  In Blissful Company    3.88     16           0.0   \n",
       "\n",
       "      tracks                styles release_country  \\\n",
       "8016       8  ['Psychedelic Rock']              UK   \n",
       "\n",
       "                                         artist_profile  \n",
       "8016  Formed in 1969, they played a blend of jazz, p...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Quintessence\".strip()].sort_values('votes', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3234, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = df_artists_origins[df_artists_origins['origin']!='United Kingdom']\n",
    "df_artists_origins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists_origins.to_csv('Datasets/df_artists_origins.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_artists_origins_concat exported to .csv\n",
      "(3251, 2)\n"
     ]
    }
   ],
   "source": [
    "export_artists_origins_concat(df_new_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 - London, Greater London, England, United Kingdom\n",
      "2/9 - Bristol, City of Bristol, West of England, England, United Kingdom\n",
      "3/9 - Wandsworth, London Borough of Wandsworth, London, Greater London, England, SW18 1UJ, United Kingdom\n",
      "4/9 - Mount Sinai, Miller Place, Town of Brookhaven, Suffolk County, New York, 11766, United States\n",
      "5/9 - Lambeth, London Borough of Lambeth, London, Greater London, England, SE1 7JW, United Kingdom\n",
      "6/9 - Sheffield, South Yorkshire, England, United Kingdom\n",
      "7/9 - Hampstead, Greater London, England, NW3 1QG, United Kingdom\n",
      "8/9 - Ladbroke Grove, Westway, Lancaster West Estate, North Kensington, Royal Borough of Kensington and Chelsea, London, Greater London, England, W10 5YG, United Kingdom\n",
      "9/9 - Dudley, West Midlands, England, United Kingdom\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Bristol, England</td>\n",
       "      <td>Bristol, England</td>\n",
       "      <td>51.453802</td>\n",
       "      <td>-2.597298</td>\n",
       "      <td>Bristol, City of Bristol, West of England, Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Dudley</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "      <td>52.511083</td>\n",
       "      <td>-2.081681</td>\n",
       "      <td>Dudley, West Midlands, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Hampstead</td>\n",
       "      <td>Hampstead, England</td>\n",
       "      <td>Hampstead, England</td>\n",
       "      <td>51.556530</td>\n",
       "      <td>-0.178301</td>\n",
       "      <td>Hampstead, Greater London, England, NW3 1QG, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Ladbroke Grove</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "      <td>51.517264</td>\n",
       "      <td>-0.211102</td>\n",
       "      <td>Ladbroke Grove, Westway, Lancaster West Estate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Lambeth, England</td>\n",
       "      <td>Lambeth, England</td>\n",
       "      <td>51.495211</td>\n",
       "      <td>-0.116335</td>\n",
       "      <td>Lambeth, London Borough of Lambeth, London, Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>London, England</td>\n",
       "      <td>London, England</td>\n",
       "      <td>51.507446</td>\n",
       "      <td>-0.127765</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>Sheffield, England</td>\n",
       "      <td>Sheffield, England</td>\n",
       "      <td>53.380663</td>\n",
       "      <td>-1.470228</td>\n",
       "      <td>Sheffield, South Yorkshire, England, United Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "      <td>51.457027</td>\n",
       "      <td>-0.193261</td>\n",
       "      <td>Wandsworth, London Borough of Wandsworth, Lond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>United States</td>\n",
       "      <td>Mount Sinai</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "      <td>40.941066</td>\n",
       "      <td>-73.019455</td>\n",
       "      <td>Mount Sinai, Miller Place, Town of Brookhaven,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country            city                                 origin  \\\n",
       "0  United Kingdom         Bristol                       Bristol, England   \n",
       "1  United Kingdom          Dudley  Dudley, West Midlands, United Kingdom   \n",
       "2  United Kingdom       Hampstead                     Hampstead, England   \n",
       "3  United Kingdom  Ladbroke Grove        Ladbroke Grove, London, England   \n",
       "4  United Kingdom         Lambeth                       Lambeth, England   \n",
       "5  United Kingdom          London                        London, England   \n",
       "6  United Kingdom       Sheffield                     Sheffield, England   \n",
       "7  United Kingdom      Wandsworth                    Wandsworth, England   \n",
       "8   United States     Mount Sinai         Mount Sinai, NY, United States   \n",
       "\n",
       "                            origin_clean   latitude  longitude  \\\n",
       "0                       Bristol, England  51.453802  -2.597298   \n",
       "1  Dudley, West Midlands, United Kingdom  52.511083  -2.081681   \n",
       "2                     Hampstead, England  51.556530  -0.178301   \n",
       "3        Ladbroke Grove, London, England  51.517264  -0.211102   \n",
       "4                       Lambeth, England  51.495211  -0.116335   \n",
       "5                        London, England  51.507446  -0.127765   \n",
       "6                     Sheffield, England  53.380663  -1.470228   \n",
       "7                    Wandsworth, England  51.457027  -0.193261   \n",
       "8         Mount Sinai, NY, United States  40.941066 -73.019455   \n",
       "\n",
       "                                             address  \n",
       "0  Bristol, City of Bristol, West of England, Eng...  \n",
       "1     Dudley, West Midlands, England, United Kingdom  \n",
       "2  Hampstead, Greater London, England, NW3 1QG, U...  \n",
       "3  Ladbroke Grove, Westway, Lancaster West Estate...  \n",
       "4  Lambeth, London Borough of Lambeth, London, Gr...  \n",
       "5    London, Greater London, England, United Kingdom  \n",
       "6  Sheffield, South Yorkshire, England, United Ki...  \n",
       "7  Wandsworth, London Borough of Wandsworth, Lond...  \n",
       "8  Mount Sinai, Miller Place, Town of Brookhaven,...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates = get_coordinates_geopy(df_new_artists)\n",
    "df_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_coordinates``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527, 7)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "df_coordinates_scraped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Adelaide, South Australia, Australia</td>\n",
       "      <td>Adelaide, South Australia, Australia</td>\n",
       "      <td>-34.928181</td>\n",
       "      <td>138.599931</td>\n",
       "      <td>Adelaide, Adelaide City Council, South Austral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Adelaide, South Australia</td>\n",
       "      <td>Adelaide, South Australia</td>\n",
       "      <td>-34.928181</td>\n",
       "      <td>138.599931</td>\n",
       "      <td>Adelaide, Adelaide City Council, South Austral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Blue Mountains</td>\n",
       "      <td>Blue Mountains, NSW, Australia</td>\n",
       "      <td>Blue Mountains, NSW, Australia</td>\n",
       "      <td>-33.609741</td>\n",
       "      <td>150.405224</td>\n",
       "      <td>Blue Mountains, New South Wales, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane, Queensland, Australia</td>\n",
       "      <td>Brisbane, Queensland, Australia</td>\n",
       "      <td>-27.468968</td>\n",
       "      <td>153.023499</td>\n",
       "      <td>City of Brisbane, Queensland, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Byron Bay</td>\n",
       "      <td>Byron Bay, New South Wales, Australia</td>\n",
       "      <td>Byron Bay, New South Wales, Australia</td>\n",
       "      <td>-28.648333</td>\n",
       "      <td>153.617778</td>\n",
       "      <td>Byron Bay, Byron Shire Council, New South Wale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country            city                                 origin  \\\n",
       "0  Australia        Adelaide   Adelaide, South Australia, Australia   \n",
       "1  Australia        Adelaide              Adelaide, South Australia   \n",
       "2  Australia  Blue Mountains         Blue Mountains, NSW, Australia   \n",
       "3  Australia        Brisbane        Brisbane, Queensland, Australia   \n",
       "4  Australia       Byron Bay  Byron Bay, New South Wales, Australia   \n",
       "\n",
       "                            origin_clean   latitude   longitude  \\\n",
       "0   Adelaide, South Australia, Australia -34.928181  138.599931   \n",
       "1              Adelaide, South Australia -34.928181  138.599931   \n",
       "2         Blue Mountains, NSW, Australia -33.609741  150.405224   \n",
       "3        Brisbane, Queensland, Australia -27.468968  153.023499   \n",
       "4  Byron Bay, New South Wales, Australia -28.648333  153.617778   \n",
       "\n",
       "                                             address  \n",
       "0  Adelaide, Adelaide City Council, South Austral...  \n",
       "1  Adelaide, Adelaide City Council, South Austral...  \n",
       "2         Blue Mountains, New South Wales, Australia  \n",
       "3            City of Brisbane, Queensland, Australia  \n",
       "4  Byron Bay, Byron Shire Council, New South Wale...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>54.702354</td>\n",
       "      <td>-3.276575</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            country            city          origin    origin_clean  \\\n",
       "702  United Kingdom  United Kingdom  United Kingdom  United Kingdom   \n",
       "\n",
       "      latitude  longitude         address  \n",
       "702  54.702354  -3.276575  United Kingdom  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped[df_coordinates_scraped['city']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country, city, origin, origin_clean, latitude, longitude, address]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped.drop(702, axis=0, inplace=True)\n",
    "df_coordinates_scraped[df_coordinates_scraped['city']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinates_scraped.to_csv('Datasets/df_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_coordinates_scraped: (1526, 7)\n",
      "\n",
      "Found 4 duplicates:\n",
      "               city         country\n",
      "324         Bristol  United Kingdom\n",
      "515  Ladbroke Grove  United Kingdom\n",
      "542          London  United Kingdom\n",
      "650       Sheffield  United Kingdom\n",
      "\n",
      "Resulting dataset: (1531, 7)\n",
      "Merged artists with coordinates! Found 5 new locations\n",
      "df_coordinates_concat exported to .csv\n"
     ]
    }
   ],
   "source": [
    "export_coordinates_concat(df_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_artists_origins_coordinates_concat``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to a .csv file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>Gilgamesh</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Hampstead</td>\n",
       "      <td>51.556530</td>\n",
       "      <td>-0.178301</td>\n",
       "      <td>Hampstead, Greater London, England, NW3 1QG, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>Young Legionnaire</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>51.489334</td>\n",
       "      <td>-0.144055</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>The Deviants</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Ladbroke Grove</td>\n",
       "      <td>51.517264</td>\n",
       "      <td>-0.211102</td>\n",
       "      <td>Ladbroke Grove, Westway, Lancaster West Estate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>Head of David</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Dudley</td>\n",
       "      <td>52.511083</td>\n",
       "      <td>-2.081681</td>\n",
       "      <td>Dudley, West Midlands, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Quintessence</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>51.489334</td>\n",
       "      <td>-0.144055</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist         country            city   latitude  longitude  \\\n",
       "3246          Gilgamesh  United Kingdom       Hampstead  51.556530  -0.178301   \n",
       "3247  Young Legionnaire  United Kingdom          London  51.489334  -0.144055   \n",
       "3248       The Deviants  United Kingdom  Ladbroke Grove  51.517264  -0.211102   \n",
       "3249      Head of David  United Kingdom          Dudley  52.511083  -2.081681   \n",
       "3250       Quintessence  United Kingdom          London  51.489334  -0.144055   \n",
       "\n",
       "                                                address  \n",
       "3246  Hampstead, Greater London, England, NW3 1QG, U...  \n",
       "3247    London, Greater London, England, United Kingdom  \n",
       "3248  Ladbroke Grove, Westway, Lancaster West Estate...  \n",
       "3249     Dudley, West Midlands, England, United Kingdom  \n",
       "3250    London, Greater London, England, United Kingdom  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins_coordinates_concat = merge_origins_coordinates(df_new_artists)\n",
    "df_artists_origins_coordinates_concat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>3821235</td>\n",
       "      <td>1537522</td>\n",
       "      <td>13529787</td>\n",
       "      <td>US</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Entity</td>\n",
       "      <td>2019</td>\n",
       "      <td>38.42</td>\n",
       "      <td>8</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Death Metal']</td>\n",
       "      <td>Death Metal band from Chicago, Illinois, USA. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>3821235</td>\n",
       "      <td>1094310</td>\n",
       "      <td>8362817</td>\n",
       "      <td>US</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Sentient</td>\n",
       "      <td>2016</td>\n",
       "      <td>37.92</td>\n",
       "      <td>9</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Death Metal']</td>\n",
       "      <td>Death Metal band from Chicago, Illinois, USA. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>184256</td>\n",
       "      <td>175620</td>\n",
       "      <td>279855</td>\n",
       "      <td>UK</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>We'll Talk About It Later</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Jazz', 'Rock']</td>\n",
       "      <td>['Fusion', 'Jazz-Funk', 'Jazz-Rock', 'Prog Rock']</td>\n",
       "      <td>Pioneering jazz-rock, progressive, psychedelic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>184256</td>\n",
       "      <td>23574</td>\n",
       "      <td>465143</td>\n",
       "      <td>UK</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Elastic Rock</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Jazz', 'Rock']</td>\n",
       "      <td>['Jazz-Rock', 'Fusion', 'Prog Rock']</td>\n",
       "      <td>Pioneering jazz-rock, progressive, psychedelic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist_id  master_id  main_release_id release_country        artist  \\\n",
       "1004     3821235    1537522         13529787              US  Nucleus (US)   \n",
       "1592     3821235    1094310          8362817              US  Nucleus (US)   \n",
       "5257      184256     175620           279855              UK  Nucleus (UK)   \n",
       "10195     184256      23574           465143              UK  Nucleus (UK)   \n",
       "\n",
       "                           title  year  album_length  tracks     release_type  \\\n",
       "1004                      Entity  2019         38.42       8        ['Album']   \n",
       "1592                    Sentient  2016         37.92       9        ['Album']   \n",
       "5257   We'll Talk About It Later  1971          0.00       7  ['LP', 'Album']   \n",
       "10195               Elastic Rock  1970          0.00      13  ['LP', 'Album']   \n",
       "\n",
       "                 genres                                             styles  \\\n",
       "1004           ['Rock']                                    ['Death Metal']   \n",
       "1592           ['Rock']                                    ['Death Metal']   \n",
       "5257   ['Jazz', 'Rock']  ['Fusion', 'Jazz-Funk', 'Jazz-Rock', 'Prog Rock']   \n",
       "10195  ['Jazz', 'Rock']               ['Jazz-Rock', 'Fusion', 'Prog Rock']   \n",
       "\n",
       "                                          artist_profile  \n",
       "1004   Death Metal band from Chicago, Illinois, USA. ...  \n",
       "1592   Death Metal band from Chicago, Illinois, USA. ...  \n",
       "5257   Pioneering jazz-rock, progressive, psychedelic...  \n",
       "10195  Pioneering jazz-rock, progressive, psychedelic...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended[df_masters_blended['artist'].str.contains('Nucleus')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist_id, master_id, main_release_id, release_country, artist, title, year, album_length, tracks, release_type, genres, styles, artist_profile]\n",
       "Index: []"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended[df_masters_blended['title'].str.contains('Alleycat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29004</th>\n",
       "      <td>86398</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Elastic Rock</td>\n",
       "      <td>3.55</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29120</th>\n",
       "      <td>87140</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>We'll Talk About It Later</td>\n",
       "      <td>3.79</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39636</th>\n",
       "      <td>216509</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Sentient</td>\n",
       "      <td>3.29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45524</th>\n",
       "      <td>333839</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Entity</td>\n",
       "      <td>3.68</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46380</th>\n",
       "      <td>352917</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Alleycat</td>\n",
       "      <td>3.52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       album_id        artist                      title  rating  votes\n",
       "29004     86398  Nucleus (UK)               Elastic Rock    3.55     20\n",
       "29120     87140  Nucleus (UK)  We'll Talk About It Later    3.79     21\n",
       "39636    216509  Nucleus (US)                   Sentient    3.29     29\n",
       "45524    333839  Nucleus (US)                     Entity    3.68     40\n",
       "46380    352917  Nucleus (UK)                   Alleycat    3.52     20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_20[df_ratings_20['artist'].str.contains('Nucleus')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.loc[46380, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[29004, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[29120, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[39636, 'artist'] = 'Nucleus (US)'\n",
    "df_ratings_20.loc[45524, 'artist'] = 'Nucleus (US)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12059, 10)"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([7660, 8037], axis=0, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [album_id, artist, album, rating, votes]\n",
       "Index: []"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist'] = np.where(df['artist']=='pg.99 / Majority Rule', 'Majority Rule', df['artist'])\n",
    "df[df['artist']=='pg.99 / Majority Rule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.to_csv('Datasets/df_ratings_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12059, 10)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing code for strange cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Funeral_for_a_Friend_(band): Bridgend, Wales\n",
      "1 - Millencolin_(band): multiple issues - rebro, Sweden\n",
      "2 - The_Flaming_Lips_(band): Oklahoma City, Oklahoma, U.S.\n",
      "3 - Feeder_(band): Feeder in 2008\n",
      "4 - Descendents_(band): Manhattan Beach, California, U.S.\n",
      "5 - PJ Harvey: no location found\n",
      "6 - Godsmack_(band): Lawrence, Massachusetts U.S.\n",
      "7 - Blind_Faith_(band): Ripley, Surrey, England\n",
      "8 - Van_Halen_(band): Pasadena, California, U.S.\n",
      "9 - Damageplan_(band): Dallas, Texas, U.S.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/df_ratings.csv')\n",
    "artists = df['artist'].unique()\n",
    "\n",
    "artists_list = []\n",
    "origin_list = []\n",
    "count=0\n",
    "\n",
    "for index in artists[140:150]:\n",
    "\n",
    "    artists_list.append(index)\n",
    "    name_changed = index.replace(' ', '_')\n",
    "    name_changed_band = name_changed + ('_(band)')\n",
    "\n",
    "    try:\n",
    "        url = f\"https://en.wikipedia.org/wiki/{name_changed_band}\"\n",
    "        response = requests.get(url).content\n",
    "        soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "        origin = soup.select('table tr th', class_='infobox-label')\n",
    "\n",
    "        if len(origin) > 0:\n",
    "            try:\n",
    "                if origin[2].text == 'Origin':\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[1].text\n",
    "                elif origin[3].text == 'Origin':\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[2].text\n",
    "                # else:\n",
    "                    \n",
    "                if 'multiple issues' in location:\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[7].text        \n",
    "                    print(f'{count} - {name_changed_band}: multiple issues - {location}')\n",
    "                    origin_list.append(location)\n",
    "                elif 'additional citations' in location:\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[3].text        \n",
    "                    print(f'{count} - {name_changed_band}: additional citations - {location}')\n",
    "                    origin_list.append(location)\n",
    "\n",
    "                else:\n",
    "                    print(f'{count} - {name_changed_band}: {location}')\n",
    "                    origin_list.append(location)\n",
    "            except:\n",
    "                print(f'{count} - {name_changed_band}: {location}')\n",
    "                origin_list.append(location)      \n",
    "        else:\n",
    "            try:\n",
    "                url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "                response = requests.get(url).content\n",
    "                soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "                origin = soup.select('table tr th', class_='infobox-label')\n",
    "\n",
    "                if len(origin) > 0:\n",
    "                    if origin[2].text == 'Origin':\n",
    "                        location = soup.select('table tr td', class_='infobox-data')[1].text\n",
    "\n",
    "                        if 'multiple issues' in location:\n",
    "                            location = soup.select('table tr td', class_='infobox-data')[7].text        \n",
    "                            print(f'{count} - {name_changed_band}: multiple issues - {location}')\n",
    "                            origin_list.append(location)\n",
    "                        elif 'additional citations' in location:\n",
    "                            location = soup.select('table tr td', class_='infobox-data')[3].text        \n",
    "                            print(f'{count} - {name_changed_band}: additional citations - {location}')\n",
    "                            origin_list.append(location)\n",
    "                        else:\n",
    "                            print(f'{count} - {name_changed_band}: {location}')\n",
    "                            origin_list.append(location)\n",
    "\n",
    "                    elif origin[3].text == 'Origin':\n",
    "                        location = soup.select('table tr td', class_='infobox-data')[2].text\n",
    "                        print(f'{count} - {name_changed_band}: {location}')\n",
    "                        origin_list.append(location) \n",
    "\n",
    "                    else:\n",
    "                        print(f'{count} - {index}: no location found')\n",
    "                        origin_list.append(np.nan)  \n",
    "                else:\n",
    "                    print(f'{count} - {index}: short length')\n",
    "                    origin_list.append(np.nan)\n",
    "            except:\n",
    "                print(f'{count} - {index}: error')\n",
    "                origin_list.append(np.nan)\n",
    "    except:\n",
    "        print(f'{count} - {index}: error')\n",
    "        origin_list.append(np.nan)\n",
    "\n",
    "    if len(artists_list) != len(origin_list):\n",
    "        print('different lengths')\n",
    "        break\n",
    "\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_origins_wikipedia(df, start_index, final_index):\n",
    "    df = pd.read_csv('Datasets/df_rock_ratings_20.csv')\n",
    "    artists = df['artist'].unique()\n",
    "\n",
    "    try:\n",
    "    # import the DataFrame with the locations whose coordinates I already have\n",
    "        df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "        print('Bingo! df_coordinates.csv found \\n')\n",
    "    except: \n",
    "        print('df_coordinates.csv not found \\n')\n",
    "\n",
    "    artists_list = []\n",
    "    origin_list = []\n",
    "    count=0\n",
    "    scraped=0\n",
    "\n",
    "    for index in artists_us_to_do[start_index:final_index]:\n",
    "\n",
    "        name_changed = index.replace(' ', '_')\n",
    "        name_changed_band = name_changed + ('_(band)')\n",
    "\n",
    "        try:\n",
    "            url = f\"https://en.wikipedia.org/wiki/{name_changed_band}\"\n",
    "            response = requests.get(url).content\n",
    "            soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "            table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "            location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "            city = location.split(', ')[0]\n",
    "            count+=1\n",
    "            \n",
    "        # save info in lists\n",
    "            artists_list.append(index)  \n",
    "            origin_list.append(location)\n",
    "            scraped+=1\n",
    "            print(f'{scraped}/{count} - {name_changed_band}: {location}')\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "                response = requests.get(url).content\n",
    "                soup = BeautifulSoup(response, \"html.parser\")\n",
    "                table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "                try:\n",
    "                    location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1 \n",
    "    \n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed}: {location}')\n",
    "\n",
    "                except:\n",
    "                    location = table[0].text.split(')')[2].split('Genres')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1\n",
    "\n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed} (individual): {location}')\n",
    "\n",
    "            except:\n",
    "                try:\n",
    "                    url = f\"https://es.wikipedia.org/wiki/{name_changed}\"\n",
    "                    response = requests.get(url).content\n",
    "                    soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "                    table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "                    location = table[0].text.split('Origen\\n')[1].split(' Informacin')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1    \n",
    "    \n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed} (espaol): {location}')\n",
    "\n",
    "                except:\n",
    "                    count+=1\n",
    "                    print(f'{scraped}/{count} - {index}: error')\n",
    "                    artists_list.append(index) \n",
    "                    origin_list.append(np.nan)\n",
    "\n",
    "        if len(artists_list) != len(origin_list):\n",
    "            print('different lengths')\n",
    "            break\n",
    "\n",
    "    df_artists_origins = pd.DataFrame({'artist': artists_list\n",
    "                             , 'origin': origin_list})\n",
    "    \n",
    "    return df_artists_origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_artists(df_artists_origins):\n",
    "\n",
    "# import the df with the artists' origins already scraped\n",
    "    df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "\n",
    "    if df_artists_origins['origin'].isna().sum() == 0:        \n",
    "        print(\"No null values, but let's take a look just in case there are weird locations\")\n",
    "\n",
    "    else: \n",
    "    # take a look at the df with the new artists and make sure there are non null values in origin (when it couldn't find it in Wikipedia)\n",
    "        print(f'{round(df_artists_origins['origin'].isna().sum() / df_artists_origins.shape[0]*100, 2)} % of nulls')\n",
    "    \n",
    "# subset of the new artists I just got, wether there are null values or not\n",
    "    df_new_artists = df_artists_origins[~df_artists_origins['artist'].isin(df_artists_origins_scraped['artist'].values)]\n",
    "\n",
    "    print(\"Here is the dataframe with the new artists, without duplicates\")\n",
    "    return df_new_artists   # so I can take a look at it and then continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_artists_origins_concat(df_new_artists):\n",
    "\n",
    "# import the df with the artists' origins already scraped\n",
    "    df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "\n",
    "# concat with the df I just got\n",
    "    df_artists_origins_concat = pd.concat([df_artists_origins_scraped, df_new_artists])\n",
    "    df_artists_origins_concat.drop_duplicates(inplace=True)     # just in case\n",
    "    df_artists_origins_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# export all the artists and their origins to a .csv file (the ones I got plus the new artists)\n",
    "    df_artists_origins_concat.to_csv('Datasets/df_artists_origins.csv', index=False)\n",
    "    print('df_artists_origins_concat exported to .csv')\n",
    "    print(df_artists_origins_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_geopy(df_new_artists):\n",
    "    \n",
    "# replace special characters for spaces\n",
    "    df_new_artists['origin_clean'] = df_new_artists['origin'].str.replace('.', '')\n",
    "    df_new_artists['origin_clean'] = df_new_artists['origin_clean'].str.replace(r'\\[\\d+\\]', '', regex=True)\n",
    "\n",
    "# run the function that gets the coordinates from the origins from Geopy\n",
    "    geolocator = Nominatim(user_agent=\"music_analysis\", timeout=10)\n",
    "\n",
    "# if they are 'dirty' origins that after the cleaning, they result in the same 'origin_clean'\n",
    "    df_unique = df_new_artists[['origin', 'origin_clean']].drop_duplicates() \n",
    "    unique_origins = df_unique['origin'].values\n",
    "    unique_origins_clean = df_unique['origin_clean'].values\n",
    "\n",
    "    country_list = []\n",
    "    city_list = []\n",
    "    latitude_list = []\n",
    "    longitude_list = []\n",
    "    address_list = []\n",
    "    lists = [country_list, city_list, latitude_list, longitude_list, address_list]\n",
    "    count = 0\n",
    "\n",
    "    for origin in unique_origins_clean:\n",
    "        count+=1\n",
    "        time.sleep(1)\n",
    "        location = geolocator.geocode(origin)\n",
    "\n",
    "        print(f'{count}/{len(unique_origins_clean)} - {location.address}')  \n",
    "\n",
    "    # save the info in lists\n",
    "        country_list.append(location.address.split(', ')[-1])\n",
    "        city_list.append(origin.split(', ')[0])\n",
    "        latitude_list.append(location.latitude)\n",
    "        longitude_list.append(location.longitude)\n",
    "        address_list.append(location.address)\n",
    "\n",
    "        # # Check lengths\n",
    "        # print(f\"{count}/{len(unique_origins_clean)} - {origin}\")\n",
    "        # print(f\"Current list lengths -> country: {len(country_list)}, city: {len(city_list)}, \"\n",
    "        #     f\"lat: {len(latitude_list)}, lon: {len(longitude_list)}, address: {len(address_list)}\")\n",
    "\n",
    "    df_coordinates = pd.DataFrame({'country': country_list\n",
    "                                , 'city': city_list\n",
    "                                , 'origin': unique_origins\n",
    "                                , 'origin_clean': unique_origins_clean\n",
    "                                , 'latitude': latitude_list\n",
    "                                , 'longitude': longitude_list\n",
    "                                , 'address': address_list})\n",
    "    df_coordinates.sort_values(['country', 'city'], inplace=True) # sort by country and city\n",
    "    df_coordinates.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_coordinates_concat(df_coordinates):\n",
    "\n",
    "# import the last df that contains the coordinates of the unique origins\n",
    "    df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "    print(f\"df_coordinates_scraped: {df_coordinates_scraped.shape}\\n\")\n",
    "\n",
    "# concat with the df of the coordinates I just got\n",
    "    df_coordinates_concat = pd.concat([df_coordinates_scraped, df_coordinates])\n",
    "    df_coordinates_concat.sort_values(['country', 'city'], inplace=True) # sort by country and city\n",
    "    df_coordinates_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# look for duplicates in the origin, between the locations I had already gotten and the new ones\n",
    "    check_duplicates_origins(df_coordinates_concat)\n",
    "    new_origins = df_coordinates_concat.shape[0] - df_coordinates_scraped.shape[0]\n",
    "    print(f\"Merged artists with coordinates! Found {new_origins} new locations\")\n",
    "\n",
    "# save it in a csv file (the coordinates I had plus the ones from the new artists I just got)\n",
    "    df_coordinates_concat.to_csv('Datasets/df_coordinates.csv', index=False)\n",
    "    print('df_coordinates_concat exported to .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_origins_coordinates(df_new_artists):\n",
    "\n",
    "# import the last df that contains the coordinates of the unique origins\n",
    "    df_coordinates_concat = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "\n",
    "# merge with the previous df with the artists\n",
    "    df_artists_origins_coordinates = pd.merge(df_new_artists, df_coordinates_concat, on=['origin'])\n",
    "    df_artists_origins_coordinates.drop(columns=['origin', 'origin_clean_x', 'origin_clean_y'], inplace=True)\n",
    "\n",
    "# import the df that contains info of the artists and the coordinates of their origins\n",
    "    df_artists_origins_coordinates_scraped = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')\n",
    "\n",
    "# concat to get the df with all the artists, origins and their coordinates\n",
    "    df_artists_origins_coordinates_concat = pd.concat([df_artists_origins_coordinates_scraped, df_artists_origins_coordinates])\n",
    "    df_artists_origins_coordinates_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# save it in a csv file\n",
    "    df_artists_origins_coordinates_concat.to_csv('Datasets/df_artists_origins_coordinates.csv', index=False)\n",
    "    print(\"Exported to a .csv file\")\n",
    "\n",
    "    return df_artists_origins_coordinates_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dataframes and look for the ``new_artists``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4527"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_blend = df_masters_blended['artist'].unique()\n",
    "len(artists_blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1555"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "artists = df_artists_origins['artist'].unique()\n",
    "artists_usa = []\n",
    "\n",
    "for artist in artists_blend:\n",
    "    if artist not in df_artists_origins['artist'].values:\n",
    "        artists_usa.append(artist)\n",
    "\n",
    "len(artists_usa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As Living Arrows',\n",
       " 'Hidden Mothers',\n",
       " 'Tiny Moving Parts',\n",
       " 'Poppy',\n",
       " 'State Champs',\n",
       " 'Oso Oso',\n",
       " 'Better Lovers',\n",
       " 'Lowen',\n",
       " 'Halsey',\n",
       " 'Amyl and the Sniffers',\n",
       " 'Delta Sleep',\n",
       " 'High Vis',\n",
       " 'Cemetery Skyline',\n",
       " 'Goat',\n",
       " 'Chat Pile',\n",
       " 'Drug Church',\n",
       " 'Origami Angel',\n",
       " 'Heriot',\n",
       " 'Nightwish',\n",
       " 'Foxing',\n",
       " 'Alora Crucible',\n",
       " 'Wage War',\n",
       " 'TURQUOISEDEATH',\n",
       " 'Dawn Treader',\n",
       " 'Boston Manor',\n",
       " 'MJ Lenderman',\n",
       " 'Fat Dog',\n",
       " 'Kingcrow',\n",
       " 'Leprous',\n",
       " 'Wunderhorse',\n",
       " 'thrown',\n",
       " 'Horse Jumper of Love',\n",
       " 'Within the Ruins',\n",
       " 'Magdalena Bay',\n",
       " 'Fontaines D.C.',\n",
       " 'beabadoobee',\n",
       " 'State Faults',\n",
       " 'Graphic Nature',\n",
       " 'The Home Team',\n",
       " 'Speed',\n",
       " 'Remi Wolf',\n",
       " 'Clairo',\n",
       " 'Crippling Alcoholism',\n",
       " 'Cigarettes After Sex',\n",
       " 'Abriction',\n",
       " 'Pijn',\n",
       " 'Outlander',\n",
       " 'Imagine Dragons',\n",
       " 'The Dangerous Summer',\n",
       " 'Pond',\n",
       " 'Hyperdontia',\n",
       " 'Vredehammer',\n",
       " 'Pedro the Lion',\n",
       " 'Weston Super Maim',\n",
       " 'Stand Still',\n",
       " 'Mortal Wound',\n",
       " 'Eye of Solitude',\n",
       " 'Beth Gibbons',\n",
       " 'Contention',\n",
       " 'Knocked Loose',\n",
       " 'Mdou Moctar',\n",
       " 'The Lemon Twigs',\n",
       " 'Mk.Gee',\n",
       " 'Vennart',\n",
       " 'Microwave',\n",
       " 'Mastiff',\n",
       " 'Skycamefalling',\n",
       " 'SeeYouSpaceCowboy',\n",
       " 'Jamie Lenman',\n",
       " 'AVRALIZE',\n",
       " 'Imminence',\n",
       " 'Aaron West and The Roaring Twenties',\n",
       " 'Lo Moon',\n",
       " 'English Teacher',\n",
       " 'Engulfed',\n",
       " 'Khruangbin',\n",
       " 'Coffin Storm',\n",
       " 'Blanket',\n",
       " 'Boundaries',\n",
       " 'Adrianne Lenker',\n",
       " 'samlrc',\n",
       " 'Sticky Fingers',\n",
       " 'Bleachers',\n",
       " 'Stay Inside',\n",
       " 'Mannequin Pussy',\n",
       " 'Yard Act',\n",
       " 'Faye Webster',\n",
       " 'Little Kid',\n",
       " 'Job For A Cowboy',\n",
       " 'IDLES',\n",
       " 'Ihsahn',\n",
       " 'Laura Jane Grace',\n",
       " 'The Chisel',\n",
       " 'The Last Dinner Party',\n",
       " 'NewDad',\n",
       " 'Frank Carter and the Rattlesnakes',\n",
       " 'Tapir!',\n",
       " 'Neck Deep',\n",
       " 'Casey',\n",
       " 'Marika Hackman',\n",
       " 'Slift',\n",
       " 'Sprints',\n",
       " 'Killing Me Softly',\n",
       " 'Rannoch',\n",
       " 'Termina',\n",
       " 'Harp',\n",
       " 'Empty Country',\n",
       " 'Free Throw',\n",
       " 'Psychedelic Porn Crumpets',\n",
       " 'Dying Wish',\n",
       " 'END',\n",
       " 'Wargasm',\n",
       " 'Maria BC',\n",
       " 'Myrkur',\n",
       " 'Knuckle Puck',\n",
       " 'Creeper',\n",
       " 'Beartooth',\n",
       " 'Blood Command',\n",
       " 'Rorcal',\n",
       " 'Yeule',\n",
       " 'Slow Pulp',\n",
       " 'Dead and Dripping',\n",
       " 'Koyo',\n",
       " 'Shade Empire',\n",
       " 'TesseracT',\n",
       " 'Explosions in the Sky',\n",
       " 'Cursetheknife',\n",
       " 'Olivia Rodrigo',\n",
       " 'Uada',\n",
       " 'Pain of Truth',\n",
       " 'Reverence To Paroxysm',\n",
       " 'Royal Blood',\n",
       " 'Celestial Sanctuary',\n",
       " 'Empire State Bastard',\n",
       " 'Jeff Rosenstock',\n",
       " 'Spanish Love Songs',\n",
       " 'Urne',\n",
       " 'Movements',\n",
       " 'Caskets',\n",
       " 'Fiddlehead',\n",
       " 'Sunami',\n",
       " 'Teenage Wrist',\n",
       " 'Deitus',\n",
       " 'Mutoid Man',\n",
       " 'Voyager',\n",
       " 'Dawnwalker',\n",
       " 'PVRIS',\n",
       " 'Julie Byrne',\n",
       " 'Blindfolded and Led to the Woods',\n",
       " 'Nothing But Thieves',\n",
       " 'Grian Chatten',\n",
       " 'Model/Actriz',\n",
       " 'Burner',\n",
       " 'Death Goals',\n",
       " 'King Krule',\n",
       " 'feeble little horse',\n",
       " 'Noah Kahan',\n",
       " 'Squid',\n",
       " 'Tigercub',\n",
       " 'Pupil Slicer',\n",
       " 'Protomartyr',\n",
       " 'Phoxjaw',\n",
       " 'Bully',\n",
       " 'Wytch Hazel',\n",
       " 'Water From Your Eyes',\n",
       " 'Incendiary',\n",
       " 'bar italia',\n",
       " 'Sleep Token',\n",
       " 'Mandy, Indiana',\n",
       " 'Covet',\n",
       " 'The Amity Affliction',\n",
       " 'Veil of Maya',\n",
       " 'Currents',\n",
       " 'Crown the Empire',\n",
       " 'There Will Be Fireworks',\n",
       " 'Waterparks',\n",
       " 'Blondshell',\n",
       " 'HMLTD',\n",
       " 'deathcrash',\n",
       " 'Wednesday',\n",
       " 'Gel',\n",
       " 'Allfather',\n",
       " 'Bury Tomorrow',\n",
       " 'City and Colour',\n",
       " 'Boygenius',\n",
       " \"Dawn Ray'd\",\n",
       " 'BABYMETAL',\n",
       " 'Mork',\n",
       " 'Green Druid',\n",
       " 'M83',\n",
       " '100 Gecs',\n",
       " 'Periphery',\n",
       " 'Sleaford Mods',\n",
       " 'Acres',\n",
       " \"Can't Swim\",\n",
       " 'Pest Control',\n",
       " 'Host',\n",
       " 'U.S. Girls',\n",
       " 'Shame',\n",
       " 'Avatar',\n",
       " 'Hellripper',\n",
       " 'Avey Tare',\n",
       " 'A Wake in Providence',\n",
       " 'Pigs Pigs Pigs Pigs Pigs Pigs Pigs',\n",
       " 'Ihlo',\n",
       " 'Narrow Head',\n",
       " 'Emarosa',\n",
       " 'Molly',\n",
       " 'The Murder Capital',\n",
       " 'Margo Price',\n",
       " 'Weyes Blood',\n",
       " 'Turnover',\n",
       " 'Demon Hunter',\n",
       " \"Arm's Length\",\n",
       " 'Fit for a King',\n",
       " 'Dead Cross',\n",
       " 'Abduction',\n",
       " 'Brutus',\n",
       " 'Dry Cleaning',\n",
       " 'The 1975',\n",
       " 'Lacuna Coil',\n",
       " 'Gilla Band',\n",
       " 'Alvvays',\n",
       " 'Counterparts',\n",
       " 'Vacuous',\n",
       " 'Faceless Burial',\n",
       " 'Drowning Pool',\n",
       " 'Within Destruction',\n",
       " 'Miss May I',\n",
       " 'Escuela Grind',\n",
       " 'No Devotion',\n",
       " 'Holy Fawn',\n",
       " 'Courting',\n",
       " 'Tamino',\n",
       " 'Horsey',\n",
       " 'Inclination',\n",
       " 'Rina Sawayama',\n",
       " 'Electric Callboy',\n",
       " 'Camping In Alaska',\n",
       " 'Slaughterhouse',\n",
       " 'YUNGBLUD',\n",
       " 'Stella Donnelly',\n",
       " 'Julia Jacklin',\n",
       " 'Pale Waves',\n",
       " 'The Halo Effect',\n",
       " 'Sedimentum',\n",
       " 'Pool Kids',\n",
       " 'Ithaca',\n",
       " 'Dance Gavin Dance',\n",
       " 'Molder',\n",
       " 'Black Midi',\n",
       " 'Say Sue Me',\n",
       " 'Viagra Boys',\n",
       " 'Wormrot',\n",
       " 'Momma',\n",
       " 'Petrol Girls',\n",
       " 'Saor',\n",
       " 'Soccer Mommy',\n",
       " 'Sunrise Patriot Motion',\n",
       " 'Nova Twins',\n",
       " 'Ataraxy',\n",
       " 'Otoboke Beaver',\n",
       " 'Motionless In White',\n",
       " 'Corpsessed',\n",
       " 'Blood Youth',\n",
       " 'Horsegirl',\n",
       " 'Just Mustard',\n",
       " 'Malevolence',\n",
       " 'Harry Styles',\n",
       " 'Porridge Radio',\n",
       " 'Toad',\n",
       " 'Rolling Blackouts Coastal Fever',\n",
       " 'Bodysnatcher',\n",
       " 'Static Dress',\n",
       " 'Halestorm',\n",
       " 'Stand Atlantic',\n",
       " 'Proper.',\n",
       " 'Black Sheep Wall',\n",
       " 'Hatchie',\n",
       " 'Prince Daddy and The Hyena',\n",
       " 'Undeath',\n",
       " 'Epitaphe',\n",
       " 'Envy of None',\n",
       " 'Helpless',\n",
       " 'Wet Leg',\n",
       " 'PUP',\n",
       " 'Camp Cope',\n",
       " 'Ditz',\n",
       " 'Aldous Harding',\n",
       " 'Indian Summer',\n",
       " 'Machine Gun Kelly',\n",
       " 'Animals As Leaders',\n",
       " 'Yumi Zouma',\n",
       " 'Twelve Foot Ninja',\n",
       " 'Belmont',\n",
       " 'Messa',\n",
       " 'Chalk Hands',\n",
       " 'Ghost',\n",
       " 'Cryptworm',\n",
       " 'Mountaineer',\n",
       " 'Ecchymosis',\n",
       " 'Bloodywood',\n",
       " 'Sasami',\n",
       " 'Avril Lavigne',\n",
       " 'Mom Jeans.',\n",
       " 'Caroline',\n",
       " 'Scorpions',\n",
       " 'Evergreen',\n",
       " 'Sea Power',\n",
       " 'Big Thief',\n",
       " 'As It Is',\n",
       " 'Grivo',\n",
       " 'Mitski',\n",
       " 'Pinegrove',\n",
       " 'Black Country, New Road',\n",
       " 'Bad Omens',\n",
       " 'Voices',\n",
       " 'Comeback Kid',\n",
       " 'Shadow Of Intent',\n",
       " 'Vertebra Atlantis',\n",
       " 'Slow Crush',\n",
       " 'Unfurl',\n",
       " 'Geese',\n",
       " 'Papangu',\n",
       " 'Damon Albarn',\n",
       " 'Sermon of Flames',\n",
       " 'Springtime',\n",
       " 'Snail Mail',\n",
       " 'Emma Ruth Rundle',\n",
       " 'Courtney Barnett',\n",
       " 'Black Veil Brides',\n",
       " 'Frontierer',\n",
       " 'Monolord',\n",
       " 'Sulphurous',\n",
       " 'Black Marble',\n",
       " 'Ice Nine Kills',\n",
       " 'I Feel Fine',\n",
       " 'Sugar Horse',\n",
       " 'Dean Blunt',\n",
       " 'Sam Fender',\n",
       " \"KK's Priest\",\n",
       " 'Full of Hell',\n",
       " 'Tremonti',\n",
       " 'LLNN',\n",
       " 'Spiritbox',\n",
       " 'Aborted',\n",
       " 'Kacey Musgraves',\n",
       " 'Trna',\n",
       " 'Slaughter To Prevail',\n",
       " 'sonhos tomam conta',\n",
       " 'Bossk',\n",
       " 'Indigo De Souza',\n",
       " 'Deafheaven',\n",
       " 'Wolves in the Throne Room',\n",
       " 'Qrixkuor',\n",
       " 'Trash Boat',\n",
       " 'Galvanizer',\n",
       " 'Yola',\n",
       " 'Torres',\n",
       " 'LUMP',\n",
       " 'The Maine',\n",
       " 'Ophidian I',\n",
       " 'Diabolizer',\n",
       " 'Descendents',\n",
       " 'Lightning Bug',\n",
       " 'Atvm',\n",
       " 'Project 86',\n",
       " 'Lovesliescrushing',\n",
       " 'Hacktivist',\n",
       " 'Lucy Dacus',\n",
       " 'Portal',\n",
       " 'Ceremonium',\n",
       " 'Nexilva',\n",
       " 'Fear Factory',\n",
       " 'Morbific',\n",
       " 'Marina',\n",
       " 'Our Hollow, Our Home',\n",
       " 'Wolf Alice',\n",
       " 'Tilian',\n",
       " 'Bachelor',\n",
       " 'Noctule',\n",
       " 'Japanese Breakfast',\n",
       " 'Home Is Where',\n",
       " 'Manchester Orchestra',\n",
       " 'The Raging Nathans',\n",
       " 'Holding Absence',\n",
       " 'Flock of Dimes',\n",
       " \"'68\",\n",
       " 'Genghis Tron',\n",
       " 'Ominous Ruin',\n",
       " 'Cassandra Jenkins',\n",
       " 'Julien Baker',\n",
       " 'Love and Death',\n",
       " 'Defacement',\n",
       " 'Divide And Dissolve',\n",
       " 'TV Priest',\n",
       " 'Lamp of Murmuur',\n",
       " 'Goat Girl',\n",
       " 'Soen',\n",
       " 'Accept',\n",
       " 'Pom Poko',\n",
       " 'The Casket Lottery',\n",
       " 'Parquet Courts',\n",
       " 'Pearl Charles',\n",
       " 'Respire',\n",
       " 'Teenage Mutant Ninja Turtles',\n",
       " 'Dominic Fike',\n",
       " 'Undergang',\n",
       " 'Edenic Past',\n",
       " 'Red City Radio',\n",
       " 'Palm Reader',\n",
       " 'Bearings',\n",
       " 'Seahaven',\n",
       " 'Black Foxxes',\n",
       " 'Scalp',\n",
       " 'The Menzingers',\n",
       " 'Kingdom of Giants',\n",
       " 'Guitar Fight from Fooly Cooly',\n",
       " 'Miasmatic Necrosis',\n",
       " 'Black Stone Cherry',\n",
       " 'Nothing',\n",
       " 'The Fall of Troy',\n",
       " 'Matt Berninger',\n",
       " 'Gorephilia',\n",
       " 'Joji',\n",
       " 'Corey Taylor',\n",
       " 'Fires in the Distance',\n",
       " 'Obsidian Kingdom',\n",
       " 'Svalbard',\n",
       " 'The Ocean',\n",
       " 'Into It. Over It.',\n",
       " 'Fawn Limbs',\n",
       " 'Vous Autres',\n",
       " 'Carnation',\n",
       " 'Special Interest',\n",
       " 'Declan McKenna',\n",
       " 'Xazraug',\n",
       " 'Necrot',\n",
       " 'Angel Olsen',\n",
       " \"Luna's Call\",\n",
       " 'No Joy',\n",
       " 'Pharmacist',\n",
       " 'Duma',\n",
       " 'Misery Signals',\n",
       " 'Slightly Stoopid',\n",
       " 'Aseitas',\n",
       " 'Paara',\n",
       " 'Greg Puciato',\n",
       " 'The Beths',\n",
       " 'Nation of Language',\n",
       " 'Grey Daze',\n",
       " 'Carach Angren',\n",
       " 'Melt Yourself Down',\n",
       " 'Pottery',\n",
       " 'Sault',\n",
       " 'Calligram',\n",
       " 'Phoebe Bridgers',\n",
       " 'Owen',\n",
       " 'Justice For The Damned',\n",
       " 'Make Them Suffer',\n",
       " 'Westerman',\n",
       " 'Sports Team',\n",
       " 'Muzz',\n",
       " 'Palaye Royale',\n",
       " \"Caligula's Horse\",\n",
       " 'Infant Island',\n",
       " 'VVilderness',\n",
       " 'Car Seat Headrest',\n",
       " 'Elephant Tree',\n",
       " 'Molested Divinity',\n",
       " 'Ellis',\n",
       " 'Kontinuum',\n",
       " 'Yves Tumor',\n",
       " 'Telepathy',\n",
       " '5 Seconds of Summer',\n",
       " 'Brian Fallon',\n",
       " 'Sorry',\n",
       " 'The Chats',\n",
       " 'Malokarpatan',\n",
       " 'Afterbirth',\n",
       " 'Temple of Void',\n",
       " 'Hot Mulligan',\n",
       " 'Horse Lords',\n",
       " 'The Districts',\n",
       " 'Monsters',\n",
       " 'Greg Dulli',\n",
       " 'Panchiko',\n",
       " 'Bambara',\n",
       " 'Giver',\n",
       " 'Loathe',\n",
       " 'Shopping',\n",
       " 'Leeched',\n",
       " 'Lowrider',\n",
       " 'Lovebites',\n",
       " 'Vengeful Spectre',\n",
       " 'Higher Power',\n",
       " 'Slick Shoes',\n",
       " 'Wolf Parade',\n",
       " 'Mura Masa',\n",
       " 'Garganjua',\n",
       " 'Algiers',\n",
       " 'Vomit the Soul',\n",
       " 'The Last Ten Seconds Of Life',\n",
       " 'Blood Incantation',\n",
       " 'Dream State',\n",
       " 'Stray from the Path',\n",
       " 'Rex Orange County',\n",
       " 'Sadisme',\n",
       " 'Patrick Watson',\n",
       " 'Common Holly',\n",
       " 'Car Bomb',\n",
       " 'We Lost the Sea',\n",
       " 'Surf Curse',\n",
       " 'Issues',\n",
       " 'Kim Gordon',\n",
       " 'Alarmist',\n",
       " 'Dayseeker',\n",
       " 'Renounced',\n",
       " 'Post Malone',\n",
       " 'Klone',\n",
       " 'Void of Vision',\n",
       " 'The Agonist',\n",
       " 'Liam Gallagher',\n",
       " 'The Hu',\n",
       " 'Grayscale',\n",
       " 'Chris Farren',\n",
       " 'The Odious',\n",
       " 'Sleeping With Sirens',\n",
       " 'Nocturnal Departure',\n",
       " 'Whitney',\n",
       " 'Jay Som',\n",
       " 'Tropical Fuck Storm',\n",
       " 'King Gizzard and The Lizard Wizard',\n",
       " 'Blanck Mass',\n",
       " 'Richard Henshall',\n",
       " 'Rosalie Cunningham',\n",
       " 'Slaughter Beach, Dog',\n",
       " 'iamthemorning',\n",
       " 'Iniquitous Deeds',\n",
       " 'Throes',\n",
       " 'Abbath',\n",
       " 'Ossuary',\n",
       " 'Shirokuma',\n",
       " 'Puppy',\n",
       " 'Bill Callahan',\n",
       " 'CHON',\n",
       " 'Vanishing Twin',\n",
       " 'Frank Iero and The Future Violents',\n",
       " 'Novo Amor',\n",
       " 'Death Angel',\n",
       " 'Cate Le Bon',\n",
       " 'Plastic Mermaids',\n",
       " 'Black Mountain',\n",
       " 'Alex Lahey',\n",
       " 'Lewis Capaldi',\n",
       " 'Holding Patterns',\n",
       " 'Forests',\n",
       " 'We Never Learned To Live',\n",
       " 'Shin Guard',\n",
       " 'Town Portal',\n",
       " 'Trade Wind',\n",
       " 'Kevin Morby',\n",
       " 'Nucleus',\n",
       " 'Wand',\n",
       " 'Clowns',\n",
       " 'The Raven Age',\n",
       " 'Ceremony Of Silence',\n",
       " 'The Dismemberment Plan',\n",
       " 'CHAI',\n",
       " 'Orville Peck',\n",
       " 'Akasha',\n",
       " 'Venom Prison',\n",
       " 'Oozing Wound',\n",
       " 'Baalsebub',\n",
       " 'Tim Bowness',\n",
       " 'Mammoth Weed Wizard Bastard',\n",
       " 'Hozier',\n",
       " 'Teeth Of The Sea',\n",
       " 'Badflower',\n",
       " 'Drenge',\n",
       " 'Astronauts',\n",
       " 'Homeshake',\n",
       " 'Green Lung',\n",
       " 'Set It Off',\n",
       " 'Minors',\n",
       " 'King 810',\n",
       " 'Mystifier',\n",
       " 'Jade Bird',\n",
       " 'Press Club',\n",
       " 'Mono',\n",
       " 'Palisades',\n",
       " 'Tallies',\n",
       " 'Deuce',\n",
       " 'Napoleon',\n",
       " 'Normandie',\n",
       " 'XXXTENTACION',\n",
       " 'Ex:Re',\n",
       " 'Bliss Signal',\n",
       " 'Portrayal of Guilt',\n",
       " 'The Good, The Bad and The Queen',\n",
       " 'Toska',\n",
       " 'Tenacious D',\n",
       " 'Hippo Campus',\n",
       " 'Mass of the Fermenting Dregs',\n",
       " 'The Struts',\n",
       " 'Frog',\n",
       " 'The Dirty Nil',\n",
       " 'Polyphia',\n",
       " 'Hands Like Houses',\n",
       " 'Tom Morello',\n",
       " 'Pagan',\n",
       " 'Black Peaks',\n",
       " 'Kero Kero Bonito',\n",
       " 'Monuments',\n",
       " 'Exit North',\n",
       " 'Against The Current',\n",
       " 'Windhand',\n",
       " 'All Them Witches',\n",
       " 'Head with Wings',\n",
       " 'Wstr',\n",
       " 'Imperial Triumphant',\n",
       " 'The Skull',\n",
       " 'Gia Margaret',\n",
       " 'Trophy Eyes',\n",
       " 'Regal Worm',\n",
       " 'Talons',\n",
       " 'Like Pacific',\n",
       " 'The Antichrist Imperium',\n",
       " 'Mouse On The Keys',\n",
       " 'Burial Invocation',\n",
       " 'Morrow',\n",
       " 'The Interrupters',\n",
       " 'Panic! at the Disco',\n",
       " 'Mark Kozelek',\n",
       " 'Church of the Cosmic Skull',\n",
       " 'Zeal and Ardor',\n",
       " 'Jonathan Davis',\n",
       " 'Tancred',\n",
       " 'Lunatic Soul',\n",
       " 'Flasher',\n",
       " 'Graveyard',\n",
       " 'Keiji Haino',\n",
       " 'Body Void',\n",
       " 'Middle Kids',\n",
       " 'Pinkshinyultrablast',\n",
       " 'Forth Wanderers',\n",
       " 'Sectioned',\n",
       " 'Speedy Ortiz',\n",
       " 'Cassus',\n",
       " 'Boss Keloid',\n",
       " 'Tangled Hair',\n",
       " 'Ruins',\n",
       " 'Mastersystem',\n",
       " 'Rainbow Kitten Surprise',\n",
       " 'Autokrator',\n",
       " 'Night Flowers',\n",
       " 'Hinds',\n",
       " 'Sunflower Bean',\n",
       " 'Nervus',\n",
       " 'George Ezra',\n",
       " 'King Goat',\n",
       " 'Dead!',\n",
       " 'Moose Blood',\n",
       " \"Ed Schrader's Music Beat\",\n",
       " 'Gleb Kolyadin',\n",
       " 'Slugdge',\n",
       " 'Conjurer',\n",
       " 'Vundabar',\n",
       " 'Dvne',\n",
       " 'S. Carey',\n",
       " 'Pianos Become the Teeth',\n",
       " 'Band-Maid',\n",
       " 'Legend of the Seagullmen',\n",
       " 'Crywank',\n",
       " 'The Plot In You',\n",
       " 'Loma',\n",
       " 'Ezra Furman',\n",
       " 'Son Lux',\n",
       " 'Alpha Male Tea Party',\n",
       " 'Palm',\n",
       " 'Philip H. Anselmo and The Illegals',\n",
       " 'Marmozets',\n",
       " 'Somali Yacht Club',\n",
       " 'Anna Burch',\n",
       " 'Dream Wife',\n",
       " 'Thousand Below',\n",
       " 'Of Mice and Men',\n",
       " \"Leaves' Eyes\",\n",
       " 'Embodyment',\n",
       " 'Five Iron Frenzy',\n",
       " 'Yellow Days',\n",
       " 'Death Toll 80k',\n",
       " 'Sacred Son',\n",
       " 'Peach Pit',\n",
       " 'Beast In Black',\n",
       " 'ROAM',\n",
       " 'Turnpike Troubadours',\n",
       " 'Ibeyi',\n",
       " 'Grave Pleasures',\n",
       " 'IDYLLS',\n",
       " 'With the Dead',\n",
       " 'Nothing More',\n",
       " 'Prawn',\n",
       " 'Seaway',\n",
       " 'Ariel Pink',\n",
       " 'Rostam',\n",
       " 'The Contortionist',\n",
       " 'Prophets of Rage',\n",
       " 'White Moth Black Butterfly',\n",
       " 'Hammock',\n",
       " 'Hungry Ghosts',\n",
       " 'Thy Art Is Murder',\n",
       " 'ostraca',\n",
       " 'Kesha',\n",
       " 'Horrified',\n",
       " 'Agents of Oblivion',\n",
       " 'Sheer Mag',\n",
       " 'Silverstein',\n",
       " 'HAIM',\n",
       " 'Public Service Broadcasting',\n",
       " 'Spaceslug',\n",
       " 'Floating Points',\n",
       " 'Ex Eye',\n",
       " 'Hey Violet',\n",
       " 'Single Mothers',\n",
       " 'Wode',\n",
       " 'Flogging Molly',\n",
       " 'Tricot',\n",
       " 'Pumarosa',\n",
       " 'Employed To Serve',\n",
       " 'Gnarwolves',\n",
       " 'Woods',\n",
       " 'PWR BTTM',\n",
       " 'i hate sex',\n",
       " 'Spotlights',\n",
       " 'Sundara Karma',\n",
       " 'Hoops',\n",
       " 'The Physics House Band',\n",
       " 'Artificial Brain',\n",
       " 'Falling in Reverse',\n",
       " 'Jeromes Dream',\n",
       " 'Richard Cheese',\n",
       " 'Michelle Branch',\n",
       " 'Timber Timbre',\n",
       " 'I Declare War',\n",
       " 'Chinese Football',\n",
       " 'The Smith Street Band',\n",
       " 'Phrenelith',\n",
       " 'Hurray For The Riff Raff',\n",
       " 'Circa Waves',\n",
       " 'Temples',\n",
       " 'Raspberry Bulbs',\n",
       " 'Crystal Fairy',\n",
       " 'Vagabon',\n",
       " 'Peter Silberman',\n",
       " 'Meat Wave',\n",
       " 'The Orwells',\n",
       " 'Andrew McMahon in the Wilderness',\n",
       " 'Starset',\n",
       " 'Mark Eitzel',\n",
       " 'Foxygen',\n",
       " 'The Mayfield Four',\n",
       " 'Tycho',\n",
       " 'Youth Funeral',\n",
       " '40 Watt Sun',\n",
       " 'Attila',\n",
       " 'You Blew It!',\n",
       " 'Voices from the Fuselage',\n",
       " 'Earth Moves',\n",
       " 'D.D Dumbo',\n",
       " 'Lewis Del Mar',\n",
       " 'From Ashes To New',\n",
       " 'Shawn Mendes',\n",
       " 'Airbourne',\n",
       " 'Merchandise',\n",
       " 'Beach Slang',\n",
       " 'Newsboys',\n",
       " 'Preoccupations',\n",
       " 'Okkervil River',\n",
       " 'Dope Lemon',\n",
       " 'Mild High Club',\n",
       " 'David Brent',\n",
       " 'Abhorrent Decimation',\n",
       " 'Bayside',\n",
       " 'SWMRS',\n",
       " 'Gouge Away',\n",
       " 'Young the Giant',\n",
       " 'Monarch',\n",
       " 'Coldrain',\n",
       " \"Bear's Den\",\n",
       " 'Despised Icon',\n",
       " 'Omni',\n",
       " 'McCafferty',\n",
       " 'Dikembe',\n",
       " 'Nonpoint',\n",
       " 'The Avalanches',\n",
       " 'Big Business',\n",
       " 'Martha',\n",
       " 'Fates Warning',\n",
       " 'Lonely the Brave',\n",
       " 'British Theatre',\n",
       " 'Thousand Foot Krutch',\n",
       " 'Art Of Dying',\n",
       " 'With Confidence',\n",
       " 'Jake Bugg',\n",
       " 'The Hotelier',\n",
       " 'Rival Sons',\n",
       " 'The Claypool Lennon Delirium',\n",
       " 'Wicked Innocence',\n",
       " 'Minor Victories',\n",
       " 'Fear of Men',\n",
       " 'Real Friends',\n",
       " 'Catfish and the Bottlemen',\n",
       " 'Pantha Du Prince',\n",
       " 'Crystal Lake',\n",
       " 'Kikagaku Moyo',\n",
       " 'Schammasch',\n",
       " 'Twin Peaks',\n",
       " 'Destruction',\n",
       " 'Eagulls',\n",
       " 'RY X',\n",
       " 'LUH',\n",
       " 'ANOHNI',\n",
       " 'Messenger',\n",
       " 'Annisokay',\n",
       " 'Dowsing',\n",
       " 'Crooks',\n",
       " 'Dehumanized',\n",
       " 'Moonlit Sailor',\n",
       " 'The Comet Is Coming',\n",
       " 'Radical Face',\n",
       " 'King Buffalo',\n",
       " 'The Drones',\n",
       " 'Plague Vendor',\n",
       " 'Richmond Fontaine',\n",
       " 'Sarah Neufeld',\n",
       " 'Heck',\n",
       " 'Wormed',\n",
       " 'ee',\n",
       " 'Guerilla Toss',\n",
       " 'Big Ups',\n",
       " 'Mothers',\n",
       " 'Cindy Lee',\n",
       " 'The Neighbourhood',\n",
       " 'Porches',\n",
       " 'Money',\n",
       " 'Nevermen',\n",
       " 'Savages',\n",
       " 'Intervals',\n",
       " 'Fit for an Autopsy',\n",
       " 'Violet Cold',\n",
       " 'Sam Hunt',\n",
       " 'Nokturnel',\n",
       " 'Good Tiger',\n",
       " 'Sexwitch',\n",
       " 'EL VY',\n",
       " 'Love Lost But Not Forgotten',\n",
       " 'Half Moon Run',\n",
       " 'Shining',\n",
       " 'Marietta',\n",
       " 'Dilly Dally',\n",
       " 'One Ok Rock',\n",
       " 'Cruciamentum',\n",
       " 'Kylesa',\n",
       " 'Caspian',\n",
       " 'Agent Fresco',\n",
       " 'P.O.D.',\n",
       " 'X Ambassadors',\n",
       " 'Hills',\n",
       " 'Soilwork',\n",
       " 'Heartist',\n",
       " 'The Sword',\n",
       " 'Royal Headache',\n",
       " 'Highly Suspect',\n",
       " 'Kings Kaleidoscope',\n",
       " 'Archivist',\n",
       " 'Jason Isbell',\n",
       " 'Dan Andriano in the Emergency Room',\n",
       " 'Years and Years',\n",
       " 'Ethereal Shroud',\n",
       " 'God Damn',\n",
       " 'August Burns Red',\n",
       " 'Human Hands',\n",
       " 'Iwrestledabearonce',\n",
       " 'Mutiny On The Bounty',\n",
       " 'Mylets',\n",
       " 'Lucifer',\n",
       " 'Zella Day',\n",
       " 'FFS',\n",
       " 'Jaga Jazzist',\n",
       " 'Girlpool',\n",
       " 'Pet Symmetry',\n",
       " 'Charlie Simpson',\n",
       " 'Johnny Rebel',\n",
       " 'Surfer Blood',\n",
       " 'Murmur',\n",
       " 'We Are Harlot',\n",
       " 'Nai Harvest',\n",
       " 'Ghost Bath',\n",
       " 'Alabama Shakes',\n",
       " 'Bio-Cancer',\n",
       " 'Neon Trees',\n",
       " 'Say Lou Lou',\n",
       " 'Until The Ribbon Breaks',\n",
       " 'Shizune',\n",
       " 'Lower Dens',\n",
       " 'Ryley Walker',\n",
       " 'James Bay',\n",
       " 'AWOLNATION',\n",
       " 'Ranger',\n",
       " 'Trepalium',\n",
       " 'Houndmouth',\n",
       " 'The Sidekicks',\n",
       " 'Pile',\n",
       " 'Ghostpoet',\n",
       " 'A Textbook Tragedy',\n",
       " 'Colleen Green',\n",
       " 'Butch Walker',\n",
       " 'xRepentancex',\n",
       " 'Peace',\n",
       " 'The Arrogant Sons of Bitches',\n",
       " 'Jessica Pratt',\n",
       " 'This Is A Standoff',\n",
       " 'Planet X',\n",
       " 'Kodaline',\n",
       " 'FACT',\n",
       " 'Abstracter',\n",
       " 'California X',\n",
       " 'Cloakroom',\n",
       " 'Swallowed',\n",
       " 'Charli XCX',\n",
       " 'Clouds',\n",
       " 'TrenchRot',\n",
       " 'Forever Came Calling',\n",
       " 'The Ghost Inside',\n",
       " 'Youngblood Hawke',\n",
       " 'No Bragging Rights',\n",
       " 'Disembarked',\n",
       " 'The Jazz June',\n",
       " 'Wildbirds and Peacedrums',\n",
       " 'Crobot',\n",
       " 'Miroist',\n",
       " 'Climates',\n",
       " 'Tweedy',\n",
       " 'Adult Jazz',\n",
       " 'Benjamin Booker',\n",
       " 'My Brightest Diamond',\n",
       " 'The Hell',\n",
       " 'The Wytches',\n",
       " 'Lay Down Rotten',\n",
       " 'Owl John',\n",
       " 'The Algorithm',\n",
       " 'The Flex',\n",
       " 'Bear Hands',\n",
       " 'Totem Skin',\n",
       " 'Breathe Carolina',\n",
       " 'Braid',\n",
       " 'Total Control',\n",
       " 'Glass Animals',\n",
       " 'White Lung',\n",
       " 'Dreamshade',\n",
       " 'Tombs',\n",
       " 'Harry Pussy',\n",
       " 'Vales',\n",
       " 'Archspire',\n",
       " 'Sickening Gore',\n",
       " 'Mars Red Sky',\n",
       " 'Lewis',\n",
       " 'Sorority Noise',\n",
       " 'Echosmith',\n",
       " 'Brody Dalle',\n",
       " 'Circles',\n",
       " 'Ian Anderson',\n",
       " 'The Mire',\n",
       " \"Avey Tare's Slasher Flicks\",\n",
       " 'Chuck Ragan',\n",
       " 'Scar the Martyr',\n",
       " 'Owls',\n",
       " 'Collide',\n",
       " 'Laibach',\n",
       " 'Tony Molina',\n",
       " 'Adrenaline Mob',\n",
       " 'I See Stars',\n",
       " 'Pan.Thy.Monium',\n",
       " 'Above and Beyond',\n",
       " 'Cheatahs',\n",
       " 'Sahg',\n",
       " 'Harvey Danger',\n",
       " 'Mutual Benefit',\n",
       " 'Marvelous 3',\n",
       " 'Pestilence',\n",
       " 'Beastmilk',\n",
       " 'Hell',\n",
       " 'Steve Von Till',\n",
       " 'Laughing Hyenas',\n",
       " 'Yamantaka // Sonic Titan',\n",
       " 'Sky Ferreira',\n",
       " 'Kind of Like Spitting',\n",
       " 'the GazettE',\n",
       " 'San Fermin',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4249"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I have to import this df for the function to properly work\n",
    "df = pd.read_csv('Datasets/df_blend_ratings.csv')\n",
    "artists = df['artist'].unique()\n",
    "len(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As Living Arrows'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3423"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>Philadelphia, Pennsylvania, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>Death From Above 1979</td>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago, Illinois, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>The Nation of Ulysses</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>Strung Out</td>\n",
       "      <td>Simi Valley, California, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     artist                            origin\n",
       "3419             Cinderella  Philadelphia, Pennsylvania, U.S.\n",
       "3420  Death From Above 1979          Toronto, Ontario, Canada\n",
       "3421                Chicago  Chicago, Illinois, United States\n",
       "3422  The Nation of Ulysses                  Washington, D.C.\n",
       "3423             Strung Out     Simi Valley, California, U.S."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2772], dtype=int64),)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(artists=='July Talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'July Talk'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[2772]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Code to execute the functions from ``geopy_functions.py``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_to_remove = ['Cemetery Skyline', 'Goat', 'Kingcrow', 'Speed', 'Hyperdontia', 'Vredehammer', 'Weston Super Maim',\n",
    "                'Mdou Moctar', 'AVRALIZE', 'Engulfed', 'Coffin Storm', 'samlrc', 'Little Kid', 'Termina', 'Rorcal',\n",
    "                'Reverence To Paroxysm', 'Voyager', 'Blindfolded and Led to the Woods', 'Mork', 'Yeule', 'Pond',\n",
    "                'Empire State Bastard', 'Blood Command', 'Avatar', 'Brutus', 'Faceless Burial', 'Within Destruction',\n",
    "                'Sedimentum', 'Ataraxy', 'Corpsessed', 'Epitaphe', 'Aldous Harding', 'Messa', 'Ghost', 'Ecchymosis',\n",
    "                'Wormrot', 'Vertebra Atlantis', 'Papangu', 'Sermon of Flames', 'Springtime', 'Monolord', 'Sulphurous',\n",
    "                'LLNN', 'Trna', 'Slaughter To Prevail', 'sonhos tomam conta', 'Galvanizer', 'Ophidian I', 'Diabolizer',\n",
    "                'Morbific', 'Defacement', 'Divide And Dissolve', 'Soen', 'Scorpions', 'Accept', 'Respire', 'Undergang',\n",
    "                'Bearings', 'Scalp', 'Miasmatic Necrosis', 'Teenage Mutant Ninja Turtles', 'Gorephilia', 'Vous Autres',\n",
    "                'Carnation', 'Pharmacist', 'Paara', \"Justice For The Damned\", 'VVilderness', 'Molested Divinity', 'Ellis',\n",
    "                'Kontinuum', 'Monsters', 'Giver', 'Lowrider', 'Vengeful Spectre', 'Vomit the Soul', 'Sadisme', 'Alarmist',\n",
    "                'Klone', 'Nocturnal Departure', 'King Gizzard and The Lizard Wizard', 'Make Them Suffer', 'The Chats',\n",
    "                'Patrick Watson', 'Shirokuma', 'Forests', 'Town Portal', 'Ceremony Of Silence', 'CHAI', 'Baalsebub',\n",
    "                'Minors', 'Mono', 'Tallies', 'Normandie', 'Mouse On The Keys', 'Burial Invocation', 'Orville Peck',\n",
    "                'Lunatic Soul', 'Alex Lahey', 'Hozier', 'Mystifier', 'Hands Like Houses', 'Ruins', 'Autokrator',\n",
    "                'Legend of the Seagullmen', 'Death Toll 80k', 'IDYLLS', 'Spaceslug', 'i hate sex', 'Band-Maid',\n",
    "                'With the Dead', 'Hungry Ghosts', 'Middle Kids', 'Gleb Kolyadin', \"Leaves' Eyes\", \"Phrenelith\",\n",
    "                \"David Brent\", \"Art Of Dying\", \"Minor Victories\", \"Pantha Du Prince\", \"Schammasch\", 'LUH',\n",
    "                'Violet Cold', 'EL VY', 'Shining', 'Hills', \"Mutiny On The Bounty\", 'Lucifer', 'FFS', 'Ranger',\n",
    "                'Trepalium', 'A Textbook Tragedy', 'This Is A Standoff', 'FACT', 'Swallowed', 'Disembarked',\n",
    "                'Wildbirds and Peacedrums', 'Archivist', 'Timber Timbre', 'Newsboys', 'Dope Lemon', 'Vagabon',\n",
    "                'RY X', 'Moonlit Sailor', 'The Drones', 'Sarah Neufeld', 'Say Lou Lou', 'Cruciamentum', 'Lay Down Rotten',\n",
    "                'Dreamshade', 'Sickening Gore', 'Circles', \"Avey Tare's Slasher Flicks\", 'Forest Silence',\n",
    "                \"One Eyed God Prophecy\", 'Coffins', 'Osamu Kitajima', 'Living With Lions', 'Ansur', 'Parades',\n",
    "                \"Intestine Baalism\", 'Comity', 'No Omega', 'Wolverine', 'Disavowed', 'Angel Dust', \"!T.O.O.H.!\",\n",
    "                'Hypnosia', 'Hexenhaus', 'Paradox', 'Deathrow', 'Excruciate', 'FareWell Poetry', 'Sights and Sounds',\n",
    "                'Supersister', \"Birds Of Tokyo\", 'Ark', \"The Flower Kings\", 'Beardfish', 'Graveworm', 'Acid',\n",
    "                'Ladyhawke', 'Geddy Lee', 'Yngwie Malmsteen', \"World's End Girlfriend\", 'Totem Skin', 'Lewis',\n",
    "                'I Hate Sally', \"The Band\", 'Lisa Hannigan', 'Lethal', 'Bubu', 'Van She', 'Mooncake', 'The Haunted',\n",
    "                \"Orphaned Land\", 'Madder Mortem', 'Kataxu', 'Gilberto Gil', 'Vendetta', 'Kvist', 'Acrostichon', 'Pain',\n",
    "                'Obliteration', 'Flames of Hell', 'Wombbath', 'Stone', 'Disgrace', 'Fionn Regan', 'Disastrous Murmur',\n",
    "                'Urfaust', 'Sleepingdog', 'Island', 'Bethlehem', 'Subterranean Masquerade', 'After Dinner', \n",
    "                'Black Boned Angel', 'FM', 'Embrace', 'Solefald', 'Maneige', 'Amberian Dawn', 'OOIOO', 'Anekdoten',\n",
    "                \"Aphrodite's Child\", 'Hollenthon', 'Lykke Li', 'Lenka', 'Sarah McLachlan', 'Owen Pallett',\n",
    "                'Devin Townsend Project', 'Missy Higgins', 'The Devin Townsend Band', 'Selda', 'Massacra', \"Rory Gallagher\",\n",
    "                'Taste', 'Celestial Season', 'Ida Maria', 'Dark Tranquillity', 'Cadaver', 'Pele', 'Exuma',\n",
    "                'Great Lake Swimmers', 'Dawn', 'The Bats', 'Yoko Ono', 'Illogicist', 'The Saints', 'Final Fantasy',\n",
    "                'Pendulum', 'Lunar Aurora', 'Bee Gees', 'Stars', \"David Sylvian and Robert Fripp\", 'Afflicted', 'Lengsel',\n",
    "                'Extol', 'MDFMK', 'Univers Zero', 'Mortuary Drape', 'Zyklon', 'Winds', 'Zyklon-B', 'The Sins of Thy Beloved',\n",
    "                'Lords of Acid', 'Devin Townsend', 'Diablo Swing Orchestra', 'Arcturus', 'Cornelius', 'Manu Chao',\n",
    "                'Bryan Adams', 'Peaches', 'Doro', 'Kingdom Come', 'Pekka Pohjola', 'Shakira', 'Massacre', 'Subhumans',\n",
    "                'Set Fire to Flames', 'Gorgoroth', 'Gandalf', 'Klaus Schulze', 'The Ecstasy of Saint Theresa',\n",
    "                \"Lou Reed and John Cale\", 'Brian Eno and David Byrne', 'Bob Dylan and The Band', 'Era', 'Devil Doll',\n",
    "                'Cauterize', 'Roadrunner United', 'Circus Maximus', 'Crowpath', 'Raunchy', 'Tad Morose', 'Kenna',\n",
    "                'Head Control System', 'Torchbearer', 'Rosesdead', 'Angtoria', 'Nightrage', 'Necros Christos', 'Hypnos 69',\n",
    "                'Wold', 'Andromeda', 'Chad VanGaalen', 'Melechesh', 'Spheric Universe Experience', 'Anubis Gate',\n",
    "                'The Project Hate MCMXCIX', 'Myrath', 'Savage Circus', 'Hartfield', 'Evereve', 'Daturah', 'Ad Infinitum',\n",
    "                'Tash Sultana', 'Tarja Turunen', 'Ram-Zet', 'Sweven', 'Arcane', 'Sons of Apollo', 'Celesty', 'Brainstorm',\n",
    "                'Unleash The Archers', 'Prostitute Disfigurement', 'The Psyke Project', 'Dornenreich', 'Watain', 'Funeral',\n",
    "                'Cultes Des Ghoules', 'Revolting', 'Igorrr', 'Symfonia', 'Darkestrah', 'Sarah Blasko', 'Fractal Universe',\n",
    "                'The End', 'Apotheosis', 'Drautran', 'Monolithe', 'CrazyEightyEight', 'Black Hole', 'Polaris', 'Nug',\n",
    "                'Klabautamann', 'James LaBrie', 'Vance Joy', 'Helena Deland', 'Authorize', 'Blazon Stone', 'Rapture',\n",
    "                'Worship', 'Conqueror', 'Swan Lake', 'Yyrkoon', 'Inquisition', 'Kerli', 'Keldian', 'Wake', 'Megiddo',\n",
    "                'Juanes', 'William Hung', 'Votum', 'Atramentus', 'Abysmal Torment', 'Paul Dempsey', 'Cytotoxin',\n",
    "                'Vulture Industries', 'Entrails', 'Jorn', 'Conception', 'Centaurus-A', 'Gezan', 'Blood Tsunami',\n",
    "                'Machinemade God', 'Proscription', 'Ragnarok', 'Zeromancer', 'Satariel', 'Circle of Ouroborus', 'Emeth',\n",
    "                'Before The Dawn', 'Near Death Condition', 'Ignivomous', 'MEANS', 'Svart Crown', 'Alan Sorrenti', 'Chthonic',\n",
    "                'Blues Pills', 'Majestica', 'Bedsore', 'Ravencult', 'William Shatner', 'Cheval De Frise', 'Emptiness',\n",
    "                'WHOURKR', 'Jet Black Stare', 'Despondency', 'October Falls', 'Istapp', 'Slumber', 'Night in Gales',\n",
    "                'Ov HELL', 'Aficionado', 'Old Silver Key', 'Junior Battles', 'Adversarial', 'Shugo Tokumaru', 'North',\n",
    "                'Fuck on the Beach', 'Anoice', 'Viscera', 'Two Tongues', 'The Last Felony', 'Revenge', 'The Secret',\n",
    "                'Cosmic Putrefaction', 'Miseration', 'Azusa', 'Stalaggh']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "491"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_new_masters_clean = pd.read_csv('Datasets/df_us_new_masters_clean.csv')\n",
    "unique_artists = df_us_new_masters_clean[df_us_new_masters_clean['year']<2011]['artist'].unique()\n",
    "\n",
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "artists = df_artists_origins['artist'].unique()\n",
    "artists_to_do = []\n",
    "\n",
    "for artist in unique_artists:\n",
    "    if artist not in artists and artist not in artists_to_remove:\n",
    "        artists_to_do.append(artist)\n",
    "\n",
    "len(artists_to_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Miseration',\n",
       " 'At The Throne of Judgment',\n",
       " 'Fleeting Joys',\n",
       " 'Vivian Girls',\n",
       " 'Nora']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first next 5 artists I'm going to scrape\n",
    "artists_to_do[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bingo! df_coordinates.csv found \n",
      "\n",
      "1/1 - Miseration: Sweden\n",
      "2/2 - At_The_Throne_of_Judgment: Lebanon, Ohio, United States\n",
      "2/3 - Fleeting Joys: error\n",
      "3/4 - Vivian_Girls: Brooklyn, New York, United States\n",
      "4/5 - Nora_(band): Highland Park, New Jersey, United States\n",
      "4/6 - ...Of Sinking Ships: error\n",
      "5/7 - Arma_Angelus: Chicago, Illinois, U.S.\n",
      "5/8 - Encoffination: error\n",
      "6/9 - Dia_Frampton (individual): Draper, Utah, U.S.GenresPopfolkEDM\n",
      "6/10 - Lady Radiator: error\n",
      "7/11 - Harkonen_(band): Tacoma, Washington, U.S.\n",
      "8/12 - Jex_Thoth: Madison, Wisconsin, United States\n",
      "9/13 - Like_Moths_to_Flames: Columbus, Ohio, U.S.\n",
      "10/14 - Brandon_Boyd (individual): Van Nuys, California, U.S.Genres\n",
      "Alternative rock\n",
      "indie rock\n",
      "alternative metal\n",
      "funk rock\n",
      "nu metal\n",
      "funk metal\n",
      "\n",
      "11/15 - Azusa_(band): Oslo, NorwayDrama, GreecePhiladelphia, US\n",
      "12/16 - Confide_(band): Sunland, California\n",
      "13/17 - Satyr_(band): Atlanta, Georgia, United States\n",
      "14/18 - Curl_Up_and_Die: Las Vegas, Nevada, U.S.\n",
      "14/19 - Fuck on the Beach: error\n",
      "15/20 - Soft_Kill (espaol): Portland, Oregn, Estados UnidosInformacinartsticaGnero(s)\n",
      "Post-punk revival[1]SadcorePerodo de actividad\n",
      "2010-20112014-actualidadDiscogrfica(s)\n",
      "Fast WeaponsElectric Voice RecordsFuneral Party RecordsProfound Lore RecordsArtistas relacionados\n",
      "Blessure GraveChameleonsVoxMiembros\n",
      "\n",
      "\n",
      "Tobias GraveOwen GlendowerConrad VollmerExmiembros\n",
      "\n",
      "\n",
      "Shiloe AliaJustin GradinMattey HunterMaximillion AvilaAdam BulgasemBrandon PierceBrian LevinCarlos Sandoval Eric PhippsNathan HowdeshellDanny Valadez[editar datos en Wikidata]\n",
      "16/21 - Gulfer: Montreal, Quebec, Canada\n",
      "16/22 - Anoice: error\n",
      "17/23 - The_Color_Morale: Rockford, Illinois, U.S.\n",
      "18/24 - Grade_(band): Burlington, Ontario, Canada\n",
      "19/25 - Priscilla_Ahn (individual): Fort Stewart, Georgia, U.S.\n",
      "20/26 - Joie_de_Vivre (espaol): Rockford, Illinois\n",
      "21/27 - Dogleg_(band): Detroit, Michigan, U.S.\n",
      "22/28 - El_Ten_Eleven: Los Angeles, California, United States\n",
      "23/29 - xDEATHSTARx: Redlands, California, U.S.\n",
      "23/30 - Kid Liberty: error\n",
      "24/31 - Dropping_Daylight: Minneapolis, Minnesota, United States\n",
      "24/32 - Giraffes? Giraffes!: error\n",
      "25/33 - An_Horse: Brisbane, Australia[1]\n",
      "26/34 - Number_One_Gun: Chico, California, U.S.\n",
      "27/35 - The_Ergs!: South Amboy, New Jersey\n",
      "28/36 - Smith_Westerns: Chicago, Illinois, United States\n",
      "29/37 - Forevermore_(band): Indianapolis, Indiana, U.S.\n",
      "30/38 - Major_Organ_and_the_Adding_Machine: Athens, GA, United States\n",
      "30/39 - Elevate: I am: error\n",
      "30/40 - Viscera: error\n",
      "31/41 - Volcano_Choir: Wisconsin, United States\n",
      "32/42 - The_Garden_(band): Orange County, California, U.S.\n",
      "32/43 - Two Tongues: error\n",
      "32/44 - The Last Felony: error\n",
      "32/45 - Ioanna Gika: error\n",
      "32/46 - Us, From Outside: error\n",
      "33/47 - Ramshackle_Glory (individual): Brattleboro, Vermont, United StatesGenres\n",
      "Anarcho-punk\n",
      "folk punk[1]\n",
      "riot-folk\n",
      "Hip-Hop\n",
      "\n",
      "34/48 - Rings_of_Saturn_(band): Bay Area, California, U.S.\n",
      "35/49 - I_Set_My_Friends_On_Fire: Miami, Florida, U.S.\n",
      "36/50 - Dax_Riggs (individual): Evansville, Indiana, U.S.GenresAlternative rock, blues rock, swamp rock, indie rock, sludgemetal\n",
      "37/51 - Scott_Kelly: Oakland, California, U.S.\n",
      "37/52 - Revenge: error\n",
      "38/53 - Elvis_Depressedly: Columbia, South Carolina, U.S.\n",
      "39/54 - Stalaggh (espaol): msterdam, PasesBajosEstado\n",
      "DisueltoInformacinartsticaGnero(s)\n",
      "Noise, Black Metal, Dark AmbientPerodo de actividad\n",
      "2000 - 2008Miembros\n",
      "\n",
      "\n",
      "Desconocidos\n",
      "[editar datos en Wikidata]\n",
      "40/55 - Autumn's_Grey_Solace: St. Augustine, Florida, United States\n",
      "41/56 - Kimya_Dawson (individual): Bedford Hills, New York, U.S.\n",
      "41/57 - Disembowel: error\n",
      "42/58 - Lucy_Rose (individual): Camberley, Surrey, EnglandGenresFolk rock, indie folk\n",
      "42/59 - Bitter End: error\n",
      "42/60 - Seapony: error\n",
      "42/61 - Weaver At The Loom: error\n",
      "42/62 - Life on Repeat: error\n",
      "43/63 - Circle_of_Contempt: Pori, Finland\n",
      "44/64 - Mat_Kerekes: Bedford Township, Michigan, United States\n",
      "45/65 - Sever_Your_Ties: San Diego, US\n",
      "45/66 - The Secret: error\n",
      "46/67 - Cheekface: Los Angeles, California, U.S.\n",
      "47/68 - Impending_Doom_(band): Riverside, California, U.S.\n",
      "48/69 - 90_Day_Men: St. Louis, Missouri, U.S.\n",
      "49/70 - Torture_Killer: Turku, Finland\n",
      "50/71 - Good_Old_War: Philadelphia, Pennsylvania, United States\n",
      "50/72 - Destruction of a Rose: error\n",
      "51/73 - Carnifex_(band): San Diego County, California, U.S.\n",
      "52/74 - Retirement_Party: Chicago, Illinois\n",
      "53/75 - American_Me_(band): Portland, Oregon, U.S.\n",
      "54/76 - Contrarian_(band): Rochester, New York, U.S.\n",
      "55/77 - Locksley_(band): Madison, Wisconsin, United States\n",
      "56/78 - Davenport_Cabinet: New York City, United States\n",
      "57/79 - Angelcorpse: Kansas City, Missouri, U.S.\n",
      "58/80 - Sullivan_(band): Greensboro, North Carolina, U.S.\n",
      "59/81 - Every_Avenue: Marysville, Michigan\n",
      "60/82 - Last_Chance_to_Reason: Augusta, Maine, U.S.\n",
      "60/83 - Cosmic Putrefaction: error\n",
      "61/84 - Engineer_(band): Syracuse, New York, U.S.\n",
      "61/85 - Paddock Park: error\n",
      "61/86 - Perdition Temple: error\n",
      "62/87 - Drumcorps: Berlin, Germany\n",
      "62/88 - To Speak Of Wolves: error\n",
      "63/89 - Violent_Soho: Brisbane, Queensland, Australia\n",
      "63/90 - Insidious Decrepancy: error\n",
      "64/91 - Write_This_Down_(band): Minneapolis, Minnesota\n",
      "65/92 - Hostage_Calm: Wallingford, Connecticut, United States\n",
      "65/93 - Iress: error\n",
      "66/94 - Shakey_Graves (individual): Austin, TexasGenresAmericana\n",
      "67/95 - Recon_(band): California, U.S.\n",
      "67/96 - Des Ark: error\n",
      "67/97 - The Taste Of Blood: error\n",
      "67/98 - Inferi: error\n",
      "67/99 - Half Waif: error\n",
      "67/100 - INDK: error\n"
     ]
    }
   ],
   "source": [
    "# create the df with the origins scraped from Wikipedia\n",
    "\n",
    "df = pd.read_csv('Datasets/df_us_new_masters_clean.csv')\n",
    "start_index = 0\n",
    "final_index = start_index+100\n",
    "\n",
    "df_artists_origins = get_origins_wikipedia(df, start_index, final_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33 nulls (33.0 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miseration</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At The Throne of Judgment</td>\n",
       "      <td>Lebanon, Ohio, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fleeting Joys</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vivian Girls</td>\n",
       "      <td>Brooklyn, New York, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nora</td>\n",
       "      <td>Highland Park, New Jersey, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      artist                                    origin\n",
       "0                 Miseration                                    Sweden\n",
       "1  At The Throne of Judgment              Lebanon, Ohio, United States\n",
       "2              Fleeting Joys                                       NaN\n",
       "3               Vivian Girls         Brooklyn, New York, United States\n",
       "4                       Nora  Highland Park, New Jersey, United States"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a subset of the new artists I just got, and tell me if there are nulls\n",
    "df_new_artists = get_new_artists(df_artists_origins)\n",
    "\n",
    "# show the first new artists, if they were duplicates they have been dropped\n",
    "df_new_artists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there are null or weird values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8, 2)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a df with where origin is a null value\n",
    "nulls = df_new_artists[df_new_artists['origin'].isna()]\n",
    "nulls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"To Speak Of Wolves\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Insidious Decrepancy\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Iress\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Des Ark\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Taste Of Blood\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Inferi\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Half Waif\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"INDK\", \"England\", df_new_artists[\"origin\"])\n"
     ]
    }
   ],
   "source": [
    "# so I can print the np.where and I save time\n",
    "for artist in nulls['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"England\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking in the internet for the real origins of these artists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>To Speak Of Wolves</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>Insidious Decrepancy</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>Iress</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Des Ark</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The Taste Of Blood</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Inferi</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Half Waif</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>INDK</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist origin\n",
       "87    To Speak Of Wolves    NaN\n",
       "89  Insidious Decrepancy    NaN\n",
       "92                 Iress    NaN\n",
       "95               Des Ark    NaN\n",
       "96    The Taste Of Blood    NaN\n",
       "97                Inferi    NaN\n",
       "98             Half Waif    NaN\n",
       "99                  INDK    NaN"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls.head(10) # so it's faster to copy the names of the artists to look for their origins on the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"To Speak Of Wolves\", \"Greensboro, NC\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Insidious Decrepancy\", \"Houston, Texas\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Iress\", \"Los Angeles\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Des Ark\", \"Durham, NC, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Taste Of Blood\", \"Santa Cruz, CA, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Inferi\", \"Nashville, Tennessee\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Half Waif\", \"Hudson Valley, Upstate New York\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"INDK\", \"New York City\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4559</th>\n",
       "      <td>852935</td>\n",
       "      <td>0</td>\n",
       "      <td>2398932</td>\n",
       "      <td>US</td>\n",
       "      <td>INDK</td>\n",
       "      <td>Kill Whitey!</td>\n",
       "      <td>2002</td>\n",
       "      <td>34.02</td>\n",
       "      <td>14</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Punk', 'Hardcore']</td>\n",
       "      <td>Punk band from New York City, active from 1998...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_id  master_id  main_release_id release_country artist  \\\n",
       "4559     852935          0          2398932              US   INDK   \n",
       "\n",
       "             title  year  album_length  tracks release_type    genres  \\\n",
       "4559  Kill Whitey!  2002         34.02      14    ['Album']  ['Rock']   \n",
       "\n",
       "                    styles                                     artist_profile  \n",
       "4559  ['Punk', 'Hardcore']  Punk band from New York City, active from 1998...  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"INDK\".strip()].sort_values('year').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melodic death metal band from Nashville, Tennessee.  Founded in 2006, the band released two albums, \"Divinity in War\"\n",
      "(2007) and \"The End of an Era\" (2009), then it was put on hold. In 2011 the lead guitarist, Malcolm Pugh, decided to\n",
      "resurrect the band.\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[4555]['artist_profile']\n",
    "\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the original dataframes in case needed (ex: two bands with the same name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[11090, 'artist'] = 'Embrace (US)'\n",
    "df.loc[6140, 'artist'] = 'Embrace (UK)'\n",
    "df.loc[6141, 'artist'] = 'Embrace (UK)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Datasets/df_masters_blended.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>7197</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>The Good Will Out</td>\n",
       "      <td>3.56</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>7198</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>Out Of Nothing</td>\n",
       "      <td>3.39</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>14575</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>3.99</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      album_id   artist              title  rating  votes\n",
       "4485      7197  Embrace  The Good Will Out    3.56     24\n",
       "4486      7198  Embrace     Out Of Nothing    3.39     27\n",
       "8649     14575  Embrace            Embrace    3.99    309"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df_ratings_20 to check it's the correct artist\n",
    "df_ratings_20[df_ratings_20['artist']==\"Embrace\".strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.loc[8649, 'artist'] = 'Embrace (US)'\n",
    "df_ratings_20.loc[4486, 'artist'] = 'Embrace (UK)'\n",
    "df_ratings_20.loc[4485, 'artist'] = 'Embrace (UK)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.to_csv('Datasets/df_ratings_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists['origin'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Drop artists that are not from the UK or the US** (or supergroups that don't have a clear origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_to_remove = []\n",
    "\n",
    "for artist in artists_to_remove:\n",
    "    try:\n",
    "        artists_usa.remove(artist)\n",
    "        print(f'{artist} removed')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping: 90\n",
      "Rows after dropping: 89\n"
     ]
    }
   ],
   "source": [
    "# I can drop single rows or I can just create a subset with the artists that I want to keep, the ones that are not in the list of artists to remove\n",
    "print(f\"Rows before dropping: {df_new_artists.shape[0]}\")\n",
    "df_new_artists = df_new_artists[~df_new_artists['artist'].isin(artists_to_remove)]\n",
    "print(f\"Rows after dropping: {df_new_artists.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Check short and long origins, probably wrong**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print abnormally short origins and visually check if they are correct\n",
    "for index, row in df_new_artists.iterrows():\n",
    "    if len(row['origin']) < 10:\n",
    "        print(index, row['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Miseration</td>\n",
       "      <td>Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>At The Throne of Judgment</td>\n",
       "      <td>Lebanon, Ohio, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Fleeting Joys</td>\n",
       "      <td>Sacramento, California</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Vivian Girls</td>\n",
       "      <td>Brooklyn, New York, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nora</td>\n",
       "      <td>Highland Park, New Jersey, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>...Of Sinking Ships</td>\n",
       "      <td>Belmont, NC, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      artist                                    origin\n",
       "0                 Miseration                                    Sweden\n",
       "1  At The Throne of Judgment              Lebanon, Ohio, United States\n",
       "2              Fleeting Joys                    Sacramento, California\n",
       "3               Vivian Girls         Brooklyn, New York, United States\n",
       "4                       Nora  Highland Park, New Jersey, United States\n",
       "5        ...Of Sinking Ships                Belmont, NC, United States"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = 0\n",
    "\n",
    "end_index = start_index+5\n",
    "df_new_artists.loc[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4323</th>\n",
       "      <td>6819831</td>\n",
       "      <td>1726608</td>\n",
       "      <td>15127954</td>\n",
       "      <td>Norway</td>\n",
       "      <td>Azusa</td>\n",
       "      <td>Loop of Yesterdays</td>\n",
       "      <td>2020</td>\n",
       "      <td>35.82</td>\n",
       "      <td>12</td>\n",
       "      <td>['Album', 'Stereo']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Melodic Death Metal', 'Progressive Metal', '...</td>\n",
       "      <td>Metal band from Oslo, Norway; Philadelphia, US...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_id  master_id  main_release_id release_country artist  \\\n",
       "4323    6819831    1726608         15127954          Norway  Azusa   \n",
       "\n",
       "                   title  year  album_length  tracks         release_type  \\\n",
       "4323  Loop of Yesterdays  2020         35.82      12  ['Album', 'Stereo']   \n",
       "\n",
       "        genres                                             styles  \\\n",
       "4323  ['Rock']  ['Melodic Death Metal', 'Progressive Metal', '...   \n",
       "\n",
       "                                         artist_profile  \n",
       "4323  Metal band from Oslo, Norway; Philadelphia, US...  "
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Azusa\".strip()].sort_values('year').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Catherine was a metalcore band from Sacramento, CA.. They self-released their debut EP 'A Call To Entropy' in 2005.\n",
      "After signing with Rise Records, Catherine released their first full-length album 'Rumor Has It: Astaroth Has Stolen\n",
      "Your Eyes' on August 6th, 2006.    Catherine released their second album under Rise Records, 'The Naturals' with Nick\n",
      "Bradwell as the lead vocalist on August 7th, 2007.    It was announced that on December 28th, 2008, original lead\n",
      "vocalist Bryan LeMasters passed away after battling cancer.    The band posted the following message: \"As some of you\n",
      "may already know Bryan Lemasters (original vocalist for Catherine and an amazing person) has been battling cancer.\n",
      "Yesterday he passed away at the age of 23. Please keep his family and friends in your hearts.\"    On April 28th, 2009,\n",
      "with a variety of new members, Catherine released their third and final full-length album on Rise Records, 'Inside Out'.\n",
      "On August 10th, 2015 original founding member and guitarist Robert Lee Tobin passed away.      Catherine Lineup\n",
      "(Comprehensive):    Nick Bradwell (Vocals)  Robert Lee Tobin (Guitar)  Taylor Rearick (Guitar)  Steve Barboza (Bass)\n",
      "Justin Salinas (Drums)  Jesse Alejandrez (Guitar)  Andrew Franz (Bass)  Julio Garcia (Drums)  Bryan LeMasters (Vocals)\n",
      "Paul Vickery (Bass)  Chase Bratton  Aaron Brekky  Sam Cowan\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[4590]['artist_profile']\n",
    "\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = df_new_artists[df_new_artists['origin'].str.contains('Genres')]\n",
    "genres.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in genres['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"UK\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Dia Frampton\", \"Draper, Utah, U.S.\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Brandon Boyd\", \"Van Nuys, California, U.S.\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Ramshackle Glory\", \"Brattleboro, Vermont, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Dax Riggs\", \"Evansville, Indiana, U.S.\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Lucy Rose\", \"Camberley, Surrey, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Shakey Graves\", \"Austin, Texas\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the df so I can copy the origin from the column (before 'Genres')\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Genres')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 3)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I create a new column to calculate the lenght of the origin, if it's long it probably didn't scrap correctly Wikipedia\n",
    "df_new_artists[\"origin_length\"] = df_new_artists[\"origin\"].str.len()\n",
    "long_strings = df_new_artists[df_new_artists[\"origin_length\"]>40] # create a df based on these long origins\n",
    "long_strings.shape # to see how many artists I have to take care of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Azusa</td>\n",
       "      <td>Oslo, NorwayDrama, GreecePhiladelphia, US</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Soft Kill</td>\n",
       "      <td>Portland, Oregn, Estados UnidosInformacinar...</td>\n",
       "      <td>516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>Stalaggh</td>\n",
       "      <td>msterdam, PasesBajosEstado\\nDisueltoInform...</td>\n",
       "      <td>184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Mat Kerekes</td>\n",
       "      <td>Bedford Township, Michigan, United States</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Good Old War</td>\n",
       "      <td>Philadelphia, Pennsylvania, United States</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          artist                                             origin  \\\n",
       "14         Azusa          Oslo, NorwayDrama, GreecePhiladelphia, US   \n",
       "19     Soft Kill  Portland, Oregn, Estados UnidosInformacinar...   \n",
       "53      Stalaggh  msterdam, PasesBajosEstado\\nDisueltoInform...   \n",
       "63   Mat Kerekes          Bedford Township, Michigan, United States   \n",
       "70  Good Old War          Philadelphia, Pennsylvania, United States   \n",
       "\n",
       "    origin_length  \n",
       "14             41  \n",
       "19            516  \n",
       "53            184  \n",
       "63             41  \n",
       "70             41  "
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_strings # display the df so I can copy the parts I am interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in long_strings['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"UK\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Soft Kill\", \"Portland, OR\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Mat Kerekes\", \"Bedford Township, Michigan\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Half Waif\", \"Kingston, NY\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I drop the column I just created of 'origin_length'\n",
    "df_new_artists = df_new_artists[['artist', 'origin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from United Kingdom, wrong origin, poor level of detail\n",
    "df_new_artists[df_new_artists['origin']==('United Kingdom')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Changing easy values: individuals that didn't get the right origin in Wikipedia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# individuals that didn't get the right origin in Wikipedia\n",
    "df_new_artists[df_new_artists['origin'].str.contains(' and ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Cumbria, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Cumbria')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace('Cumbria', 'Cumberland'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Middlesex, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Middlesex')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', Middlesex', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Yorkshire, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('West Riding of Yorkshire')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', West Riding of Yorkshire', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Merseyside, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Merseyside')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', Merseyside', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try a single origin in Geopy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kirkland, King County, Washington, United States\n",
      "47.6765382 -122.2070775\n"
     ]
    }
   ],
   "source": [
    "# try to get the right origin of an origin that crashed\n",
    "geolocator = Nominatim(user_agent=\"music_analysis\")\n",
    "\n",
    "origin = \"Kirkland, Washington\"\n",
    "\n",
    "origin_clean = re.sub(r'\\[\\d+\\]', '', origin).replace('.', '')\n",
    "location = geolocator.geocode(origin_clean)\n",
    "print(f\"{location.address}\")\n",
    "print(location.latitude, location.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>The Taste Of Blood</td>\n",
       "      <td>Santa Cruz, CA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Inferi</td>\n",
       "      <td>Nashville, Tennessee</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Half Waif</td>\n",
       "      <td>Hudson Valley, Upstate New York</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>INDK</td>\n",
       "      <td>New York City</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist                           origin\n",
       "96  The Taste Of Blood    Santa Cruz, CA, United States\n",
       "97              Inferi             Nashville, Tennessee\n",
       "98           Half Waif  Hudson Valley, Upstate New York\n",
       "99                INDK                    New York City"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = 85\n",
    "\n",
    "end_index = start_index+5\n",
    "df_new_artists[start_index:end_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try all origins in Geopy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "85 - Santa Cruz County, California, United States\n",
      "86 - Nashville, Davidson County, Middle Tennessee, Tennessee, United States\n",
      "87 - City of Kingston, Ulster County, New York, 12401, United States\n",
      "88 - City of New York, New York, United States\n"
     ]
    }
   ],
   "source": [
    "# try to get the coordinates of the origins from Geopy and see if it crashes (wrong location that I have to change)\n",
    "geolocator = Nominatim(user_agent=\"music_analysis\", timeout=10)\n",
    "\n",
    "initial_index = 85\n",
    "count = initial_index-1\n",
    "\n",
    "for origin in df_new_artists['origin'].str.replace('.', '').str.replace(r'\\[\\d+\\]', '', regex=True)[initial_index:]:\n",
    "    count+=1\n",
    "    location = geolocator.geocode(origin)\n",
    "    print(f\"{count} - {location.address}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Export to .csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoPy wrong locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case GeoPy fails due to a wrong location, I have to delete the new locations, export again, change the location and run GeoPy again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # import the df with the artists' origins already scraped\n",
    "# df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "# df_artists_origins_scraped = df_artists_origins_scraped[0:-20]\n",
    "# df_artists_origins_scraped.to_csv('Datasets/df_artists_origins.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89, 2)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case I created by mistake already 'origin_clean' and I want to drop it\n",
    "# df_new_artists = df_new_artists[['artist', 'origin']]\n",
    "# df_new_artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Export to .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_artists_origins_concat exported to .csv\n",
      "(6346, 2)\n"
     ]
    }
   ],
   "source": [
    "export_artists_origins_concat(df_new_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GeoPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/86 - Lebanon, Warren County, Ohio, 45036, United States\n",
      "2/86 - Sacramento, Sacramento County, California, United States\n",
      "3/86 - Brooklyn, Kings County, City of New York, New York, United States\n",
      "4/86 - Highland Park, Middlesex County, New Jersey, 08904, United States\n",
      "5/86 - Belmont, Gaston County, North Carolina, 28012, United States\n",
      "6/86 - Chicago, Cook County, Illinois, United States\n",
      "7/86 - Atlanta, Fulton County, Georgia, United States\n",
      "8/86 - Draper, Salt Lake County, Utah, 84020, United States\n",
      "9/86 - Union City, Hudson County, New Jersey, 07087, United States\n",
      "10/86 - Tacoma, Pierce County, Washington, United States\n",
      "11/86 - Madison, Dane County, Wisconsin, United States\n",
      "12/86 - Columbus, Franklin County, Ohio, United States\n",
      "13/86 - Van Nuys Neighborhood Council District, Los Angeles, Los Angeles County, California, 91411, United States\n",
      "14/86 - Sunland, Los Angeles, Los Angeles County, California, 91040, United States\n",
      "15/86 - Atlanta, Fulton County, Georgia, United States\n",
      "16/86 - Las Vegas, Clark County, Nevada, United States\n",
      "17/86 - Portland, Multnomah County, Oregon, United States\n",
      "18/86 - Montral, Agglomration de Montral, Montral (rgion administrative), Qubec, Canada\n",
      "19/86 - Rockford, Rockford Township, Winnebago County, Illinois, United States\n",
      "20/86 - Burlington, Halton Region, Golden Horseshoe, Ontario, Canada\n",
      "21/86 - Fort Stewart, Hinesville, Liberty County, Georgia, United States\n",
      "22/86 - Rockford, Rockford Township, Winnebago County, Illinois, United States\n",
      "23/86 - Detroit, Wayne County, Michigan, United States\n",
      "24/86 - Los Angeles, Los Angeles County, California, United States\n",
      "25/86 - Redlands, San Bernardino County, California, United States\n",
      "26/86 - Sherman County, Texas, United States\n",
      "27/86 - Minneapolis, Hennepin County, Minnesota, United States\n",
      "28/86 - Keene, Cheshire County, New Hampshire, United States\n",
      "29/86 - City of Brisbane, Queensland, Australia\n",
      "30/86 - Chico, Butte County, California, United States\n",
      "31/86 - South Amboy, Middlesex County, New Jersey, United States\n",
      "32/86 - Chicago, Cook County, Illinois, United States\n",
      "33/86 - Indianapolis, Marion County, Indiana, United States\n",
      "34/86 - Athens, Clarke County, Georgia, United States\n",
      "35/86 - San Diego, San Diego County, California, United States\n",
      "36/86 - Wisconsin, United States\n",
      "37/86 - Orange County, California, United States\n",
      "38/86 - Washington, District of Columbia, United States\n",
      "39/86 - Philadelphia, Philadelphia County, Pennsylvania, United States\n",
      "40/86 - Brattleboro, Windham County, Vermont, United States\n",
      "41/86 - San Francisco Bay Area, San Francisco, California, 94110, United States\n",
      "42/86 - Miami, Miami-Dade County, Florida, United States\n",
      "43/86 - Evansville, Vanderburgh County, Indiana, United States\n",
      "44/86 - Oakland, Alameda County, California, United States\n",
      "45/86 - Columbia, Richland County, South Carolina, United States\n",
      "46/86 - Saint Augustine, Saint Johns County, Florida, 32084, United States\n",
      "47/86 - Bedford Hills, Town of Bedford, Westchester County, New York, United States\n",
      "48/86 - Camberley, Surrey Heath, Surrey, England, GU15 3SA, United Kingdom\n",
      "49/86 - San Antonio, Bexar County, Texas, United States\n",
      "50/86 - Seattle, King County, Washington, United States\n",
      "51/86 - Minneapolis, Hennepin County, Minnesota, United States\n",
      "52/86 - Salisbury, Wicomico County, Maryland, United States\n",
      "53/86 - Pori, Porin seutukunta, Satakunta, Manner-Suomi, Suomi / Finland\n",
      "54/86 - Bedford Township, Monroe County, Michigan, United States\n",
      "55/86 - San Diego, San Diego County, California, United States\n",
      "56/86 - Los Angeles, Los Angeles County, California, United States\n",
      "57/86 - Riverside, Riverside County, California, United States\n",
      "58/86 - Saint Louis, Missouri, United States\n",
      "59/86 - Turku, Turun seutukunta, Varsinais-Suomi, Manner-Suomi, Suomi / Finland\n",
      "60/86 - Philadelphia, Philadelphia County, Pennsylvania, United States\n",
      "61/86 - Las Vegas, Clark County, Nevada, United States\n",
      "62/86 - San Diego County, California, United States\n",
      "63/86 - Chicago, Cook County, Illinois, United States\n",
      "64/86 - Portland, Multnomah County, Oregon, United States\n",
      "65/86 - City of Rochester, Monroe County, New York, United States\n",
      "66/86 - City of New York, New York, United States\n",
      "67/86 - Kansas City, Jackson County, Missouri, United States\n",
      "68/86 - Greensboro, Guilford County, North Carolina, United States\n",
      "69/86 - Marysville, Saint Clair County, Michigan, 48040, United States\n",
      "70/86 - Augusta, Kennebec County, Maine, 04330, United States\n",
      "71/86 - City of Syracuse, Onondaga County, New York, United States\n",
      "72/86 - Panama City, Bay County, Florida, United States\n",
      "73/86 - Tampa, Hillsborough County, Florida, United States\n",
      "74/86 - Berlin, Pankow, Deutschland\n",
      "75/86 - Greensboro, Guilford County, North Carolina, United States\n",
      "76/86 - City of Brisbane, Queensland, Australia\n",
      "77/86 - Houston, Harris County, Texas, United States\n",
      "78/86 - Wallingford, South Central Connecticut Planning Region, Connecticut, 06492, United States\n",
      "79/86 - Los Angeles, Los Angeles County, California, United States\n",
      "80/86 - Austin, Travis County, Texas, United States\n",
      "81/86 - California, United States\n",
      "82/86 - Durham, Durham County, North Carolina, United States\n",
      "83/86 - Santa Cruz County, California, United States\n",
      "84/86 - Nashville, Davidson County, Middle Tennessee, Tennessee, United States\n",
      "85/86 - City of Kingston, Ulster County, New York, 12401, United States\n",
      "86/86 - City of New York, New York, United States\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane, Australia[1]</td>\n",
       "      <td>Brisbane, Australia</td>\n",
       "      <td>-27.468968</td>\n",
       "      <td>153.023499</td>\n",
       "      <td>City of Brisbane, Queensland, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane, Queensland, Australia</td>\n",
       "      <td>Brisbane, Queensland, Australia</td>\n",
       "      <td>-27.468968</td>\n",
       "      <td>153.023499</td>\n",
       "      <td>City of Brisbane, Queensland, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Burlington</td>\n",
       "      <td>Burlington, Ontario, Canada</td>\n",
       "      <td>Burlington, Ontario, Canada</td>\n",
       "      <td>43.324892</td>\n",
       "      <td>-79.796684</td>\n",
       "      <td>Burlington, Halton Region, Golden Horseshoe, O...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Montreal</td>\n",
       "      <td>Montreal, Quebec, Canada</td>\n",
       "      <td>Montreal, Quebec, Canada</td>\n",
       "      <td>45.503182</td>\n",
       "      <td>-73.569806</td>\n",
       "      <td>Montral, Agglomration de Montral, Montral ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Deutschland</td>\n",
       "      <td>Berlin</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>Berlin, Germany</td>\n",
       "      <td>52.510885</td>\n",
       "      <td>13.398937</td>\n",
       "      <td>Berlin, Pankow, Deutschland</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>United States</td>\n",
       "      <td>Union City</td>\n",
       "      <td>Union City, NJ, United States</td>\n",
       "      <td>Union City, NJ, United States</td>\n",
       "      <td>40.779545</td>\n",
       "      <td>-74.023751</td>\n",
       "      <td>Union City, Hudson County, New Jersey, 07087, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>United States</td>\n",
       "      <td>Van Nuys</td>\n",
       "      <td>Van Nuys, California, U.S.</td>\n",
       "      <td>Van Nuys, California, US</td>\n",
       "      <td>34.186619</td>\n",
       "      <td>-118.448667</td>\n",
       "      <td>Van Nuys Neighborhood Council District, Los An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>United States</td>\n",
       "      <td>Wallingford</td>\n",
       "      <td>Wallingford, Connecticut, United States</td>\n",
       "      <td>Wallingford, Connecticut, United States</td>\n",
       "      <td>41.457042</td>\n",
       "      <td>-72.823155</td>\n",
       "      <td>Wallingford, South Central Connecticut Plannin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>United States</td>\n",
       "      <td>Washington</td>\n",
       "      <td>Washington, DC, United States</td>\n",
       "      <td>Washington, DC, United States</td>\n",
       "      <td>38.895037</td>\n",
       "      <td>-77.036543</td>\n",
       "      <td>Washington, District of Columbia, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>United States</td>\n",
       "      <td>Wisconsin</td>\n",
       "      <td>Wisconsin, United States</td>\n",
       "      <td>Wisconsin, United States</td>\n",
       "      <td>44.430898</td>\n",
       "      <td>-89.688464</td>\n",
       "      <td>Wisconsin, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          country         city                                   origin  \\\n",
       "0       Australia     Brisbane                   Brisbane, Australia[1]   \n",
       "1       Australia     Brisbane          Brisbane, Queensland, Australia   \n",
       "2          Canada   Burlington              Burlington, Ontario, Canada   \n",
       "3          Canada     Montreal                 Montreal, Quebec, Canada   \n",
       "4     Deutschland       Berlin                          Berlin, Germany   \n",
       "..            ...          ...                                      ...   \n",
       "81  United States   Union City            Union City, NJ, United States   \n",
       "82  United States     Van Nuys               Van Nuys, California, U.S.   \n",
       "83  United States  Wallingford  Wallingford, Connecticut, United States   \n",
       "84  United States   Washington            Washington, DC, United States   \n",
       "85  United States    Wisconsin                 Wisconsin, United States   \n",
       "\n",
       "                               origin_clean   latitude   longitude  \\\n",
       "0                       Brisbane, Australia -27.468968  153.023499   \n",
       "1           Brisbane, Queensland, Australia -27.468968  153.023499   \n",
       "2               Burlington, Ontario, Canada  43.324892  -79.796684   \n",
       "3                  Montreal, Quebec, Canada  45.503182  -73.569806   \n",
       "4                           Berlin, Germany  52.510885   13.398937   \n",
       "..                                      ...        ...         ...   \n",
       "81            Union City, NJ, United States  40.779545  -74.023751   \n",
       "82                 Van Nuys, California, US  34.186619 -118.448667   \n",
       "83  Wallingford, Connecticut, United States  41.457042  -72.823155   \n",
       "84            Washington, DC, United States  38.895037  -77.036543   \n",
       "85                 Wisconsin, United States  44.430898  -89.688464   \n",
       "\n",
       "                                              address  \n",
       "0             City of Brisbane, Queensland, Australia  \n",
       "1             City of Brisbane, Queensland, Australia  \n",
       "2   Burlington, Halton Region, Golden Horseshoe, O...  \n",
       "3   Montral, Agglomration de Montral, Montral ...  \n",
       "4                         Berlin, Pankow, Deutschland  \n",
       "..                                                ...  \n",
       "81  Union City, Hudson County, New Jersey, 07087, ...  \n",
       "82  Van Nuys Neighborhood Council District, Los An...  \n",
       "83  Wallingford, South Central Connecticut Plannin...  \n",
       "84    Washington, District of Columbia, United States  \n",
       "85                           Wisconsin, United States  \n",
       "\n",
       "[86 rows x 7 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates = get_coordinates_geopy(df_new_artists)\n",
    "df_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_coordinates_scraped: (2580, 7)\n",
      "\n",
      "Found 55 duplicates:\n",
      "                  city         country\n",
      "11            Brisbane       Australia\n",
      "63          Burlington          Canada\n",
      "93            Montreal          Canada\n",
      "146             Berlin     Deutschland\n",
      "535          Camberley  United Kingdom\n",
      "1134           Atlanta   United States\n",
      "1135           Atlanta   United States\n",
      "1151            Austin   United States\n",
      "1173          Bay Area   United States\n",
      "1264          Brooklyn   United States\n",
      "1285        California   United States\n",
      "1336           Chicago   United States\n",
      "1337           Chicago   United States\n",
      "1338           Chicago   United States\n",
      "1340             Chico   United States\n",
      "1369          Columbia   United States\n",
      "1376          Columbus   United States\n",
      "1442           Detroit   United States\n",
      "1455            Durham   United States\n",
      "1493        Evansville   United States\n",
      "1649      Indianapolis   United States\n",
      "1684       Kansas City   United States\n",
      "1731         Las Vegas   United States\n",
      "1732         Las Vegas   United States\n",
      "1801       Los Angeles   United States\n",
      "1802       Los Angeles   United States\n",
      "1803       Los Angeles   United States\n",
      "1826           Madison   United States\n",
      "1880             Miami   United States\n",
      "1905       Minneapolis   United States\n",
      "1906       Minneapolis   United States\n",
      "1958         Nashville   United States\n",
      "2008     New York City   United States\n",
      "2009     New York City   United States\n",
      "2046           Oakland   United States\n",
      "2074     Orange County   United States\n",
      "2132      Philadelphia   United States\n",
      "2133      Philadelphia   United States\n",
      "2177          Portland   United States\n",
      "2178          Portland   United States\n",
      "2228          Redlands   United States\n",
      "2256         Riverside   United States\n",
      "2262         Rochester   United States\n",
      "2268          Rockford   United States\n",
      "2269          Rockford   United States\n",
      "2290        Sacramento   United States\n",
      "2314  San Diego County   United States\n",
      "2351        Santa Cruz   United States\n",
      "2375           Seattle   United States\n",
      "2417          St Louis   United States\n",
      "2447          Syracuse   United States\n",
      "2451            Tacoma   United States\n",
      "2460             Tampa   United States\n",
      "2522          Van Nuys   United States\n",
      "2552        Washington   United States\n",
      "\n",
      "Resulting dataset: (2611, 7)\n",
      "Merged artists with coordinates! Found 31 new locations\n",
      "df_coordinates_concat exported to .csv\n"
     ]
    }
   ],
   "source": [
    "export_coordinates_concat(df_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to a .csv file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6308</th>\n",
       "      <td>Des Ark</td>\n",
       "      <td>United States</td>\n",
       "      <td>Durham</td>\n",
       "      <td>35.996653</td>\n",
       "      <td>-78.901805</td>\n",
       "      <td>Durham, Durham County, North Carolina, United ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6309</th>\n",
       "      <td>The Taste Of Blood</td>\n",
       "      <td>United States</td>\n",
       "      <td>Santa Cruz</td>\n",
       "      <td>37.050096</td>\n",
       "      <td>-121.990590</td>\n",
       "      <td>Santa Cruz County, California, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6310</th>\n",
       "      <td>Inferi</td>\n",
       "      <td>United States</td>\n",
       "      <td>Nashville</td>\n",
       "      <td>36.162277</td>\n",
       "      <td>-86.774298</td>\n",
       "      <td>Nashville, Davidson County, Middle Tennessee, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6311</th>\n",
       "      <td>Half Waif</td>\n",
       "      <td>United States</td>\n",
       "      <td>Kingston</td>\n",
       "      <td>41.926810</td>\n",
       "      <td>-73.995270</td>\n",
       "      <td>City of Kingston, Ulster County, New York, 124...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6312</th>\n",
       "      <td>INDK</td>\n",
       "      <td>United States</td>\n",
       "      <td>New York City</td>\n",
       "      <td>40.712728</td>\n",
       "      <td>-74.006015</td>\n",
       "      <td>City of New York, New York, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist        country           city   latitude   longitude  \\\n",
       "6308             Des Ark  United States         Durham  35.996653  -78.901805   \n",
       "6309  The Taste Of Blood  United States     Santa Cruz  37.050096 -121.990590   \n",
       "6310              Inferi  United States      Nashville  36.162277  -86.774298   \n",
       "6311           Half Waif  United States       Kingston  41.926810  -73.995270   \n",
       "6312                INDK  United States  New York City  40.712728  -74.006015   \n",
       "\n",
       "                                                address  \n",
       "6308  Durham, Durham County, North Carolina, United ...  \n",
       "6309       Santa Cruz County, California, United States  \n",
       "6310  Nashville, Davidson County, Middle Tennessee, ...  \n",
       "6311  City of Kingston, Ulster County, New York, 124...  \n",
       "6312          City of New York, New York, United States  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with the dataframe containing all the artists and their origins\n",
    "df_artists_origins_coordinates_concat = merge_origins_coordinates(df_new_artists)\n",
    "df_artists_origins_coordinates_concat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6313, 6)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins_coordinates_concat = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')\n",
    "df_artists_origins_coordinates_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "brittish_cities = df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United Kingdom']\n",
    "american_cities = df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "United States     3703\n",
      "United Kingdom    1490\n",
      "Canada             207\n",
      "Sverige            148\n",
      "Australia          127\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "order = df_artists_origins_coordinates_concat['country'].value_counts().index\n",
    "print(df_artists_origins_coordinates_concat['country'].value_counts().head())\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.countplot(df_artists_origins_coordinates_concat['country'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 Brittish artists\n",
      "428 Brittish cities\n",
      "\n",
      "city\n",
      "London         402\n",
      "Birmingham      40\n",
      "Glasgow         40\n",
      "Manchester      39\n",
      "Brighton        38\n",
      "Leeds           36\n",
      "Liverpool       30\n",
      "Bristol         25\n",
      "Nottingham      22\n",
      "Sheffield       19\n",
      "Edinburgh       16\n",
      "Cardiff         16\n",
      "Cambridge       15\n",
      "Reading         13\n",
      "Southampton     13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{brittish_cities.shape[0]} Brittish artists\")\n",
    "order = brittish_cities['city'].value_counts().index\n",
    "print(f\"{brittish_cities['city'].nunique()} Brittish cities\\n\")\n",
    "print(brittish_cities['city'].value_counts().head(15))\n",
    "\n",
    "# plt.figure(figsize=(9,45))\n",
    "# sns.countplot(brittish_cities['city'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3703 American artists\n",
      "868 American cities\n",
      "\n",
      "city\n",
      "Los Angeles      341\n",
      "New York City    182\n",
      "Chicago          138\n",
      "San Francisco    112\n",
      "Seattle           89\n",
      "Boston            84\n",
      "Brooklyn          74\n",
      "Portland          63\n",
      "Philadelphia      61\n",
      "San Diego         56\n",
      "Atlanta           43\n",
      "Washington        41\n",
      "Austin            41\n",
      "Nashville         38\n",
      "New York          38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{american_cities.shape[0]} American artists\")\n",
    "order = american_cities['city'].value_counts().index\n",
    "print(f\"{american_cities['city'].nunique()} American cities\\n\")\n",
    "print(american_cities['city'].value_counts().head(15))\n",
    "\n",
    "# plt.figure(figsize=(5,55))\n",
    "# sns.countplot(df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United States']['city'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
