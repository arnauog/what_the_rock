{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import time\n",
    "import re\n",
    "\n",
    "# pip install geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from geopy_functions import *\n",
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56660, 13): df_uk_masters\n",
      "(48690, 13): df_us_masters\n",
      "(18207, 13): df_us_new_masters\n",
      "(51222, 5): df_ratings_20\n",
      "(11920, 13): df_masters_blended\n"
     ]
    }
   ],
   "source": [
    "# import the dataframes\n",
    "df_uk_masters = pd.read_csv('Datasets/df_uk_masters.csv')                         # all the albums from the UK\n",
    "df_us_masters = pd.read_csv('Datasets/df_us_masters.csv')                         # albums from the US until 1996, 1998 and 2000\n",
    "df_us_new_masters = pd.read_csv('Datasets/df_us_new_masters.csv')                         # albums from the US from 1997, 1999 and 2001\n",
    "df_ratings_20 = pd.read_csv('Datasets/df_ratings_20.csv', keep_default_na=False)  # albums with >= 20 votes, mostly from rock, worldwide\n",
    "df_masters_blended = pd.read_csv('Datasets/df_masters_blended.csv')               # albums from the UK and US (and others) with >= 10 votes \n",
    "df_artists_origins_coordinates = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')               # merge of df_masters_blended with their locations\n",
    "\n",
    "# print information\n",
    "print(f'{df_uk_masters.shape}: df_uk_masters')\n",
    "print(f'{df_us_masters.shape}: df_us_masters')\n",
    "print(f'{df_us_new_masters.shape}: df_us_new_masters')\n",
    "print(f'{df_ratings_20.shape}: df_ratings_20')\n",
    "print(f'{df_masters_blended.shape}: df_masters_blended')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coses pendents, artistes a revisar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi ha dos grups que es diuen 'Embrace', un de UK i un de USA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**YOB** te **8** albums a Sputnik ``df_ratings_20``, però nomes **2** a Discogs ``df_masters_blended``, tot i que és una banda de UK, ja que no hi ha releases a UK d'aquests 6 altres àlbums \n",
    "\n",
    "Si apareixen al df de US, hauré de fer un concat/merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2241</th>\n",
       "      <td>563922</td>\n",
       "      <td>729329</td>\n",
       "      <td>6054020</td>\n",
       "      <td>US</td>\n",
       "      <td>YOB</td>\n",
       "      <td>Clearing The Path To Ascend</td>\n",
       "      <td>2014</td>\n",
       "      <td>62.53</td>\n",
       "      <td>4</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Doom Metal', 'Sludge Metal']</td>\n",
       "      <td>Yob is an American stoner/doom metal band from...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5833</th>\n",
       "      <td>563922</td>\n",
       "      <td>129480</td>\n",
       "      <td>2806549</td>\n",
       "      <td>US</td>\n",
       "      <td>YOB</td>\n",
       "      <td>Catharsis</td>\n",
       "      <td>2003</td>\n",
       "      <td>49.07</td>\n",
       "      <td>3</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Doom Metal']</td>\n",
       "      <td>Yob is an American stoner/doom metal band from...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_id  master_id  main_release_id release_country artist  \\\n",
       "2241     563922     729329          6054020              US    YOB   \n",
       "5833     563922     129480          2806549              US    YOB   \n",
       "\n",
       "                            title  year  album_length  tracks release_type  \\\n",
       "2241  Clearing The Path To Ascend  2014         62.53       4    ['Album']   \n",
       "5833                    Catharsis  2003         49.07       3    ['Album']   \n",
       "\n",
       "        genres                          styles  \\\n",
       "2241  ['Rock']  ['Doom Metal', 'Sludge Metal']   \n",
       "5833  ['Rock']                  ['Doom Metal']   \n",
       "\n",
       "                                         artist_profile  \n",
       "2241  Yob is an American stoner/doom metal band from...  \n",
       "5833  Yob is an American stoner/doom metal band from...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended[df_masters_blended['artist']=='YOB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2485</th>\n",
       "      <td>3646</td>\n",
       "      <td>YOB</td>\n",
       "      <td>The Illusion Of Motion</td>\n",
       "      <td>3.94</td>\n",
       "      <td>183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15507</th>\n",
       "      <td>29146</td>\n",
       "      <td>YOB</td>\n",
       "      <td>The Unreal Never Lived</td>\n",
       "      <td>4.06</td>\n",
       "      <td>225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19335</th>\n",
       "      <td>39606</td>\n",
       "      <td>YOB</td>\n",
       "      <td>The Great Cessation</td>\n",
       "      <td>3.90</td>\n",
       "      <td>205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24401</th>\n",
       "      <td>60240</td>\n",
       "      <td>YOB</td>\n",
       "      <td>Elaborations Of Carbon</td>\n",
       "      <td>3.42</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24402</th>\n",
       "      <td>60241</td>\n",
       "      <td>YOB</td>\n",
       "      <td>Catharsis</td>\n",
       "      <td>3.99</td>\n",
       "      <td>140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28092</th>\n",
       "      <td>80046</td>\n",
       "      <td>YOB</td>\n",
       "      <td>Atma</td>\n",
       "      <td>3.78</td>\n",
       "      <td>259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36277</th>\n",
       "      <td>163668</td>\n",
       "      <td>YOB</td>\n",
       "      <td>Clearing The Path To Ascend</td>\n",
       "      <td>3.92</td>\n",
       "      <td>331</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43372</th>\n",
       "      <td>282109</td>\n",
       "      <td>YOB</td>\n",
       "      <td>Our Raw Heart</td>\n",
       "      <td>3.87</td>\n",
       "      <td>295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       album_id artist                        title  rating  votes\n",
       "2485       3646    YOB       The Illusion Of Motion    3.94    183\n",
       "15507     29146    YOB       The Unreal Never Lived    4.06    225\n",
       "19335     39606    YOB          The Great Cessation    3.90    205\n",
       "24401     60240    YOB       Elaborations Of Carbon    3.42     73\n",
       "24402     60241    YOB                    Catharsis    3.99    140\n",
       "28092     80046    YOB                         Atma    3.78    259\n",
       "36277    163668    YOB  Clearing The Path To Ascend    3.92    331\n",
       "43372    282109    YOB                Our Raw Heart    3.87    295"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_20[df_ratings_20['artist']=='YOB']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations Wikipedia scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Datasets/df_rock_ratings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets/df_rock_ratings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, keep_default_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m artists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m albums\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Datasets/df_rock_ratings.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/df_rock_ratings.csv', keep_default_na=False)\n",
    "\n",
    "print(f\"{df['artist'].nunique()} artists\")\n",
    "print(f\"{df.shape[0]} albums\")\n",
    "print(f\"Average of {round(df.shape[0] / df['artist'].nunique(), 2)} albums per artist in the subset with the (mostly UK) albums with more than 10 votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3823 artists\n",
      "9380 albums\n",
      "Average of 2.45 albums per artist in the subset with the (mostly UK) albums with more than 20 votes\n"
     ]
    }
   ],
   "source": [
    "df_20 = pd.read_csv('Datasets/df_rock_ratings_20.csv', keep_default_na=False)\n",
    "\n",
    "print(f\"{df_20['artist'].nunique()} artists\")\n",
    "print(f\"{df_20.shape[0]} albums\")\n",
    "print(f\"Average of {round(df_20.shape[0] / df_20['artist'].nunique(), 2)} albums per artist in the subset with the (mostly UK) albums with more than 20 votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51252, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ratings_20 = pd.read_csv('Datasets/df_ratings_20.csv')\n",
    "df_ratings_20.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10580</th>\n",
       "      <td>The 1975</td>\n",
       "      <td>A Brief Inquiry into Online Relationships</td>\n",
       "      <td>2018</td>\n",
       "      <td>58.43</td>\n",
       "      <td>15</td>\n",
       "      <td>['Rock', 'Pop']</td>\n",
       "      <td>['Indie Rock', 'Alternative Rock', 'Indie Pop']</td>\n",
       "      <td>UK &amp; Europe</td>\n",
       "      <td>British indie rock band. \\r\\n\\r\\nPop-rock band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>Le Butcherettes</td>\n",
       "      <td>A Raw Youth</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>Formed by Teri Gender Bender and Auryn Jolene ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>John Fogerty</td>\n",
       "      <td>Centerfield</td>\n",
       "      <td>1985</td>\n",
       "      <td>35.33</td>\n",
       "      <td>9</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Pop Rock', 'Folk Rock', 'Country Rock']</td>\n",
       "      <td>US</td>\n",
       "      <td>American musician, songwriter, and guitarist (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>L7</td>\n",
       "      <td>The Beauty Process: Triple Platinum</td>\n",
       "      <td>1997</td>\n",
       "      <td>41.57</td>\n",
       "      <td>12</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Punk', 'Grunge']</td>\n",
       "      <td>US</td>\n",
       "      <td>American grunge punk/alternative rock band fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>The Fall</td>\n",
       "      <td>Are You Are Missing Winner</td>\n",
       "      <td>2001</td>\n",
       "      <td>47.68</td>\n",
       "      <td>10</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Garage Rock', 'Punk', 'Rockabilly']</td>\n",
       "      <td>UK</td>\n",
       "      <td>Post-punk band from Greater Manchester, UK. 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist                                      title  year  \\\n",
       "10580         The 1975  A Brief Inquiry into Online Relationships  2018   \n",
       "9889   Le Butcherettes                                A Raw Youth  2015   \n",
       "6394      John Fogerty                                Centerfield  1985   \n",
       "4498                L7        The Beauty Process: Triple Platinum  1997   \n",
       "5742          The Fall                 Are You Are Missing Winner  2001   \n",
       "\n",
       "       album_length  tracks           genres  \\\n",
       "10580         58.43      15  ['Rock', 'Pop']   \n",
       "9889           0.00      12         ['Rock']   \n",
       "6394          35.33       9         ['Rock']   \n",
       "4498          41.57      12         ['Rock']   \n",
       "5742          47.68      10         ['Rock']   \n",
       "\n",
       "                                                styles release_country  \\\n",
       "10580  ['Indie Rock', 'Alternative Rock', 'Indie Pop']     UK & Europe   \n",
       "9889                                                []              US   \n",
       "6394         ['Pop Rock', 'Folk Rock', 'Country Rock']              US   \n",
       "4498                                ['Punk', 'Grunge']              US   \n",
       "5742             ['Garage Rock', 'Punk', 'Rockabilly']              UK   \n",
       "\n",
       "                                          artist_profile  \n",
       "10580  British indie rock band. \\r\\n\\r\\nPop-rock band...  \n",
       "9889   Formed by Teri Gender Bender and Auryn Jolene ...  \n",
       "6394   American musician, songwriter, and guitarist (...  \n",
       "4498   American grunge punk/alternative rock band fro...  \n",
       "5742   Post-punk band from Greater Manchester, UK. 19...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9616"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = df['artist'].unique()\n",
    "len(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Life at These Speeds'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[4155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aabsinthe'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist = \"AABSINTHE\"\n",
    "name_changed = artist.title().replace(' ', '_')\n",
    "name_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres\n"
     ]
    }
   ],
   "source": [
    "artist = \"John Grant\"\n",
    "name_changed = artist.replace(' ', '_')\n",
    "name_changed_band = artist.replace(' ', '_') + ('_(band)')\n",
    "name_changed_musician = name_changed + ('_(musician)')\n",
    "\n",
    "url = f\"https://en.wikipedia.org/wiki/{name_changed_musician}\"\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "try:\n",
    "    text = table[0].text\n",
    "\n",
    "    # Step 1: Extract the part after 'Born'\n",
    "    after_born = text.split(\"Born\", 1)[1]\n",
    "\n",
    "    text_age = re.search(\"aged\", after_born)\n",
    "\n",
    "    if text_age:\n",
    "        # This means the musician is dead\n",
    "        location = re.split(r'(19\\d{2})', after_born)[4].split('Died')[0].strip()\n",
    "    else:\n",
    "        try:\n",
    "            text = re.split(r'(19\\d{2})', after_born)[4].split(')')[1]\n",
    "\n",
    "            if \"Other\\xa0names\" in text:\n",
    "                location = text.split('Other\\xa0names')[0]\n",
    "            else:\n",
    "                if \"Citizenship\" in text:\n",
    "                    location = text.split('Citizenship')[0]\n",
    "                else:\n",
    "                    if \"Genres\" in text:\n",
    "                        location = text.split('Genres')[0]\n",
    "                        print('Genres')\n",
    "                    else:\n",
    "                        if \"Occupations\" in text:\n",
    "                            location = text.split('Occupations')[0]\n",
    "                            print('Occupations')\n",
    "                        else:\n",
    "                            location = np.nan\n",
    "        except:  \n",
    "            location = np.nan\n",
    "except:\n",
    "    print('fuck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buchanan, Michigan, U.S.'"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John_Grant_(musician)'"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_changed_musician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = \"Stone Gossard\"\n",
    "name_changed = artist.replace(' ', '_')\n",
    "name_changed_band = artist.replace(' ', '_') + ('_(band)')\n",
    "\n",
    "url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "try:\n",
    "    location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "\n",
    "# save info in lists\n",
    "    print('origin')\n",
    "\n",
    "except:\n",
    "    text = table[0].text\n",
    "\n",
    "    # Step 1: Extract the part after 'Born'\n",
    "    after_born = text.split(\"Born\", 1)[1]\n",
    "\n",
    "    text_age = re.search(\"aged\", after_born)\n",
    "\n",
    "    if text_age:\n",
    "        # This means the artist is dead\n",
    "        print('dead')\n",
    "        location = re.split(r'(19\\d{2})', after_born)[4].split('Died')[0].strip()\n",
    "    else:\n",
    "        try:\n",
    "            text = re.split(r'(19\\d{2})', after_born)[4].split(')')[1]\n",
    "\n",
    "            if \"Other\\xa0names\" in text:\n",
    "                location = text.split('Other\\xa0names')[0]\n",
    "            else:\n",
    "                if \"Citizenship\" in text:\n",
    "                    location = text.split('Citizenship')[0]\n",
    "                else:\n",
    "                    if \"Occupations\" in text:\n",
    "                        location = text.split('Occupations')[0]\n",
    "                    else:\n",
    "                        if \"Genres\" in text:\n",
    "                            location = text.split('Genres')[0]\n",
    "                            print(repr(location))\n",
    "                        else:\n",
    "                            location = np.nan\n",
    "        except:  \n",
    "            location = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seattle, Washington, U.S.GenresAlternative rockgrungeglam punkpunk rockhard rockheavy metalglam metalOccupationsMusiciansongwriterInstrumentsGuitarvocalsYears active'"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seattle, Washington, U.S.GenresAlternative rockgrungeglam punkpunk rockhard rockheavy metalglam metal'"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>Less Than Jake</td>\n",
       "      <td>Losing Streak</td>\n",
       "      <td>3.90</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Sparta</td>\n",
       "      <td>Wiretap Scars</td>\n",
       "      <td>3.79</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Muse</td>\n",
       "      <td>Absolution</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>Muse</td>\n",
       "      <td>Showbiz</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>Finch</td>\n",
       "      <td>What It Is to Burn</td>\n",
       "      <td>3.69</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   album_id          artist               album  rating  votes\n",
       "0        37  Less Than Jake       Losing Streak    3.90    414\n",
       "1        40          Sparta       Wiretap Scars    3.79    431\n",
       "2        41            Muse          Absolution    3.99   4411\n",
       "3        42            Muse             Showbiz    3.50   2181\n",
       "4        45           Finch  What It Is to Burn    3.69    864"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_artists_origins``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3251, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "df_artists_origins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sparta</td>\n",
       "      <td>El Paso, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muse</td>\n",
       "      <td>Teignmouth, Devon, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finch</td>\n",
       "      <td>Temecula, California, Estados Unidos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transplants</td>\n",
       "      <td>Los Angeles, California, United States[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rooney</td>\n",
       "      <td>Los Angeles, California, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist                                     origin\n",
       "0       Sparta                             El Paso, Texas\n",
       "1         Muse                 Teignmouth, Devon, England\n",
       "2        Finch       Temecula, California, Estados Unidos\n",
       "3  Transplants  Los Angeles, California, United States[1]\n",
       "4       Rooney              Los Angeles, California, U.S."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins[df_artists_origins['origin']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists = df_artists_origins[df_artists_origins['origin']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>Son of Dork</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Mojave 3</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>Crippled Black Phoenix</td>\n",
       "      <td>Bristol, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>This Mortal Coil</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>Jade Warrior</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>The Waterboys</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>Blackmore's Night</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>Atomic Rooster</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>The Nefilim</td>\n",
       "      <td>Lambeth, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>Black Spiders</td>\n",
       "      <td>Sheffield, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>Brontide</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>Gilgamesh</td>\n",
       "      <td>Hampstead, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>Young Legionnaire</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>The Deviants</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>Head of David</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>Quintessence</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      artist                                 origin\n",
       "1059             Son of Dork                        London, England\n",
       "1192                Mojave 3                        London, England\n",
       "1326  Crippled Black Phoenix                       Bristol, England\n",
       "1597        This Mortal Coil                    Wandsworth, England\n",
       "2191                 Arcadia                        London, England\n",
       "2300            Jade Warrior                        London, England\n",
       "2348           The Waterboys                        London, England\n",
       "2469       Blackmore's Night         Mount Sinai, NY, United States\n",
       "2556          Atomic Rooster                        London, England\n",
       "2609             The Nefilim                       Lambeth, England\n",
       "2715           Black Spiders                     Sheffield, England\n",
       "2822                Brontide                        London, England\n",
       "2878               Gilgamesh                     Hampstead, England\n",
       "2914       Young Legionnaire                        London, England\n",
       "2924            The Deviants        Ladbroke Grove, London, England\n",
       "2956           Head of David  Dudley, West Midlands, United Kingdom\n",
       "3157            Quintessence                        London, England"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Son of Dork\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Mojave 3\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Crippled Black Phoenix\", \"Bristol, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"This Mortal Coil\", \"Wandsworth, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Arcadia\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Jade Warrior\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Waterboys\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Blackmore's Night\", \"Mount Sinai, NY, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Atomic Rooster\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Nefilim\", \"Lambeth, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Black Spiders\", \"Sheffield, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Brontide\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Gilgamesh\", \"Hampstead, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Young Legionnaire\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Deviants\", \"Ladbroke Grove, London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Head of David\", \"Dudley, West Midlands, United Kingdom\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Quintessence\", \"London, England\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formed in 1969, they played a blend of jazz, progressive rock, Indian Music, and new age rock.   Members included:\n",
      "Sambhu Babaji : Bass  Dave Codling : Guitar  Shiva Shankar Jones : Keyboards, Vocals  Jake Milton : Drums  Alan Mostert\n",
      ": Guitar  Raja Ram : Flute, Piano, Vocals\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[8016]['artist_profile']\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>styles</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>1969</td>\n",
       "      <td>Quintessence</td>\n",
       "      <td>In Blissful Company</td>\n",
       "      <td>3.88</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['Psychedelic Rock']</td>\n",
       "      <td>UK</td>\n",
       "      <td>Formed in 1969, they played a blend of jazz, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year        artist                title  rating  votes  album_length  \\\n",
       "8016  1969  Quintessence  In Blissful Company    3.88     16           0.0   \n",
       "\n",
       "      tracks                styles release_country  \\\n",
       "8016       8  ['Psychedelic Rock']              UK   \n",
       "\n",
       "                                         artist_profile  \n",
       "8016  Formed in 1969, they played a blend of jazz, p...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Quintessence\".strip()].sort_values('votes', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3234, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = df_artists_origins[df_artists_origins['origin']!='United Kingdom']\n",
    "df_artists_origins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists_origins.to_csv('Datasets/df_artists_origins.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_artists_origins_concat exported to .csv\n",
      "(3251, 2)\n"
     ]
    }
   ],
   "source": [
    "export_artists_origins_concat(df_new_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 - London, Greater London, England, United Kingdom\n",
      "2/9 - Bristol, City of Bristol, West of England, England, United Kingdom\n",
      "3/9 - Wandsworth, London Borough of Wandsworth, London, Greater London, England, SW18 1UJ, United Kingdom\n",
      "4/9 - Mount Sinai, Miller Place, Town of Brookhaven, Suffolk County, New York, 11766, United States\n",
      "5/9 - Lambeth, London Borough of Lambeth, London, Greater London, England, SE1 7JW, United Kingdom\n",
      "6/9 - Sheffield, South Yorkshire, England, United Kingdom\n",
      "7/9 - Hampstead, Greater London, England, NW3 1QG, United Kingdom\n",
      "8/9 - Ladbroke Grove, Westway, Lancaster West Estate, North Kensington, Royal Borough of Kensington and Chelsea, London, Greater London, England, W10 5YG, United Kingdom\n",
      "9/9 - Dudley, West Midlands, England, United Kingdom\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Bristol, England</td>\n",
       "      <td>Bristol, England</td>\n",
       "      <td>51.453802</td>\n",
       "      <td>-2.597298</td>\n",
       "      <td>Bristol, City of Bristol, West of England, Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Dudley</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "      <td>52.511083</td>\n",
       "      <td>-2.081681</td>\n",
       "      <td>Dudley, West Midlands, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Hampstead</td>\n",
       "      <td>Hampstead, England</td>\n",
       "      <td>Hampstead, England</td>\n",
       "      <td>51.556530</td>\n",
       "      <td>-0.178301</td>\n",
       "      <td>Hampstead, Greater London, England, NW3 1QG, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Ladbroke Grove</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "      <td>51.517264</td>\n",
       "      <td>-0.211102</td>\n",
       "      <td>Ladbroke Grove, Westway, Lancaster West Estate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Lambeth, England</td>\n",
       "      <td>Lambeth, England</td>\n",
       "      <td>51.495211</td>\n",
       "      <td>-0.116335</td>\n",
       "      <td>Lambeth, London Borough of Lambeth, London, Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>London, England</td>\n",
       "      <td>London, England</td>\n",
       "      <td>51.507446</td>\n",
       "      <td>-0.127765</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>Sheffield, England</td>\n",
       "      <td>Sheffield, England</td>\n",
       "      <td>53.380663</td>\n",
       "      <td>-1.470228</td>\n",
       "      <td>Sheffield, South Yorkshire, England, United Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "      <td>51.457027</td>\n",
       "      <td>-0.193261</td>\n",
       "      <td>Wandsworth, London Borough of Wandsworth, Lond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>United States</td>\n",
       "      <td>Mount Sinai</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "      <td>40.941066</td>\n",
       "      <td>-73.019455</td>\n",
       "      <td>Mount Sinai, Miller Place, Town of Brookhaven,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country            city                                 origin  \\\n",
       "0  United Kingdom         Bristol                       Bristol, England   \n",
       "1  United Kingdom          Dudley  Dudley, West Midlands, United Kingdom   \n",
       "2  United Kingdom       Hampstead                     Hampstead, England   \n",
       "3  United Kingdom  Ladbroke Grove        Ladbroke Grove, London, England   \n",
       "4  United Kingdom         Lambeth                       Lambeth, England   \n",
       "5  United Kingdom          London                        London, England   \n",
       "6  United Kingdom       Sheffield                     Sheffield, England   \n",
       "7  United Kingdom      Wandsworth                    Wandsworth, England   \n",
       "8   United States     Mount Sinai         Mount Sinai, NY, United States   \n",
       "\n",
       "                            origin_clean   latitude  longitude  \\\n",
       "0                       Bristol, England  51.453802  -2.597298   \n",
       "1  Dudley, West Midlands, United Kingdom  52.511083  -2.081681   \n",
       "2                     Hampstead, England  51.556530  -0.178301   \n",
       "3        Ladbroke Grove, London, England  51.517264  -0.211102   \n",
       "4                       Lambeth, England  51.495211  -0.116335   \n",
       "5                        London, England  51.507446  -0.127765   \n",
       "6                     Sheffield, England  53.380663  -1.470228   \n",
       "7                    Wandsworth, England  51.457027  -0.193261   \n",
       "8         Mount Sinai, NY, United States  40.941066 -73.019455   \n",
       "\n",
       "                                             address  \n",
       "0  Bristol, City of Bristol, West of England, Eng...  \n",
       "1     Dudley, West Midlands, England, United Kingdom  \n",
       "2  Hampstead, Greater London, England, NW3 1QG, U...  \n",
       "3  Ladbroke Grove, Westway, Lancaster West Estate...  \n",
       "4  Lambeth, London Borough of Lambeth, London, Gr...  \n",
       "5    London, Greater London, England, United Kingdom  \n",
       "6  Sheffield, South Yorkshire, England, United Ki...  \n",
       "7  Wandsworth, London Borough of Wandsworth, Lond...  \n",
       "8  Mount Sinai, Miller Place, Town of Brookhaven,...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates = get_coordinates_geopy(df_new_artists)\n",
    "df_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_coordinates``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527, 7)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "df_coordinates_scraped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Adelaide, South Australia, Australia</td>\n",
       "      <td>Adelaide, South Australia, Australia</td>\n",
       "      <td>-34.928181</td>\n",
       "      <td>138.599931</td>\n",
       "      <td>Adelaide, Adelaide City Council, South Austral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Adelaide, South Australia</td>\n",
       "      <td>Adelaide, South Australia</td>\n",
       "      <td>-34.928181</td>\n",
       "      <td>138.599931</td>\n",
       "      <td>Adelaide, Adelaide City Council, South Austral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Blue Mountains</td>\n",
       "      <td>Blue Mountains, NSW, Australia</td>\n",
       "      <td>Blue Mountains, NSW, Australia</td>\n",
       "      <td>-33.609741</td>\n",
       "      <td>150.405224</td>\n",
       "      <td>Blue Mountains, New South Wales, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane, Queensland, Australia</td>\n",
       "      <td>Brisbane, Queensland, Australia</td>\n",
       "      <td>-27.468968</td>\n",
       "      <td>153.023499</td>\n",
       "      <td>City of Brisbane, Queensland, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Byron Bay</td>\n",
       "      <td>Byron Bay, New South Wales, Australia</td>\n",
       "      <td>Byron Bay, New South Wales, Australia</td>\n",
       "      <td>-28.648333</td>\n",
       "      <td>153.617778</td>\n",
       "      <td>Byron Bay, Byron Shire Council, New South Wale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country            city                                 origin  \\\n",
       "0  Australia        Adelaide   Adelaide, South Australia, Australia   \n",
       "1  Australia        Adelaide              Adelaide, South Australia   \n",
       "2  Australia  Blue Mountains         Blue Mountains, NSW, Australia   \n",
       "3  Australia        Brisbane        Brisbane, Queensland, Australia   \n",
       "4  Australia       Byron Bay  Byron Bay, New South Wales, Australia   \n",
       "\n",
       "                            origin_clean   latitude   longitude  \\\n",
       "0   Adelaide, South Australia, Australia -34.928181  138.599931   \n",
       "1              Adelaide, South Australia -34.928181  138.599931   \n",
       "2         Blue Mountains, NSW, Australia -33.609741  150.405224   \n",
       "3        Brisbane, Queensland, Australia -27.468968  153.023499   \n",
       "4  Byron Bay, New South Wales, Australia -28.648333  153.617778   \n",
       "\n",
       "                                             address  \n",
       "0  Adelaide, Adelaide City Council, South Austral...  \n",
       "1  Adelaide, Adelaide City Council, South Austral...  \n",
       "2         Blue Mountains, New South Wales, Australia  \n",
       "3            City of Brisbane, Queensland, Australia  \n",
       "4  Byron Bay, Byron Shire Council, New South Wale...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>54.702354</td>\n",
       "      <td>-3.276575</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            country            city          origin    origin_clean  \\\n",
       "702  United Kingdom  United Kingdom  United Kingdom  United Kingdom   \n",
       "\n",
       "      latitude  longitude         address  \n",
       "702  54.702354  -3.276575  United Kingdom  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped[df_coordinates_scraped['city']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country, city, origin, origin_clean, latitude, longitude, address]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped.drop(702, axis=0, inplace=True)\n",
    "df_coordinates_scraped[df_coordinates_scraped['city']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinates_scraped.to_csv('Datasets/df_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_coordinates_scraped: (1526, 7)\n",
      "\n",
      "Found 4 duplicates:\n",
      "               city         country\n",
      "324         Bristol  United Kingdom\n",
      "515  Ladbroke Grove  United Kingdom\n",
      "542          London  United Kingdom\n",
      "650       Sheffield  United Kingdom\n",
      "\n",
      "Resulting dataset: (1531, 7)\n",
      "Merged artists with coordinates! Found 5 new locations\n",
      "df_coordinates_concat exported to .csv\n"
     ]
    }
   ],
   "source": [
    "export_coordinates_concat(df_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_artists_origins_coordinates_concat``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to a .csv file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>Gilgamesh</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Hampstead</td>\n",
       "      <td>51.556530</td>\n",
       "      <td>-0.178301</td>\n",
       "      <td>Hampstead, Greater London, England, NW3 1QG, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>Young Legionnaire</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>51.489334</td>\n",
       "      <td>-0.144055</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>The Deviants</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Ladbroke Grove</td>\n",
       "      <td>51.517264</td>\n",
       "      <td>-0.211102</td>\n",
       "      <td>Ladbroke Grove, Westway, Lancaster West Estate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>Head of David</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Dudley</td>\n",
       "      <td>52.511083</td>\n",
       "      <td>-2.081681</td>\n",
       "      <td>Dudley, West Midlands, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Quintessence</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>51.489334</td>\n",
       "      <td>-0.144055</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist         country            city   latitude  longitude  \\\n",
       "3246          Gilgamesh  United Kingdom       Hampstead  51.556530  -0.178301   \n",
       "3247  Young Legionnaire  United Kingdom          London  51.489334  -0.144055   \n",
       "3248       The Deviants  United Kingdom  Ladbroke Grove  51.517264  -0.211102   \n",
       "3249      Head of David  United Kingdom          Dudley  52.511083  -2.081681   \n",
       "3250       Quintessence  United Kingdom          London  51.489334  -0.144055   \n",
       "\n",
       "                                                address  \n",
       "3246  Hampstead, Greater London, England, NW3 1QG, U...  \n",
       "3247    London, Greater London, England, United Kingdom  \n",
       "3248  Ladbroke Grove, Westway, Lancaster West Estate...  \n",
       "3249     Dudley, West Midlands, England, United Kingdom  \n",
       "3250    London, Greater London, England, United Kingdom  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins_coordinates_concat = merge_origins_coordinates(df_new_artists)\n",
    "df_artists_origins_coordinates_concat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>3821235</td>\n",
       "      <td>1537522</td>\n",
       "      <td>13529787</td>\n",
       "      <td>US</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Entity</td>\n",
       "      <td>2019</td>\n",
       "      <td>38.42</td>\n",
       "      <td>8</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Death Metal']</td>\n",
       "      <td>Death Metal band from Chicago, Illinois, USA. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>3821235</td>\n",
       "      <td>1094310</td>\n",
       "      <td>8362817</td>\n",
       "      <td>US</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Sentient</td>\n",
       "      <td>2016</td>\n",
       "      <td>37.92</td>\n",
       "      <td>9</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Death Metal']</td>\n",
       "      <td>Death Metal band from Chicago, Illinois, USA. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>184256</td>\n",
       "      <td>175620</td>\n",
       "      <td>279855</td>\n",
       "      <td>UK</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>We'll Talk About It Later</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Jazz', 'Rock']</td>\n",
       "      <td>['Fusion', 'Jazz-Funk', 'Jazz-Rock', 'Prog Rock']</td>\n",
       "      <td>Pioneering jazz-rock, progressive, psychedelic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>184256</td>\n",
       "      <td>23574</td>\n",
       "      <td>465143</td>\n",
       "      <td>UK</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Elastic Rock</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Jazz', 'Rock']</td>\n",
       "      <td>['Jazz-Rock', 'Fusion', 'Prog Rock']</td>\n",
       "      <td>Pioneering jazz-rock, progressive, psychedelic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist_id  master_id  main_release_id release_country        artist  \\\n",
       "1004     3821235    1537522         13529787              US  Nucleus (US)   \n",
       "1592     3821235    1094310          8362817              US  Nucleus (US)   \n",
       "5257      184256     175620           279855              UK  Nucleus (UK)   \n",
       "10195     184256      23574           465143              UK  Nucleus (UK)   \n",
       "\n",
       "                           title  year  album_length  tracks     release_type  \\\n",
       "1004                      Entity  2019         38.42       8        ['Album']   \n",
       "1592                    Sentient  2016         37.92       9        ['Album']   \n",
       "5257   We'll Talk About It Later  1971          0.00       7  ['LP', 'Album']   \n",
       "10195               Elastic Rock  1970          0.00      13  ['LP', 'Album']   \n",
       "\n",
       "                 genres                                             styles  \\\n",
       "1004           ['Rock']                                    ['Death Metal']   \n",
       "1592           ['Rock']                                    ['Death Metal']   \n",
       "5257   ['Jazz', 'Rock']  ['Fusion', 'Jazz-Funk', 'Jazz-Rock', 'Prog Rock']   \n",
       "10195  ['Jazz', 'Rock']               ['Jazz-Rock', 'Fusion', 'Prog Rock']   \n",
       "\n",
       "                                          artist_profile  \n",
       "1004   Death Metal band from Chicago, Illinois, USA. ...  \n",
       "1592   Death Metal band from Chicago, Illinois, USA. ...  \n",
       "5257   Pioneering jazz-rock, progressive, psychedelic...  \n",
       "10195  Pioneering jazz-rock, progressive, psychedelic...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended[df_masters_blended['artist'].str.contains('Nucleus')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist_id, master_id, main_release_id, release_country, artist, title, year, album_length, tracks, release_type, genres, styles, artist_profile]\n",
       "Index: []"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended[df_masters_blended['title'].str.contains('Alleycat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29004</th>\n",
       "      <td>86398</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Elastic Rock</td>\n",
       "      <td>3.55</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29120</th>\n",
       "      <td>87140</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>We'll Talk About It Later</td>\n",
       "      <td>3.79</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39636</th>\n",
       "      <td>216509</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Sentient</td>\n",
       "      <td>3.29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45524</th>\n",
       "      <td>333839</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Entity</td>\n",
       "      <td>3.68</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46380</th>\n",
       "      <td>352917</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Alleycat</td>\n",
       "      <td>3.52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       album_id        artist                      title  rating  votes\n",
       "29004     86398  Nucleus (UK)               Elastic Rock    3.55     20\n",
       "29120     87140  Nucleus (UK)  We'll Talk About It Later    3.79     21\n",
       "39636    216509  Nucleus (US)                   Sentient    3.29     29\n",
       "45524    333839  Nucleus (US)                     Entity    3.68     40\n",
       "46380    352917  Nucleus (UK)                   Alleycat    3.52     20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_20[df_ratings_20['artist'].str.contains('Nucleus')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.loc[46380, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[29004, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[29120, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[39636, 'artist'] = 'Nucleus (US)'\n",
    "df_ratings_20.loc[45524, 'artist'] = 'Nucleus (US)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12059, 10)"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([7660, 8037], axis=0, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [album_id, artist, album, rating, votes]\n",
       "Index: []"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist'] = np.where(df['artist']=='pg.99 / Majority Rule', 'Majority Rule', df['artist'])\n",
    "df[df['artist']=='pg.99 / Majority Rule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.to_csv('Datasets/df_ratings_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12059, 10)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing code for strange cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Funeral_for_a_Friend_(band): Bridgend, Wales\n",
      "1 - Millencolin_(band): multiple issues - Örebro, Sweden\n",
      "2 - The_Flaming_Lips_(band): Oklahoma City, Oklahoma, U.S.\n",
      "3 - Feeder_(band): Feeder in 2008\n",
      "4 - Descendents_(band): Manhattan Beach, California, U.S.\n",
      "5 - PJ Harvey: no location found\n",
      "6 - Godsmack_(band): Lawrence, Massachusetts U.S.\n",
      "7 - Blind_Faith_(band): Ripley, Surrey, England\n",
      "8 - Van_Halen_(band): Pasadena, California, U.S.\n",
      "9 - Damageplan_(band): Dallas, Texas, U.S.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/df_ratings.csv')\n",
    "artists = df['artist'].unique()\n",
    "\n",
    "artists_list = []\n",
    "origin_list = []\n",
    "count=0\n",
    "\n",
    "for index in artists[140:150]:\n",
    "\n",
    "    artists_list.append(index)\n",
    "    name_changed = index.replace(' ', '_')\n",
    "    name_changed_band = name_changed + ('_(band)')\n",
    "\n",
    "    try:\n",
    "        url = f\"https://en.wikipedia.org/wiki/{name_changed_band}\"\n",
    "        response = requests.get(url).content\n",
    "        soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "        origin = soup.select('table tr th', class_='infobox-label')\n",
    "\n",
    "        if len(origin) > 0:\n",
    "            try:\n",
    "                if origin[2].text == 'Origin':\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[1].text\n",
    "                elif origin[3].text == 'Origin':\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[2].text\n",
    "                # else:\n",
    "                    \n",
    "                if 'multiple issues' in location:\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[7].text        \n",
    "                    print(f'{count} - {name_changed_band}: multiple issues - {location}')\n",
    "                    origin_list.append(location)\n",
    "                elif 'additional citations' in location:\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[3].text        \n",
    "                    print(f'{count} - {name_changed_band}: additional citations - {location}')\n",
    "                    origin_list.append(location)\n",
    "\n",
    "                else:\n",
    "                    print(f'{count} - {name_changed_band}: {location}')\n",
    "                    origin_list.append(location)\n",
    "            except:\n",
    "                print(f'{count} - {name_changed_band}: {location}')\n",
    "                origin_list.append(location)      \n",
    "        else:\n",
    "            try:\n",
    "                url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "                response = requests.get(url).content\n",
    "                soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "                origin = soup.select('table tr th', class_='infobox-label')\n",
    "\n",
    "                if len(origin) > 0:\n",
    "                    if origin[2].text == 'Origin':\n",
    "                        location = soup.select('table tr td', class_='infobox-data')[1].text\n",
    "\n",
    "                        if 'multiple issues' in location:\n",
    "                            location = soup.select('table tr td', class_='infobox-data')[7].text        \n",
    "                            print(f'{count} - {name_changed_band}: multiple issues - {location}')\n",
    "                            origin_list.append(location)\n",
    "                        elif 'additional citations' in location:\n",
    "                            location = soup.select('table tr td', class_='infobox-data')[3].text        \n",
    "                            print(f'{count} - {name_changed_band}: additional citations - {location}')\n",
    "                            origin_list.append(location)\n",
    "                        else:\n",
    "                            print(f'{count} - {name_changed_band}: {location}')\n",
    "                            origin_list.append(location)\n",
    "\n",
    "                    elif origin[3].text == 'Origin':\n",
    "                        location = soup.select('table tr td', class_='infobox-data')[2].text\n",
    "                        print(f'{count} - {name_changed_band}: {location}')\n",
    "                        origin_list.append(location) \n",
    "\n",
    "                    else:\n",
    "                        print(f'{count} - {index}: no location found')\n",
    "                        origin_list.append(np.nan)  \n",
    "                else:\n",
    "                    print(f'{count} - {index}: short length')\n",
    "                    origin_list.append(np.nan)\n",
    "            except:\n",
    "                print(f'{count} - {index}: error')\n",
    "                origin_list.append(np.nan)\n",
    "    except:\n",
    "        print(f'{count} - {index}: error')\n",
    "        origin_list.append(np.nan)\n",
    "\n",
    "    if len(artists_list) != len(origin_list):\n",
    "        print('different lengths')\n",
    "        break\n",
    "\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_origins_wikipedia(df, start_index, final_index):\n",
    "    df = pd.read_csv('Datasets/df_rock_ratings_20.csv')\n",
    "    artists = df['artist'].unique()\n",
    "\n",
    "    try:\n",
    "    # import the DataFrame with the locations whose coordinates I already have\n",
    "        df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "        print('Bingo! df_coordinates.csv found \\n')\n",
    "    except: \n",
    "        print('df_coordinates.csv not found \\n')\n",
    "\n",
    "    artists_list = []\n",
    "    origin_list = []\n",
    "    count=0\n",
    "    scraped=0\n",
    "\n",
    "    for index in artists_us_to_do[start_index:final_index]:\n",
    "\n",
    "        name_changed = index.replace(' ', '_')\n",
    "        name_changed_band = name_changed + ('_(band)')\n",
    "\n",
    "        try:\n",
    "            url = f\"https://en.wikipedia.org/wiki/{name_changed_band}\"\n",
    "            response = requests.get(url).content\n",
    "            soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "            table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "            location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "            city = location.split(', ')[0]\n",
    "            count+=1\n",
    "            \n",
    "        # save info in lists\n",
    "            artists_list.append(index)  \n",
    "            origin_list.append(location)\n",
    "            scraped+=1\n",
    "            print(f'{scraped}/{count} - {name_changed_band}: {location}')\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "                response = requests.get(url).content\n",
    "                soup = BeautifulSoup(response, \"html.parser\")\n",
    "                table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "                try:\n",
    "                    location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1 \n",
    "    \n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed}: {location}')\n",
    "\n",
    "                except:\n",
    "                    location = table[0].text.split(')')[2].split('Genres')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1\n",
    "\n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed} (individual): {location}')\n",
    "\n",
    "            except:\n",
    "                try:\n",
    "                    url = f\"https://es.wikipedia.org/wiki/{name_changed}\"\n",
    "                    response = requests.get(url).content\n",
    "                    soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "                    table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "                    location = table[0].text.split('Origen\\n')[1].split(' Información')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1    \n",
    "    \n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed} (español): {location}')\n",
    "\n",
    "                except:\n",
    "                    count+=1\n",
    "                    print(f'{scraped}/{count} - {index}: error')\n",
    "                    artists_list.append(index) \n",
    "                    origin_list.append(np.nan)\n",
    "\n",
    "        if len(artists_list) != len(origin_list):\n",
    "            print('different lengths')\n",
    "            break\n",
    "\n",
    "    df_artists_origins = pd.DataFrame({'artist': artists_list\n",
    "                             , 'origin': origin_list})\n",
    "    \n",
    "    return df_artists_origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_artists(df_artists_origins):\n",
    "\n",
    "# import the df with the artists' origins already scraped\n",
    "    df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "\n",
    "    if df_artists_origins['origin'].isna().sum() == 0:        \n",
    "        print(\"No null values, but let's take a look just in case there are weird locations\")\n",
    "\n",
    "    else: \n",
    "    # take a look at the df with the new artists and make sure there are non null values in origin (when it couldn't find it in Wikipedia)\n",
    "        print(f'{round(df_artists_origins['origin'].isna().sum() / df_artists_origins.shape[0]*100, 2)} % of nulls')\n",
    "    \n",
    "# subset of the new artists I just got, wether there are null values or not\n",
    "    df_new_artists = df_artists_origins[~df_artists_origins['artist'].isin(df_artists_origins_scraped['artist'].values)]\n",
    "\n",
    "    print(\"Here is the dataframe with the new artists, without duplicates\")\n",
    "    return df_new_artists   # so I can take a look at it and then continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_artists_origins_concat(df_new_artists):\n",
    "\n",
    "# import the df with the artists' origins already scraped\n",
    "    df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "\n",
    "# concat with the df I just got\n",
    "    df_artists_origins_concat = pd.concat([df_artists_origins_scraped, df_new_artists])\n",
    "    df_artists_origins_concat.drop_duplicates(inplace=True)     # just in case\n",
    "    df_artists_origins_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# export all the artists and their origins to a .csv file (the ones I got plus the new artists)\n",
    "    df_artists_origins_concat.to_csv('Datasets/df_artists_origins.csv', index=False)\n",
    "    print('df_artists_origins_concat exported to .csv')\n",
    "    print(df_artists_origins_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_geopy(df_new_artists):\n",
    "    \n",
    "# replace special characters for spaces\n",
    "    df_new_artists['origin_clean'] = df_new_artists['origin'].str.replace('.', '')\n",
    "    df_new_artists['origin_clean'] = df_new_artists['origin_clean'].str.replace(r'\\[\\d+\\]', '', regex=True)\n",
    "\n",
    "# run the function that gets the coordinates from the origins from Geopy\n",
    "    geolocator = Nominatim(user_agent=\"music_analysis\", timeout=10)\n",
    "\n",
    "# if they are 'dirty' origins that after the cleaning, they result in the same 'origin_clean'\n",
    "    df_unique = df_new_artists[['origin', 'origin_clean']].drop_duplicates() \n",
    "    unique_origins = df_unique['origin'].values\n",
    "    unique_origins_clean = df_unique['origin_clean'].values\n",
    "\n",
    "    country_list = []\n",
    "    city_list = []\n",
    "    latitude_list = []\n",
    "    longitude_list = []\n",
    "    address_list = []\n",
    "    lists = [country_list, city_list, latitude_list, longitude_list, address_list]\n",
    "    count = 0\n",
    "\n",
    "    for origin in unique_origins_clean:\n",
    "        count+=1\n",
    "        time.sleep(1)\n",
    "        location = geolocator.geocode(origin)\n",
    "\n",
    "        print(f'{count}/{len(unique_origins_clean)} - {location.address}')  \n",
    "\n",
    "    # save the info in lists\n",
    "        country_list.append(location.address.split(', ')[-1])\n",
    "        city_list.append(origin.split(', ')[0])\n",
    "        latitude_list.append(location.latitude)\n",
    "        longitude_list.append(location.longitude)\n",
    "        address_list.append(location.address)\n",
    "\n",
    "        # # Check lengths\n",
    "        # print(f\"{count}/{len(unique_origins_clean)} - {origin}\")\n",
    "        # print(f\"Current list lengths -> country: {len(country_list)}, city: {len(city_list)}, \"\n",
    "        #     f\"lat: {len(latitude_list)}, lon: {len(longitude_list)}, address: {len(address_list)}\")\n",
    "\n",
    "    df_coordinates = pd.DataFrame({'country': country_list\n",
    "                                , 'city': city_list\n",
    "                                , 'origin': unique_origins\n",
    "                                , 'origin_clean': unique_origins_clean\n",
    "                                , 'latitude': latitude_list\n",
    "                                , 'longitude': longitude_list\n",
    "                                , 'address': address_list})\n",
    "    df_coordinates.sort_values(['country', 'city'], inplace=True) # sort by country and city\n",
    "    df_coordinates.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_coordinates_concat(df_coordinates):\n",
    "\n",
    "# import the last df that contains the coordinates of the unique origins\n",
    "    df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "    print(f\"df_coordinates_scraped: {df_coordinates_scraped.shape}\\n\")\n",
    "\n",
    "# concat with the df of the coordinates I just got\n",
    "    df_coordinates_concat = pd.concat([df_coordinates_scraped, df_coordinates])\n",
    "    df_coordinates_concat.sort_values(['country', 'city'], inplace=True) # sort by country and city\n",
    "    df_coordinates_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# look for duplicates in the origin, between the locations I had already gotten and the new ones\n",
    "    check_duplicates_origins(df_coordinates_concat)\n",
    "    new_origins = df_coordinates_concat.shape[0] - df_coordinates_scraped.shape[0]\n",
    "    print(f\"Merged artists with coordinates! Found {new_origins} new locations\")\n",
    "\n",
    "# save it in a csv file (the coordinates I had plus the ones from the new artists I just got)\n",
    "    df_coordinates_concat.to_csv('Datasets/df_coordinates.csv', index=False)\n",
    "    print('df_coordinates_concat exported to .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_origins_coordinates(df_new_artists):\n",
    "\n",
    "# import the last df that contains the coordinates of the unique origins\n",
    "    df_coordinates_concat = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "\n",
    "# merge with the previous df with the artists\n",
    "    df_artists_origins_coordinates = pd.merge(df_new_artists, df_coordinates_concat, on=['origin'])\n",
    "    df_artists_origins_coordinates.drop(columns=['origin', 'origin_clean_x', 'origin_clean_y'], inplace=True)\n",
    "\n",
    "# import the df that contains info of the artists and the coordinates of their origins\n",
    "    df_artists_origins_coordinates_scraped = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')\n",
    "\n",
    "# concat to get the df with all the artists, origins and their coordinates\n",
    "    df_artists_origins_coordinates_concat = pd.concat([df_artists_origins_coordinates_scraped, df_artists_origins_coordinates])\n",
    "    df_artists_origins_coordinates_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# save it in a csv file\n",
    "    df_artists_origins_coordinates_concat.to_csv('Datasets/df_artists_origins_coordinates.csv', index=False)\n",
    "    print(\"Exported to a .csv file\")\n",
    "\n",
    "    return df_artists_origins_coordinates_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dataframes and look for the ``new_artists``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4527"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_blend = df_masters_blended['artist'].unique()\n",
    "len(artists_blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1555"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "artists = df_artists_origins['artist'].unique()\n",
    "artists_usa = []\n",
    "\n",
    "for artist in artists_blend:\n",
    "    if artist not in df_artists_origins['artist'].values:\n",
    "        artists_usa.append(artist)\n",
    "\n",
    "len(artists_usa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As Living Arrows',\n",
       " 'Hidden Mothers',\n",
       " 'Tiny Moving Parts',\n",
       " 'Poppy',\n",
       " 'State Champs',\n",
       " 'Oso Oso',\n",
       " 'Better Lovers',\n",
       " 'Lowen',\n",
       " 'Halsey',\n",
       " 'Amyl and the Sniffers',\n",
       " 'Delta Sleep',\n",
       " 'High Vis',\n",
       " 'Cemetery Skyline',\n",
       " 'Goat',\n",
       " 'Chat Pile',\n",
       " 'Drug Church',\n",
       " 'Origami Angel',\n",
       " 'Heriot',\n",
       " 'Nightwish',\n",
       " 'Foxing',\n",
       " 'Alora Crucible',\n",
       " 'Wage War',\n",
       " 'TURQUOISEDEATH',\n",
       " 'Dawn Treader',\n",
       " 'Boston Manor',\n",
       " 'MJ Lenderman',\n",
       " 'Fat Dog',\n",
       " 'Kingcrow',\n",
       " 'Leprous',\n",
       " 'Wunderhorse',\n",
       " 'thrown',\n",
       " 'Horse Jumper of Love',\n",
       " 'Within the Ruins',\n",
       " 'Magdalena Bay',\n",
       " 'Fontaines D.C.',\n",
       " 'beabadoobee',\n",
       " 'State Faults',\n",
       " 'Graphic Nature',\n",
       " 'The Home Team',\n",
       " 'Speed',\n",
       " 'Remi Wolf',\n",
       " 'Clairo',\n",
       " 'Crippling Alcoholism',\n",
       " 'Cigarettes After Sex',\n",
       " 'Abriction',\n",
       " 'Pijn',\n",
       " 'Outlander',\n",
       " 'Imagine Dragons',\n",
       " 'The Dangerous Summer',\n",
       " 'Pond',\n",
       " 'Hyperdontia',\n",
       " 'Vredehammer',\n",
       " 'Pedro the Lion',\n",
       " 'Weston Super Maim',\n",
       " 'Stand Still',\n",
       " 'Mortal Wound',\n",
       " 'Eye of Solitude',\n",
       " 'Beth Gibbons',\n",
       " 'Contention',\n",
       " 'Knocked Loose',\n",
       " 'Mdou Moctar',\n",
       " 'The Lemon Twigs',\n",
       " 'Mk.Gee',\n",
       " 'Vennart',\n",
       " 'Microwave',\n",
       " 'Mastiff',\n",
       " 'Skycamefalling',\n",
       " 'SeeYouSpaceCowboy',\n",
       " 'Jamie Lenman',\n",
       " 'AVRALIZE',\n",
       " 'Imminence',\n",
       " 'Aaron West and The Roaring Twenties',\n",
       " 'Lo Moon',\n",
       " 'English Teacher',\n",
       " 'Engulfed',\n",
       " 'Khruangbin',\n",
       " 'Coffin Storm',\n",
       " 'Blanket',\n",
       " 'Boundaries',\n",
       " 'Adrianne Lenker',\n",
       " 'samlrc',\n",
       " 'Sticky Fingers',\n",
       " 'Bleachers',\n",
       " 'Stay Inside',\n",
       " 'Mannequin Pussy',\n",
       " 'Yard Act',\n",
       " 'Faye Webster',\n",
       " 'Little Kid',\n",
       " 'Job For A Cowboy',\n",
       " 'IDLES',\n",
       " 'Ihsahn',\n",
       " 'Laura Jane Grace',\n",
       " 'The Chisel',\n",
       " 'The Last Dinner Party',\n",
       " 'NewDad',\n",
       " 'Frank Carter and the Rattlesnakes',\n",
       " 'Tapir!',\n",
       " 'Neck Deep',\n",
       " 'Casey',\n",
       " 'Marika Hackman',\n",
       " 'Slift',\n",
       " 'Sprints',\n",
       " 'Killing Me Softly',\n",
       " 'Rannoch',\n",
       " 'Termina',\n",
       " 'Harp',\n",
       " 'Empty Country',\n",
       " 'Free Throw',\n",
       " 'Psychedelic Porn Crumpets',\n",
       " 'Dying Wish',\n",
       " 'END',\n",
       " 'Wargasm',\n",
       " 'Maria BC',\n",
       " 'Myrkur',\n",
       " 'Knuckle Puck',\n",
       " 'Creeper',\n",
       " 'Beartooth',\n",
       " 'Blood Command',\n",
       " 'Rorcal',\n",
       " 'Yeule',\n",
       " 'Slow Pulp',\n",
       " 'Dead and Dripping',\n",
       " 'Koyo',\n",
       " 'Shade Empire',\n",
       " 'TesseracT',\n",
       " 'Explosions in the Sky',\n",
       " 'Cursetheknife',\n",
       " 'Olivia Rodrigo',\n",
       " 'Uada',\n",
       " 'Pain of Truth',\n",
       " 'Reverence To Paroxysm',\n",
       " 'Royal Blood',\n",
       " 'Celestial Sanctuary',\n",
       " 'Empire State Bastard',\n",
       " 'Jeff Rosenstock',\n",
       " 'Spanish Love Songs',\n",
       " 'Urne',\n",
       " 'Movements',\n",
       " 'Caskets',\n",
       " 'Fiddlehead',\n",
       " 'Sunami',\n",
       " 'Teenage Wrist',\n",
       " 'Deitus',\n",
       " 'Mutoid Man',\n",
       " 'Voyager',\n",
       " 'Dawnwalker',\n",
       " 'PVRIS',\n",
       " 'Julie Byrne',\n",
       " 'Blindfolded and Led to the Woods',\n",
       " 'Nothing But Thieves',\n",
       " 'Grian Chatten',\n",
       " 'Model/Actriz',\n",
       " 'Burner',\n",
       " 'Death Goals',\n",
       " 'King Krule',\n",
       " 'feeble little horse',\n",
       " 'Noah Kahan',\n",
       " 'Squid',\n",
       " 'Tigercub',\n",
       " 'Pupil Slicer',\n",
       " 'Protomartyr',\n",
       " 'Phoxjaw',\n",
       " 'Bully',\n",
       " 'Wytch Hazel',\n",
       " 'Water From Your Eyes',\n",
       " 'Incendiary',\n",
       " 'bar italia',\n",
       " 'Sleep Token',\n",
       " 'Mandy, Indiana',\n",
       " 'Covet',\n",
       " 'The Amity Affliction',\n",
       " 'Veil of Maya',\n",
       " 'Currents',\n",
       " 'Crown the Empire',\n",
       " 'There Will Be Fireworks',\n",
       " 'Waterparks',\n",
       " 'Blondshell',\n",
       " 'HMLTD',\n",
       " 'deathcrash',\n",
       " 'Wednesday',\n",
       " 'Gel',\n",
       " 'Allfather',\n",
       " 'Bury Tomorrow',\n",
       " 'City and Colour',\n",
       " 'Boygenius',\n",
       " \"Dawn Ray'd\",\n",
       " 'BABYMETAL',\n",
       " 'Mork',\n",
       " 'Green Druid',\n",
       " 'M83',\n",
       " '100 Gecs',\n",
       " 'Periphery',\n",
       " 'Sleaford Mods',\n",
       " 'Acres',\n",
       " \"Can't Swim\",\n",
       " 'Pest Control',\n",
       " 'Host',\n",
       " 'U.S. Girls',\n",
       " 'Shame',\n",
       " 'Avatar',\n",
       " 'Hellripper',\n",
       " 'Avey Tare',\n",
       " 'A Wake in Providence',\n",
       " 'Pigs Pigs Pigs Pigs Pigs Pigs Pigs',\n",
       " 'Ihlo',\n",
       " 'Narrow Head',\n",
       " 'Emarosa',\n",
       " 'Molly',\n",
       " 'The Murder Capital',\n",
       " 'Margo Price',\n",
       " 'Weyes Blood',\n",
       " 'Turnover',\n",
       " 'Demon Hunter',\n",
       " \"Arm's Length\",\n",
       " 'Fit for a King',\n",
       " 'Dead Cross',\n",
       " 'Abduction',\n",
       " 'Brutus',\n",
       " 'Dry Cleaning',\n",
       " 'The 1975',\n",
       " 'Lacuna Coil',\n",
       " 'Gilla Band',\n",
       " 'Alvvays',\n",
       " 'Counterparts',\n",
       " 'Vacuous',\n",
       " 'Faceless Burial',\n",
       " 'Drowning Pool',\n",
       " 'Within Destruction',\n",
       " 'Miss May I',\n",
       " 'Escuela Grind',\n",
       " 'No Devotion',\n",
       " 'Holy Fawn',\n",
       " 'Courting',\n",
       " 'Tamino',\n",
       " 'Horsey',\n",
       " 'Inclination',\n",
       " 'Rina Sawayama',\n",
       " 'Electric Callboy',\n",
       " 'Camping In Alaska',\n",
       " 'Slaughterhouse',\n",
       " 'YUNGBLUD',\n",
       " 'Stella Donnelly',\n",
       " 'Julia Jacklin',\n",
       " 'Pale Waves',\n",
       " 'The Halo Effect',\n",
       " 'Sedimentum',\n",
       " 'Pool Kids',\n",
       " 'Ithaca',\n",
       " 'Dance Gavin Dance',\n",
       " 'Molder',\n",
       " 'Black Midi',\n",
       " 'Say Sue Me',\n",
       " 'Viagra Boys',\n",
       " 'Wormrot',\n",
       " 'Momma',\n",
       " 'Petrol Girls',\n",
       " 'Saor',\n",
       " 'Soccer Mommy',\n",
       " 'Sunrise Patriot Motion',\n",
       " 'Nova Twins',\n",
       " 'Ataraxy',\n",
       " 'Otoboke Beaver',\n",
       " 'Motionless In White',\n",
       " 'Corpsessed',\n",
       " 'Blood Youth',\n",
       " 'Horsegirl',\n",
       " 'Just Mustard',\n",
       " 'Malevolence',\n",
       " 'Harry Styles',\n",
       " 'Porridge Radio',\n",
       " 'Toad',\n",
       " 'Rolling Blackouts Coastal Fever',\n",
       " 'Bodysnatcher',\n",
       " 'Static Dress',\n",
       " 'Halestorm',\n",
       " 'Stand Atlantic',\n",
       " 'Proper.',\n",
       " 'Black Sheep Wall',\n",
       " 'Hatchie',\n",
       " 'Prince Daddy and The Hyena',\n",
       " 'Undeath',\n",
       " 'Epitaphe',\n",
       " 'Envy of None',\n",
       " 'Helpless',\n",
       " 'Wet Leg',\n",
       " 'PUP',\n",
       " 'Camp Cope',\n",
       " 'Ditz',\n",
       " 'Aldous Harding',\n",
       " 'Indian Summer',\n",
       " 'Machine Gun Kelly',\n",
       " 'Animals As Leaders',\n",
       " 'Yumi Zouma',\n",
       " 'Twelve Foot Ninja',\n",
       " 'Belmont',\n",
       " 'Messa',\n",
       " 'Chalk Hands',\n",
       " 'Ghost',\n",
       " 'Cryptworm',\n",
       " 'Mountaineer',\n",
       " 'Ecchymosis',\n",
       " 'Bloodywood',\n",
       " 'Sasami',\n",
       " 'Avril Lavigne',\n",
       " 'Mom Jeans.',\n",
       " 'Caroline',\n",
       " 'Scorpions',\n",
       " 'Evergreen',\n",
       " 'Sea Power',\n",
       " 'Big Thief',\n",
       " 'As It Is',\n",
       " 'Grivo',\n",
       " 'Mitski',\n",
       " 'Pinegrove',\n",
       " 'Black Country, New Road',\n",
       " 'Bad Omens',\n",
       " 'Voices',\n",
       " 'Comeback Kid',\n",
       " 'Shadow Of Intent',\n",
       " 'Vertebra Atlantis',\n",
       " 'Slow Crush',\n",
       " 'Unfurl',\n",
       " 'Geese',\n",
       " 'Papangu',\n",
       " 'Damon Albarn',\n",
       " 'Sermon of Flames',\n",
       " 'Springtime',\n",
       " 'Snail Mail',\n",
       " 'Emma Ruth Rundle',\n",
       " 'Courtney Barnett',\n",
       " 'Black Veil Brides',\n",
       " 'Frontierer',\n",
       " 'Monolord',\n",
       " 'Sulphurous',\n",
       " 'Black Marble',\n",
       " 'Ice Nine Kills',\n",
       " 'I Feel Fine',\n",
       " 'Sugar Horse',\n",
       " 'Dean Blunt',\n",
       " 'Sam Fender',\n",
       " \"KK's Priest\",\n",
       " 'Full of Hell',\n",
       " 'Tremonti',\n",
       " 'LLNN',\n",
       " 'Spiritbox',\n",
       " 'Aborted',\n",
       " 'Kacey Musgraves',\n",
       " 'Trna',\n",
       " 'Slaughter To Prevail',\n",
       " 'sonhos tomam conta',\n",
       " 'Bossk',\n",
       " 'Indigo De Souza',\n",
       " 'Deafheaven',\n",
       " 'Wolves in the Throne Room',\n",
       " 'Qrixkuor',\n",
       " 'Trash Boat',\n",
       " 'Galvanizer',\n",
       " 'Yola',\n",
       " 'Torres',\n",
       " 'LUMP',\n",
       " 'The Maine',\n",
       " 'Ophidian I',\n",
       " 'Diabolizer',\n",
       " 'Descendents',\n",
       " 'Lightning Bug',\n",
       " 'Atvm',\n",
       " 'Project 86',\n",
       " 'Lovesliescrushing',\n",
       " 'Hacktivist',\n",
       " 'Lucy Dacus',\n",
       " 'Portal',\n",
       " 'Ceremonium',\n",
       " 'Nexilva',\n",
       " 'Fear Factory',\n",
       " 'Morbific',\n",
       " 'Marina',\n",
       " 'Our Hollow, Our Home',\n",
       " 'Wolf Alice',\n",
       " 'Tilian',\n",
       " 'Bachelor',\n",
       " 'Noctule',\n",
       " 'Japanese Breakfast',\n",
       " 'Home Is Where',\n",
       " 'Manchester Orchestra',\n",
       " 'The Raging Nathans',\n",
       " 'Holding Absence',\n",
       " 'Flock of Dimes',\n",
       " \"'68\",\n",
       " 'Genghis Tron',\n",
       " 'Ominous Ruin',\n",
       " 'Cassandra Jenkins',\n",
       " 'Julien Baker',\n",
       " 'Love and Death',\n",
       " 'Defacement',\n",
       " 'Divide And Dissolve',\n",
       " 'TV Priest',\n",
       " 'Lamp of Murmuur',\n",
       " 'Goat Girl',\n",
       " 'Soen',\n",
       " 'Accept',\n",
       " 'Pom Poko',\n",
       " 'The Casket Lottery',\n",
       " 'Parquet Courts',\n",
       " 'Pearl Charles',\n",
       " 'Respire',\n",
       " 'Teenage Mutant Ninja Turtles',\n",
       " 'Dominic Fike',\n",
       " 'Undergang',\n",
       " 'Edenic Past',\n",
       " 'Red City Radio',\n",
       " 'Palm Reader',\n",
       " 'Bearings',\n",
       " 'Seahaven',\n",
       " 'Black Foxxes',\n",
       " 'Scalp',\n",
       " 'The Menzingers',\n",
       " 'Kingdom of Giants',\n",
       " 'Guitar Fight from Fooly Cooly',\n",
       " 'Miasmatic Necrosis',\n",
       " 'Black Stone Cherry',\n",
       " 'Nothing',\n",
       " 'The Fall of Troy',\n",
       " 'Matt Berninger',\n",
       " 'Gorephilia',\n",
       " 'Joji',\n",
       " 'Corey Taylor',\n",
       " 'Fires in the Distance',\n",
       " 'Obsidian Kingdom',\n",
       " 'Svalbard',\n",
       " 'The Ocean',\n",
       " 'Into It. Over It.',\n",
       " 'Fawn Limbs',\n",
       " 'Vous Autres',\n",
       " 'Carnation',\n",
       " 'Special Interest',\n",
       " 'Declan McKenna',\n",
       " 'Xazraug',\n",
       " 'Necrot',\n",
       " 'Angel Olsen',\n",
       " \"Luna's Call\",\n",
       " 'No Joy',\n",
       " 'Pharmacist',\n",
       " 'Duma',\n",
       " 'Misery Signals',\n",
       " 'Slightly Stoopid',\n",
       " 'Aseitas',\n",
       " 'Paara',\n",
       " 'Greg Puciato',\n",
       " 'The Beths',\n",
       " 'Nation of Language',\n",
       " 'Grey Daze',\n",
       " 'Carach Angren',\n",
       " 'Melt Yourself Down',\n",
       " 'Pottery',\n",
       " 'Sault',\n",
       " 'Calligram',\n",
       " 'Phoebe Bridgers',\n",
       " 'Owen',\n",
       " 'Justice For The Damned',\n",
       " 'Make Them Suffer',\n",
       " 'Westerman',\n",
       " 'Sports Team',\n",
       " 'Muzz',\n",
       " 'Palaye Royale',\n",
       " \"Caligula's Horse\",\n",
       " 'Infant Island',\n",
       " 'VVilderness',\n",
       " 'Car Seat Headrest',\n",
       " 'Elephant Tree',\n",
       " 'Molested Divinity',\n",
       " 'Ellis',\n",
       " 'Kontinuum',\n",
       " 'Yves Tumor',\n",
       " 'Telepathy',\n",
       " '5 Seconds of Summer',\n",
       " 'Brian Fallon',\n",
       " 'Sorry',\n",
       " 'The Chats',\n",
       " 'Malokarpatan',\n",
       " 'Afterbirth',\n",
       " 'Temple of Void',\n",
       " 'Hot Mulligan',\n",
       " 'Horse Lords',\n",
       " 'The Districts',\n",
       " 'Monsters',\n",
       " 'Greg Dulli',\n",
       " 'Panchiko',\n",
       " 'Bambara',\n",
       " 'Giver',\n",
       " 'Loathe',\n",
       " 'Shopping',\n",
       " 'Leeched',\n",
       " 'Lowrider',\n",
       " 'Lovebites',\n",
       " 'Vengeful Spectre',\n",
       " 'Higher Power',\n",
       " 'Slick Shoes',\n",
       " 'Wolf Parade',\n",
       " 'Mura Masa',\n",
       " 'Garganjua',\n",
       " 'Algiers',\n",
       " 'Vomit the Soul',\n",
       " 'The Last Ten Seconds Of Life',\n",
       " 'Blood Incantation',\n",
       " 'Dream State',\n",
       " 'Stray from the Path',\n",
       " 'Rex Orange County',\n",
       " 'Sadisme',\n",
       " 'Patrick Watson',\n",
       " 'Common Holly',\n",
       " 'Car Bomb',\n",
       " 'We Lost the Sea',\n",
       " 'Surf Curse',\n",
       " 'Issues',\n",
       " 'Kim Gordon',\n",
       " 'Alarmist',\n",
       " 'Dayseeker',\n",
       " 'Renounced',\n",
       " 'Post Malone',\n",
       " 'Klone',\n",
       " 'Void of Vision',\n",
       " 'The Agonist',\n",
       " 'Liam Gallagher',\n",
       " 'The Hu',\n",
       " 'Grayscale',\n",
       " 'Chris Farren',\n",
       " 'The Odious',\n",
       " 'Sleeping With Sirens',\n",
       " 'Nocturnal Departure',\n",
       " 'Whitney',\n",
       " 'Jay Som',\n",
       " 'Tropical Fuck Storm',\n",
       " 'King Gizzard and The Lizard Wizard',\n",
       " 'Blanck Mass',\n",
       " 'Richard Henshall',\n",
       " 'Rosalie Cunningham',\n",
       " 'Slaughter Beach, Dog',\n",
       " 'iamthemorning',\n",
       " 'Iniquitous Deeds',\n",
       " 'Throes',\n",
       " 'Abbath',\n",
       " 'Ossuary',\n",
       " 'Shirokuma',\n",
       " 'Puppy',\n",
       " 'Bill Callahan',\n",
       " 'CHON',\n",
       " 'Vanishing Twin',\n",
       " 'Frank Iero and The Future Violents',\n",
       " 'Novo Amor',\n",
       " 'Death Angel',\n",
       " 'Cate Le Bon',\n",
       " 'Plastic Mermaids',\n",
       " 'Black Mountain',\n",
       " 'Alex Lahey',\n",
       " 'Lewis Capaldi',\n",
       " 'Holding Patterns',\n",
       " 'Forests',\n",
       " 'We Never Learned To Live',\n",
       " 'Shin Guard',\n",
       " 'Town Portal',\n",
       " 'Trade Wind',\n",
       " 'Kevin Morby',\n",
       " 'Nucleus',\n",
       " 'Wand',\n",
       " 'Clowns',\n",
       " 'The Raven Age',\n",
       " 'Ceremony Of Silence',\n",
       " 'The Dismemberment Plan',\n",
       " 'CHAI',\n",
       " 'Orville Peck',\n",
       " 'Akasha',\n",
       " 'Venom Prison',\n",
       " 'Oozing Wound',\n",
       " 'Baalsebub',\n",
       " 'Tim Bowness',\n",
       " 'Mammoth Weed Wizard Bastard',\n",
       " 'Hozier',\n",
       " 'Teeth Of The Sea',\n",
       " 'Badflower',\n",
       " 'Drenge',\n",
       " 'Astronauts',\n",
       " 'Homeshake',\n",
       " 'Green Lung',\n",
       " 'Set It Off',\n",
       " 'Minors',\n",
       " 'King 810',\n",
       " 'Mystifier',\n",
       " 'Jade Bird',\n",
       " 'Press Club',\n",
       " 'Mono',\n",
       " 'Palisades',\n",
       " 'Tallies',\n",
       " 'Deuce',\n",
       " 'Napoleon',\n",
       " 'Normandie',\n",
       " 'XXXTENTACION',\n",
       " 'Ex:Re',\n",
       " 'Bliss Signal',\n",
       " 'Portrayal of Guilt',\n",
       " 'The Good, The Bad and The Queen',\n",
       " 'Toska',\n",
       " 'Tenacious D',\n",
       " 'Hippo Campus',\n",
       " 'Mass of the Fermenting Dregs',\n",
       " 'The Struts',\n",
       " 'Frog',\n",
       " 'The Dirty Nil',\n",
       " 'Polyphia',\n",
       " 'Hands Like Houses',\n",
       " 'Tom Morello',\n",
       " 'Pagan',\n",
       " 'Black Peaks',\n",
       " 'Kero Kero Bonito',\n",
       " 'Monuments',\n",
       " 'Exit North',\n",
       " 'Against The Current',\n",
       " 'Windhand',\n",
       " 'All Them Witches',\n",
       " 'Head with Wings',\n",
       " 'Wstr',\n",
       " 'Imperial Triumphant',\n",
       " 'The Skull',\n",
       " 'Gia Margaret',\n",
       " 'Trophy Eyes',\n",
       " 'Regal Worm',\n",
       " 'Talons',\n",
       " 'Like Pacific',\n",
       " 'The Antichrist Imperium',\n",
       " 'Mouse On The Keys',\n",
       " 'Burial Invocation',\n",
       " 'Morrow',\n",
       " 'The Interrupters',\n",
       " 'Panic! at the Disco',\n",
       " 'Mark Kozelek',\n",
       " 'Church of the Cosmic Skull',\n",
       " 'Zeal and Ardor',\n",
       " 'Jonathan Davis',\n",
       " 'Tancred',\n",
       " 'Lunatic Soul',\n",
       " 'Flasher',\n",
       " 'Graveyard',\n",
       " 'Keiji Haino',\n",
       " 'Body Void',\n",
       " 'Middle Kids',\n",
       " 'Pinkshinyultrablast',\n",
       " 'Forth Wanderers',\n",
       " 'Sectioned',\n",
       " 'Speedy Ortiz',\n",
       " 'Cassus',\n",
       " 'Boss Keloid',\n",
       " 'Tangled Hair',\n",
       " 'Ruins',\n",
       " 'Mastersystem',\n",
       " 'Rainbow Kitten Surprise',\n",
       " 'Autokrator',\n",
       " 'Night Flowers',\n",
       " 'Hinds',\n",
       " 'Sunflower Bean',\n",
       " 'Nervus',\n",
       " 'George Ezra',\n",
       " 'King Goat',\n",
       " 'Dead!',\n",
       " 'Moose Blood',\n",
       " \"Ed Schrader's Music Beat\",\n",
       " 'Gleb Kolyadin',\n",
       " 'Slugdge',\n",
       " 'Conjurer',\n",
       " 'Vundabar',\n",
       " 'Dvne',\n",
       " 'S. Carey',\n",
       " 'Pianos Become the Teeth',\n",
       " 'Band-Maid',\n",
       " 'Legend of the Seagullmen',\n",
       " 'Crywank',\n",
       " 'The Plot In You',\n",
       " 'Loma',\n",
       " 'Ezra Furman',\n",
       " 'Son Lux',\n",
       " 'Alpha Male Tea Party',\n",
       " 'Palm',\n",
       " 'Philip H. Anselmo and The Illegals',\n",
       " 'Marmozets',\n",
       " 'Somali Yacht Club',\n",
       " 'Anna Burch',\n",
       " 'Dream Wife',\n",
       " 'Thousand Below',\n",
       " 'Of Mice and Men',\n",
       " \"Leaves' Eyes\",\n",
       " 'Embodyment',\n",
       " 'Five Iron Frenzy',\n",
       " 'Yellow Days',\n",
       " 'Death Toll 80k',\n",
       " 'Sacred Son',\n",
       " 'Peach Pit',\n",
       " 'Beast In Black',\n",
       " 'ROAM',\n",
       " 'Turnpike Troubadours',\n",
       " 'Ibeyi',\n",
       " 'Grave Pleasures',\n",
       " 'IDYLLS',\n",
       " 'With the Dead',\n",
       " 'Nothing More',\n",
       " 'Prawn',\n",
       " 'Seaway',\n",
       " 'Ariel Pink',\n",
       " 'Rostam',\n",
       " 'The Contortionist',\n",
       " 'Prophets of Rage',\n",
       " 'White Moth Black Butterfly',\n",
       " 'Hammock',\n",
       " 'Hungry Ghosts',\n",
       " 'Thy Art Is Murder',\n",
       " 'ostraca',\n",
       " 'Kesha',\n",
       " 'Horrified',\n",
       " 'Agents of Oblivion',\n",
       " 'Sheer Mag',\n",
       " 'Silverstein',\n",
       " 'HAIM',\n",
       " 'Public Service Broadcasting',\n",
       " 'Spaceslug',\n",
       " 'Floating Points',\n",
       " 'Ex Eye',\n",
       " 'Hey Violet',\n",
       " 'Single Mothers',\n",
       " 'Wode',\n",
       " 'Flogging Molly',\n",
       " 'Tricot',\n",
       " 'Pumarosa',\n",
       " 'Employed To Serve',\n",
       " 'Gnarwolves',\n",
       " 'Woods',\n",
       " 'PWR BTTM',\n",
       " 'i hate sex',\n",
       " 'Spotlights',\n",
       " 'Sundara Karma',\n",
       " 'Hoops',\n",
       " 'The Physics House Band',\n",
       " 'Artificial Brain',\n",
       " 'Falling in Reverse',\n",
       " 'Jeromes Dream',\n",
       " 'Richard Cheese',\n",
       " 'Michelle Branch',\n",
       " 'Timber Timbre',\n",
       " 'I Declare War',\n",
       " 'Chinese Football',\n",
       " 'The Smith Street Band',\n",
       " 'Phrenelith',\n",
       " 'Hurray For The Riff Raff',\n",
       " 'Circa Waves',\n",
       " 'Temples',\n",
       " 'Raspberry Bulbs',\n",
       " 'Crystal Fairy',\n",
       " 'Vagabon',\n",
       " 'Peter Silberman',\n",
       " 'Meat Wave',\n",
       " 'The Orwells',\n",
       " 'Andrew McMahon in the Wilderness',\n",
       " 'Starset',\n",
       " 'Mark Eitzel',\n",
       " 'Foxygen',\n",
       " 'The Mayfield Four',\n",
       " 'Tycho',\n",
       " 'Youth Funeral',\n",
       " '40 Watt Sun',\n",
       " 'Attila',\n",
       " 'You Blew It!',\n",
       " 'Voices from the Fuselage',\n",
       " 'Earth Moves',\n",
       " 'D.D Dumbo',\n",
       " 'Lewis Del Mar',\n",
       " 'From Ashes To New',\n",
       " 'Shawn Mendes',\n",
       " 'Airbourne',\n",
       " 'Merchandise',\n",
       " 'Beach Slang',\n",
       " 'Newsboys',\n",
       " 'Preoccupations',\n",
       " 'Okkervil River',\n",
       " 'Dope Lemon',\n",
       " 'Mild High Club',\n",
       " 'David Brent',\n",
       " 'Abhorrent Decimation',\n",
       " 'Bayside',\n",
       " 'SWMRS',\n",
       " 'Gouge Away',\n",
       " 'Young the Giant',\n",
       " 'Monarch',\n",
       " 'Coldrain',\n",
       " \"Bear's Den\",\n",
       " 'Despised Icon',\n",
       " 'Omni',\n",
       " 'McCafferty',\n",
       " 'Dikembe',\n",
       " 'Nonpoint',\n",
       " 'The Avalanches',\n",
       " 'Big Business',\n",
       " 'Martha',\n",
       " 'Fates Warning',\n",
       " 'Lonely the Brave',\n",
       " 'British Theatre',\n",
       " 'Thousand Foot Krutch',\n",
       " 'Art Of Dying',\n",
       " 'With Confidence',\n",
       " 'Jake Bugg',\n",
       " 'The Hotelier',\n",
       " 'Rival Sons',\n",
       " 'The Claypool Lennon Delirium',\n",
       " 'Wicked Innocence',\n",
       " 'Minor Victories',\n",
       " 'Fear of Men',\n",
       " 'Real Friends',\n",
       " 'Catfish and the Bottlemen',\n",
       " 'Pantha Du Prince',\n",
       " 'Crystal Lake',\n",
       " 'Kikagaku Moyo',\n",
       " 'Schammasch',\n",
       " 'Twin Peaks',\n",
       " 'Destruction',\n",
       " 'Eagulls',\n",
       " 'RY X',\n",
       " 'LUH',\n",
       " 'ANOHNI',\n",
       " 'Messenger',\n",
       " 'Annisokay',\n",
       " 'Dowsing',\n",
       " 'Crooks',\n",
       " 'Dehumanized',\n",
       " 'Moonlit Sailor',\n",
       " 'The Comet Is Coming',\n",
       " 'Radical Face',\n",
       " 'King Buffalo',\n",
       " 'The Drones',\n",
       " 'Plague Vendor',\n",
       " 'Richmond Fontaine',\n",
       " 'Sarah Neufeld',\n",
       " 'Heck',\n",
       " 'Wormed',\n",
       " 'ee',\n",
       " 'Guerilla Toss',\n",
       " 'Big Ups',\n",
       " 'Mothers',\n",
       " 'Cindy Lee',\n",
       " 'The Neighbourhood',\n",
       " 'Porches',\n",
       " 'Money',\n",
       " 'Nevermen',\n",
       " 'Savages',\n",
       " 'Intervals',\n",
       " 'Fit for an Autopsy',\n",
       " 'Violet Cold',\n",
       " 'Sam Hunt',\n",
       " 'Nokturnel',\n",
       " 'Good Tiger',\n",
       " 'Sexwitch',\n",
       " 'EL VY',\n",
       " 'Love Lost But Not Forgotten',\n",
       " 'Half Moon Run',\n",
       " 'Shining',\n",
       " 'Marietta',\n",
       " 'Dilly Dally',\n",
       " 'One Ok Rock',\n",
       " 'Cruciamentum',\n",
       " 'Kylesa',\n",
       " 'Caspian',\n",
       " 'Agent Fresco',\n",
       " 'P.O.D.',\n",
       " 'X Ambassadors',\n",
       " 'Hills',\n",
       " 'Soilwork',\n",
       " 'Heartist',\n",
       " 'The Sword',\n",
       " 'Royal Headache',\n",
       " 'Highly Suspect',\n",
       " 'Kings Kaleidoscope',\n",
       " 'Archivist',\n",
       " 'Jason Isbell',\n",
       " 'Dan Andriano in the Emergency Room',\n",
       " 'Years and Years',\n",
       " 'Ethereal Shroud',\n",
       " 'God Damn',\n",
       " 'August Burns Red',\n",
       " 'Human Hands',\n",
       " 'Iwrestledabearonce',\n",
       " 'Mutiny On The Bounty',\n",
       " 'Mylets',\n",
       " 'Lucifer',\n",
       " 'Zella Day',\n",
       " 'FFS',\n",
       " 'Jaga Jazzist',\n",
       " 'Girlpool',\n",
       " 'Pet Symmetry',\n",
       " 'Charlie Simpson',\n",
       " 'Johnny Rebel',\n",
       " 'Surfer Blood',\n",
       " 'Murmur',\n",
       " 'We Are Harlot',\n",
       " 'Nai Harvest',\n",
       " 'Ghost Bath',\n",
       " 'Alabama Shakes',\n",
       " 'Bio-Cancer',\n",
       " 'Neon Trees',\n",
       " 'Say Lou Lou',\n",
       " 'Until The Ribbon Breaks',\n",
       " 'Shizune',\n",
       " 'Lower Dens',\n",
       " 'Ryley Walker',\n",
       " 'James Bay',\n",
       " 'AWOLNATION',\n",
       " 'Ranger',\n",
       " 'Trepalium',\n",
       " 'Houndmouth',\n",
       " 'The Sidekicks',\n",
       " 'Pile',\n",
       " 'Ghostpoet',\n",
       " 'A Textbook Tragedy',\n",
       " 'Colleen Green',\n",
       " 'Butch Walker',\n",
       " 'xRepentancex',\n",
       " 'Peace',\n",
       " 'The Arrogant Sons of Bitches',\n",
       " 'Jessica Pratt',\n",
       " 'This Is A Standoff',\n",
       " 'Planet X',\n",
       " 'Kodaline',\n",
       " 'FACT',\n",
       " 'Abstracter',\n",
       " 'California X',\n",
       " 'Cloakroom',\n",
       " 'Swallowed',\n",
       " 'Charli XCX',\n",
       " 'Clouds',\n",
       " 'TrenchRot',\n",
       " 'Forever Came Calling',\n",
       " 'The Ghost Inside',\n",
       " 'Youngblood Hawke',\n",
       " 'No Bragging Rights',\n",
       " 'Disembarked',\n",
       " 'The Jazz June',\n",
       " 'Wildbirds and Peacedrums',\n",
       " 'Crobot',\n",
       " 'Miroist',\n",
       " 'Climates',\n",
       " 'Tweedy',\n",
       " 'Adult Jazz',\n",
       " 'Benjamin Booker',\n",
       " 'My Brightest Diamond',\n",
       " 'The Hell',\n",
       " 'The Wytches',\n",
       " 'Lay Down Rotten',\n",
       " 'Owl John',\n",
       " 'The Algorithm',\n",
       " 'The Flex',\n",
       " 'Bear Hands',\n",
       " 'Totem Skin',\n",
       " 'Breathe Carolina',\n",
       " 'Braid',\n",
       " 'Total Control',\n",
       " 'Glass Animals',\n",
       " 'White Lung',\n",
       " 'Dreamshade',\n",
       " 'Tombs',\n",
       " 'Harry Pussy',\n",
       " 'Vales',\n",
       " 'Archspire',\n",
       " 'Sickening Gore',\n",
       " 'Mars Red Sky',\n",
       " 'Lewis',\n",
       " 'Sorority Noise',\n",
       " 'Echosmith',\n",
       " 'Brody Dalle',\n",
       " 'Circles',\n",
       " 'Ian Anderson',\n",
       " 'The Mire',\n",
       " \"Avey Tare's Slasher Flicks\",\n",
       " 'Chuck Ragan',\n",
       " 'Scar the Martyr',\n",
       " 'Owls',\n",
       " 'Collide',\n",
       " 'Laibach',\n",
       " 'Tony Molina',\n",
       " 'Adrenaline Mob',\n",
       " 'I See Stars',\n",
       " 'Pan.Thy.Monium',\n",
       " 'Above and Beyond',\n",
       " 'Cheatahs',\n",
       " 'Sahg',\n",
       " 'Harvey Danger',\n",
       " 'Mutual Benefit',\n",
       " 'Marvelous 3',\n",
       " 'Pestilence',\n",
       " 'Beastmilk',\n",
       " 'Hell',\n",
       " 'Steve Von Till',\n",
       " 'Laughing Hyenas',\n",
       " 'Yamantaka // Sonic Titan',\n",
       " 'Sky Ferreira',\n",
       " 'Kind of Like Spitting',\n",
       " 'the GazettE',\n",
       " 'San Fermin',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4249"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I have to import this df for the function to properly work\n",
    "df = pd.read_csv('Datasets/df_blend_ratings.csv')\n",
    "artists = df['artist'].unique()\n",
    "len(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As Living Arrows'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3423"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>Philadelphia, Pennsylvania, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>Death From Above 1979</td>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago, Illinois, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>The Nation of Ulysses</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>Strung Out</td>\n",
       "      <td>Simi Valley, California, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     artist                            origin\n",
       "3419             Cinderella  Philadelphia, Pennsylvania, U.S.\n",
       "3420  Death From Above 1979          Toronto, Ontario, Canada\n",
       "3421                Chicago  Chicago, Illinois, United States\n",
       "3422  The Nation of Ulysses                  Washington, D.C.\n",
       "3423             Strung Out     Simi Valley, California, U.S."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2772], dtype=int64),)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(artists=='July Talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'July Talk'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[2772]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Code to execute the functions from ``geopy_functions.py``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_to_remove = ['Cemetery Skyline', 'Goat', 'Kingcrow', 'Speed', 'Hyperdontia', 'Vredehammer', 'Weston Super Maim',\n",
    "                'Mdou Moctar', 'AVRALIZE', 'Engulfed', 'Coffin Storm', 'samlrc', 'Little Kid', 'Termina', 'Rorcal',\n",
    "                'Reverence To Paroxysm', 'Voyager', 'Blindfolded and Led to the Woods', 'Mork', 'Yeule', 'Pond',\n",
    "                'Empire State Bastard', 'Blood Command', 'Avatar', 'Brutus', 'Faceless Burial', 'Within Destruction',\n",
    "                'Sedimentum', 'Ataraxy', 'Corpsessed', 'Epitaphe', 'Aldous Harding', 'Messa', 'Ghost', 'Ecchymosis',\n",
    "                'Wormrot', 'Vertebra Atlantis', 'Papangu', 'Sermon of Flames', 'Springtime', 'Monolord', 'Sulphurous',\n",
    "                'LLNN', 'Trna', 'Slaughter To Prevail', 'sonhos tomam conta', 'Galvanizer', 'Ophidian I', 'Diabolizer',\n",
    "                'Morbific', 'Defacement', 'Divide And Dissolve', 'Soen', 'Scorpions', 'Accept', 'Respire', 'Undergang',\n",
    "                'Bearings', 'Scalp', 'Miasmatic Necrosis', 'Teenage Mutant Ninja Turtles', 'Gorephilia', 'Vous Autres',\n",
    "                'Carnation', 'Pharmacist', 'Paara', \"Justice For The Damned\", 'VVilderness', 'Molested Divinity', 'Ellis',\n",
    "                'Kontinuum', 'Monsters', 'Giver', 'Lowrider', 'Vengeful Spectre', 'Vomit the Soul', 'Sadisme', 'Alarmist',\n",
    "                'Klone', 'Nocturnal Departure', 'King Gizzard and The Lizard Wizard', 'Make Them Suffer', 'The Chats',\n",
    "                'Patrick Watson', 'Shirokuma', 'Forests', 'Town Portal', 'Ceremony Of Silence', 'CHAI', 'Baalsebub',\n",
    "                'Minors', 'Mono', 'Tallies', 'Normandie', 'Mouse On The Keys', 'Burial Invocation', 'Orville Peck',\n",
    "                'Lunatic Soul', 'Alex Lahey', 'Hozier', 'Mystifier', 'Hands Like Houses', 'Ruins', 'Autokrator',\n",
    "                'Legend of the Seagullmen', 'Death Toll 80k', 'IDYLLS', 'Spaceslug', 'i hate sex', 'Band-Maid',\n",
    "                'With the Dead', 'Hungry Ghosts', 'Middle Kids', 'Gleb Kolyadin', \"Leaves' Eyes\", \"Phrenelith\",\n",
    "                \"David Brent\", \"Art Of Dying\", \"Minor Victories\", \"Pantha Du Prince\", \"Schammasch\", 'LUH',\n",
    "                'Violet Cold', 'EL VY', 'Shining', 'Hills', \"Mutiny On The Bounty\", 'Lucifer', 'FFS', 'Ranger',\n",
    "                'Trepalium', 'A Textbook Tragedy', 'This Is A Standoff', 'FACT', 'Swallowed', 'Disembarked',\n",
    "                'Wildbirds and Peacedrums', 'Archivist', 'Timber Timbre', 'Newsboys', 'Dope Lemon', 'Vagabon',\n",
    "                'RY X', 'Moonlit Sailor', 'The Drones', 'Sarah Neufeld', 'Say Lou Lou', 'Cruciamentum', 'Lay Down Rotten',\n",
    "                'Dreamshade', 'Sickening Gore', 'Circles', \"Avey Tare's Slasher Flicks\", 'Forest Silence',\n",
    "                \"One Eyed God Prophecy\", 'Coffins', 'Osamu Kitajima', 'Living With Lions', 'Ansur', 'Parades',\n",
    "                \"Intestine Baalism\", 'Comity', 'No Omega', 'Wolverine', 'Disavowed', 'Angel Dust', \"!T.O.O.H.!\",\n",
    "                'Hypnosia', 'Hexenhaus', 'Paradox', 'Deathrow', 'Excruciate', 'FareWell Poetry', 'Sights and Sounds',\n",
    "                'Supersister', \"Birds Of Tokyo\", 'Ark', \"The Flower Kings\", 'Beardfish', 'Graveworm', 'Acid',\n",
    "                'Ladyhawke', 'Geddy Lee', 'Yngwie Malmsteen', \"World's End Girlfriend\", 'Totem Skin', 'Lewis',\n",
    "                'I Hate Sally', \"The Band\", 'Lisa Hannigan', 'Lethal', 'Bubu', 'Van She', 'Mooncake', 'The Haunted',\n",
    "                \"Orphaned Land\", 'Madder Mortem', 'Kataxu', 'Gilberto Gil', 'Vendetta', 'Kvist', 'Acrostichon', 'Pain',\n",
    "                'Obliteration', 'Flames of Hell', 'Wombbath', 'Stone', 'Disgrace', 'Fionn Regan', 'Disastrous Murmur',\n",
    "                'Urfaust', 'Sleepingdog', 'Island', 'Bethlehem', 'Subterranean Masquerade', 'After Dinner', \n",
    "                'Black Boned Angel', 'FM', 'Embrace', 'Solefald', 'Maneige', 'Amberian Dawn', 'OOIOO', 'Anekdoten',\n",
    "                \"Aphrodite's Child\", 'Hollenthon', 'Lykke Li', 'Lenka', 'Sarah McLachlan', 'Owen Pallett',\n",
    "                'Devin Townsend Project', 'Missy Higgins', 'The Devin Townsend Band', 'Selda', 'Massacra', \"Rory Gallagher\",\n",
    "                'Taste', 'Celestial Season', 'Ida Maria', 'Dark Tranquillity', 'Cadaver', 'Pele', 'Exuma',\n",
    "                'Great Lake Swimmers', 'Dawn', 'The Bats', 'Yoko Ono', 'Illogicist', 'The Saints', 'Final Fantasy',\n",
    "                'Pendulum', 'Lunar Aurora', 'Bee Gees', 'Stars', \"David Sylvian and Robert Fripp\", 'Afflicted', 'Lengsel',\n",
    "                'Extol', 'MDFMK', 'Univers Zero', 'Mortuary Drape', 'Zyklon', 'Winds', 'Zyklon-B', 'The Sins of Thy Beloved',\n",
    "                'Lords of Acid', 'Devin Townsend', 'Diablo Swing Orchestra', 'Arcturus', 'Cornelius', 'Manu Chao',\n",
    "                'Bryan Adams', 'Peaches', 'Doro', 'Kingdom Come', 'Pekka Pohjola', 'Shakira', 'Massacre', 'Subhumans',\n",
    "                'Set Fire to Flames', 'Gorgoroth', 'Gandalf', 'Klaus Schulze', 'The Ecstasy of Saint Theresa',\n",
    "                \"Lou Reed and John Cale\", 'Brian Eno and David Byrne', 'Bob Dylan and The Band', 'Era', 'Devil Doll']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended = pd.read_csv('Datasets/df_masters_blended.csv')\n",
    "artists_blend = df_masters_blended['artist'].unique()\n",
    "\n",
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "artists = df_artists_origins['artist'].unique()\n",
    "artists_to_do = []\n",
    "\n",
    "for artist in artists_blend:\n",
    "    if artist not in df_artists_origins['artist'].values and artist not in artists_to_remove:\n",
    "        artists_to_do.append(artist)\n",
    "\n",
    "len(artists_to_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first next 5 artists I'm going to scrape\n",
    "artists_to_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bingo! df_coordinates.csv found \n",
      "\n",
      "1/1 - Circus_Lupus: Madison, Wisconsin, United States\n",
      "2/2 - Devil_Doll_(band): Venice, ItalyLjubljana, Slovenia\n",
      "3/3 - Passenger (singer): Brighton, England, United KingdomGenresFolk rockindie folkindie pop[1]\n",
      "4/4 - The_Ventures: Tacoma, Washington, U.S.\n",
      "5/5 - Castor_(band): Champaign, Illinois, U.S.\n",
      "5/6 - Lou Reed and John Cale: error\n",
      "5/7 - Brian Eno and David Byrne: error\n",
      "6/8 - Dadamah: New Zealand\n",
      "7/9 - Park_(band): Springfield, Illinois\n",
      "8/10 - Idiot_Flesh: Oakland, California\n",
      "8/11 - Bob Dylan and The Band: error\n",
      "9/12 - Era_(band): France\n",
      "10/13 - Lethargy_(band): Rochester, New York, U.S.\n",
      "11/14 - Valium_Aggelein: San Jose, California, U.S.\n",
      "11/15 - Malady: error\n"
     ]
    }
   ],
   "source": [
    "# create the df with the origins scraped from Wikipedia\n",
    "\n",
    "df = pd.read_csv('Datasets/df_masters_blended.csv')\n",
    "start_index = 0\n",
    "final_index = start_index+16\n",
    "\n",
    "df_artists_origins = get_origins_wikipedia(df, start_index, final_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 nulls (26.67 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Circus Lupus</td>\n",
       "      <td>Madison, Wisconsin, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Devil Doll</td>\n",
       "      <td>Venice, ItalyLjubljana, Slovenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Passenger</td>\n",
       "      <td>Brighton, England, United KingdomGenresFolk ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Ventures</td>\n",
       "      <td>Tacoma, Washington, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Castor</td>\n",
       "      <td>Champaign, Illinois, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist                                             origin\n",
       "0  Circus Lupus                  Madison, Wisconsin, United States\n",
       "1    Devil Doll                   Venice, ItalyLjubljana, Slovenia\n",
       "2     Passenger  Brighton, England, United KingdomGenresFolk ro...\n",
       "3  The Ventures                           Tacoma, Washington, U.S.\n",
       "4        Castor                          Champaign, Illinois, U.S."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a subset of the new artists I just got, and tell me if there are nulls\n",
    "df_new_artists = get_new_artists(df_artists_origins)\n",
    "\n",
    "# show the first new artists, if they were duplicates they have been dropped\n",
    "df_new_artists.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 2)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there are null or weird values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls = df_new_artists[df_new_artists['origin'].isna()]\n",
    "nulls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Bob Dylan and The Band\", \"England\", df_new_artists[\"origin\"])\n"
     ]
    }
   ],
   "source": [
    "for artist in nulls['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"England\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking in the internet for the real origins of these artists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Malady\", \"San Diego, CA, United States\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11902</th>\n",
       "      <td>5277808</td>\n",
       "      <td>0</td>\n",
       "      <td>9095175</td>\n",
       "      <td>US</td>\n",
       "      <td>Malady</td>\n",
       "      <td>Malady</td>\n",
       "      <td>2000</td>\n",
       "      <td>61.62</td>\n",
       "      <td>14</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Heavy Metal']</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist_id  master_id  main_release_id release_country  artist   title  \\\n",
       "11902    5277808          0          9095175              US  Malady  Malady   \n",
       "\n",
       "       year  album_length  tracks release_type    genres           styles  \\\n",
       "11902  2000         61.62      14    ['Album']  ['Rock']  ['Heavy Metal']   \n",
       "\n",
       "      artist_profile  \n",
       "11902            NaN  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Malady\".strip()].sort_values('year').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American Technical death metal band, formed in 1997.    Current line-up:  Jason Keyser - Vocals (2011 - present)  Paul\n",
      "Ryan - Guitar, Vocals (1997 - present)  Mike Flores - Bass, Vocals (2001 - present)  John Longstreth - Drums (1999 -\n",
      "2003, 2006 - present)    Former/past member(s)  Vocals :  Mark Manning (1997 - 2001)  James Lee (2001 - 2010)  Mica\n",
      "\"Maniac\" Meneke (2010 - 2011)    Guitar :  Jeremy Turner - Guitar (also vocals) (1997 - 2002, 2007 - 2010)   Clint\n",
      "Appelhanz (1997-?/?-2006) (also vocals) (originally Bass)    Bass :  Doug Williams (1999 - 2001)    Drums :  George\n",
      "Fluke (1997 - 1999)  Jeremy Gregg (live, 2003)  James King (2003 - 2007)\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[6326]['artist_profile']\n",
    "\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, country, city, latitude, longitude, address]\n",
       "Index: []"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins_coordinates[df_artists_origins_coordinates['artist']=='Yoko One']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the original dataframes in case needed (ex: two bands with the same name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[11090, 'artist'] = 'Embrace (US)'\n",
    "df.loc[6140, 'artist'] = 'Embrace (UK)'\n",
    "df.loc[6141, 'artist'] = 'Embrace (UK)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Datasets/df_masters_blended.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>7197</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>The Good Will Out</td>\n",
       "      <td>3.56</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>7198</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>Out Of Nothing</td>\n",
       "      <td>3.39</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>14575</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>3.99</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      album_id   artist              title  rating  votes\n",
       "4485      7197  Embrace  The Good Will Out    3.56     24\n",
       "4486      7198  Embrace     Out Of Nothing    3.39     27\n",
       "8649     14575  Embrace            Embrace    3.99    309"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df_ratings_20 to check it's the correct artist\n",
    "df_ratings_20[df_ratings_20['artist']==\"Embrace\".strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.loc[8649, 'artist'] = 'Embrace (US)'\n",
    "df_ratings_20.loc[4486, 'artist'] = 'Embrace (UK)'\n",
    "df_ratings_20.loc[4485, 'artist'] = 'Embrace (UK)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.to_csv('Datasets/df_ratings_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists['origin'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Drop artists that are not from the UK or the US**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Devil Doll removed\n"
     ]
    }
   ],
   "source": [
    "artists_to_remove = []\n",
    "\n",
    "for artist in artists_to_remove:\n",
    "    try:\n",
    "        artists_usa.remove(artist)\n",
    "        print(f'{artist} removed')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping: 11\n",
      "Rows after dropping: 10\n"
     ]
    }
   ],
   "source": [
    "# I can drop single rows or I can just create a subset with the artists that I want to keep, the ones that are not in the list of artists to remove\n",
    "print(f\"Rows before dropping: {df_new_artists.shape[0]}\")\n",
    "df_new_artists = df_new_artists[~df_new_artists['artist'].isin(artists_to_remove)]\n",
    "print(f\"Rows after dropping: {df_new_artists.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Check short and long origins, probably wrong**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print abnormally short origins and visually check if they are correct\n",
    "for index, row in df_new_artists.iterrows():\n",
    "    if len(row['origin']) < 10:\n",
    "        print(index, row['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Era</td>\n",
       "      <td>France</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Lethargy</td>\n",
       "      <td>Rochester, New York, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Valium Aggelein</td>\n",
       "      <td>San Jose, California, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Malady</td>\n",
       "      <td>San Diego, CA, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             artist                        origin\n",
       "11              Era                        France\n",
       "12         Lethargy     Rochester, New York, U.S.\n",
       "13  Valium Aggelein    San Jose, California, U.S.\n",
       "14           Malady  San Diego, CA, United States"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = 11\n",
    "\n",
    "end_index = start_index+5\n",
    "df_new_artists.loc[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7516</th>\n",
       "      <td>290351</td>\n",
       "      <td>68460</td>\n",
       "      <td>1526914</td>\n",
       "      <td>US</td>\n",
       "      <td>Kingdom Come</td>\n",
       "      <td>Kingdom Come</td>\n",
       "      <td>1988</td>\n",
       "      <td>47.3</td>\n",
       "      <td>10</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Hard Rock', 'Heavy Metal']</td>\n",
       "      <td>Hard Rock/Heavy Metal band from Hamburg, Germa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_id  master_id  main_release_id release_country        artist  \\\n",
       "7516     290351      68460          1526914              US  Kingdom Come   \n",
       "\n",
       "             title  year  album_length  tracks     release_type    genres  \\\n",
       "7516  Kingdom Come  1988          47.3      10  ['LP', 'Album']  ['Rock']   \n",
       "\n",
       "                            styles  \\\n",
       "7516  ['Hard Rock', 'Heavy Metal']   \n",
       "\n",
       "                                         artist_profile  \n",
       "7516  Hard Rock/Heavy Metal band from Hamburg, Germa...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Kingdom Come\t\".strip()].sort_values('year').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American indie rock band formed in 1992 in Boston, Massachusetts and disbanded in 1998.\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[5520]['artist_profile']\n",
    "\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = df_new_artists[df_new_artists['origin'].str.contains('Genres')]\n",
    "genres.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Passenger\", \"UK\", df_new_artists[\"origin\"])\n"
     ]
    }
   ],
   "source": [
    "for artist in genres['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"UK\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Passenger\", \"Brighton, England, UK\", df_new_artists[\"origin\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Passenger</td>\n",
       "      <td>Brighton, England, United KingdomGenresFolk ro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist                                             origin\n",
       "2  Passenger  Brighton, England, United KingdomGenresFolk ro..."
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# individuals that didn't get the right origin in Wikipedia\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Genres')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I create a new column to calculate the lenght of the origin, if it's long it probably didn't scrap correctly Wikipedia\n",
    "df_new_artists[\"origin_length\"] = df_new_artists[\"origin\"].str.len()\n",
    "long_strings = df_new_artists[df_new_artists[\"origin_length\"]>40] # create a df based on these long origins\n",
    "long_strings.shape # to see how many artists I have to take care of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin, origin_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_strings # display the df so I can copy the parts I am interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for artist in long_strings['artist'].values:\n",
    "#     print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"UK\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Embrace (UK)\", \"Huddersfield, West Yorkshire, United Kingdom\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Wham!\", \"Bushey, Hertfordshire, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Earth, Wind and Fire\", \"Chicago, Illinois\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Dazzling Killmen\", \"St. Louis, MO, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Freddie Mercury\", \"Feltham, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Rsdichie\", \"Perth\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Rivdschie\", \"Perth\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I drop the column I just created of 'origin_length'\n",
    "df_new_artists = df_new_artists[['artist', 'origin']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Changing easy values: individuals that didn't get the right origin in Wikipedia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# individuals that didn't get the right origin in Wikipedia\n",
    "df_new_artists[df_new_artists['origin'].str.contains(' and ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Cumbria, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Cumbria')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace('Cumbria', 'Cumberland'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Middlesex, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Middlesex')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', Middlesex', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Yorkshire, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('West Riding of Yorkshire')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', West Riding of Yorkshire', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Merseyside, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Merseyside')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', Merseyside', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from United Kingdom, wrong origin, poor level of detail\n",
    "df_new_artists[df_new_artists['origin']==('United Kingdom')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try a single origin in Geopy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Honolulu, Honolulu County, Hawaii, United States\n",
      "21.304547 -157.855676\n"
     ]
    }
   ],
   "source": [
    "# try to get the right origin of an origin that crashed\n",
    "geolocator = Nominatim(user_agent=\"music_analysis\")\n",
    "\n",
    "origin = \"Honolulu, Hawaii, U.S.\"\n",
    "\n",
    "origin_clean = re.sub(r'\\[\\d+\\]', '', origin).replace('.', '')\n",
    "location = geolocator.geocode(origin_clean)\n",
    "print(f\"{location.address}\")\n",
    "print(location.latitude, location.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Circus Lupus</td>\n",
       "      <td>Madison, Wisconsin, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Devil Doll</td>\n",
       "      <td>Venice, ItalyLjubljana, Slovenia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Passenger</td>\n",
       "      <td>Brighton, England, UK</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The Ventures</td>\n",
       "      <td>Tacoma, Washington, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Castor</td>\n",
       "      <td>Champaign, Illinois, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         artist                             origin\n",
       "0  Circus Lupus  Madison, Wisconsin, United States\n",
       "1    Devil Doll   Venice, ItalyLjubljana, Slovenia\n",
       "2     Passenger              Brighton, England, UK\n",
       "3  The Ventures           Tacoma, Washington, U.S.\n",
       "4        Castor          Champaign, Illinois, U.S."
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = 0\n",
    "\n",
    "end_index = start_index+5\n",
    "df_new_artists[start_index:end_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try all origins in Geopy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Madison, Dane County, Wisconsin, United States\n",
      "1 - Brighton, Brighton and Hove, England, BN1 1HH, United Kingdom\n",
      "2 - Tacoma, Pierce County, Washington, United States\n",
      "3 - Champaign, Champaign County, Illinois, United States\n",
      "4 - New Zealand / Aotearoa\n",
      "5 - Springfield, Sangamon County, Illinois, United States\n",
      "6 - Oakland, Alameda County, California, United States\n",
      "7 - City of Rochester, Monroe County, New York, United States\n",
      "8 - San Jose, Santa Clara County, California, United States\n",
      "9 - San Diego, San Diego County, California, United States\n"
     ]
    }
   ],
   "source": [
    "# try to get the coordinates of the origins from Geopy and see if it crashes (wrong location that I have to change)\n",
    "geolocator = Nominatim(user_agent=\"music_analysis\", timeout=10)\n",
    "\n",
    "initial_index = 0\n",
    "count = initial_index-1\n",
    "\n",
    "for origin in df_new_artists['origin'].str.replace('.', '').str.replace(r'\\[\\d+\\]', '', regex=True)[initial_index:]:\n",
    "    count+=1\n",
    "    location = geolocator.geocode(origin)\n",
    "    print(f\"{count} - {location.address}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Export to .csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoPy wrong locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case GeoPy fails due to a wrong location, I have to delete the new locations, export again, change the location and run GeoPy again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # import the df with the artists' origins already scraped\n",
    "# df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "# df_artists_origins_scraped = df_artists_origins_scraped[0:-20]\n",
    "# df_artists_origins_scraped.to_csv('Datasets/df_artists_origins.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case I created by mistake already 'origin_clean' and I want to drop it\n",
    "# df_new_artists = df_new_artists[['artist', 'origin']]\n",
    "# df_new_artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Export to .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_artists_origins_concat exported to .csv\n",
      "(4888, 2)\n"
     ]
    }
   ],
   "source": [
    "export_artists_origins_concat(df_new_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GeoPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/10 - Madison, Dane County, Wisconsin, United States\n",
      "2/10 - Brighton, Brighton and Hove, England, BN1 1HH, United Kingdom\n",
      "3/10 - Tacoma, Pierce County, Washington, United States\n",
      "4/10 - Champaign, Champaign County, Illinois, United States\n",
      "5/10 - New Zealand / Aotearoa\n",
      "6/10 - Springfield, Sangamon County, Illinois, United States\n",
      "7/10 - Oakland, Alameda County, California, United States\n",
      "8/10 - City of Rochester, Monroe County, New York, United States\n",
      "9/10 - San Jose, Santa Clara County, California, United States\n",
      "10/10 - San Diego, San Diego County, California, United States\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>New Zealand / Aotearoa</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>New Zealand</td>\n",
       "      <td>-41.500083</td>\n",
       "      <td>172.834408</td>\n",
       "      <td>New Zealand / Aotearoa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Brighton</td>\n",
       "      <td>Brighton, England, UK</td>\n",
       "      <td>Brighton, England, UK</td>\n",
       "      <td>50.821463</td>\n",
       "      <td>-0.140056</td>\n",
       "      <td>Brighton, Brighton and Hove, England, BN1 1HH,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United States</td>\n",
       "      <td>Champaign</td>\n",
       "      <td>Champaign, Illinois, U.S.</td>\n",
       "      <td>Champaign, Illinois, US</td>\n",
       "      <td>40.116484</td>\n",
       "      <td>-88.243093</td>\n",
       "      <td>Champaign, Champaign County, Illinois, United ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States</td>\n",
       "      <td>Madison</td>\n",
       "      <td>Madison, Wisconsin, United States</td>\n",
       "      <td>Madison, Wisconsin, United States</td>\n",
       "      <td>43.074761</td>\n",
       "      <td>-89.383761</td>\n",
       "      <td>Madison, Dane County, Wisconsin, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United States</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>Oakland, California</td>\n",
       "      <td>Oakland, California</td>\n",
       "      <td>37.804456</td>\n",
       "      <td>-122.271356</td>\n",
       "      <td>Oakland, Alameda County, California, United St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>United States</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>Rochester, New York, U.S.</td>\n",
       "      <td>Rochester, New York, US</td>\n",
       "      <td>43.157285</td>\n",
       "      <td>-77.615214</td>\n",
       "      <td>City of Rochester, Monroe County, New York, Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United States</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>San Diego, CA, United States</td>\n",
       "      <td>San Diego, CA, United States</td>\n",
       "      <td>32.717420</td>\n",
       "      <td>-117.162772</td>\n",
       "      <td>San Diego, San Diego County, California, Unite...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>United States</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>San Jose, California, U.S.</td>\n",
       "      <td>San Jose, California, US</td>\n",
       "      <td>37.336166</td>\n",
       "      <td>-121.890591</td>\n",
       "      <td>San Jose, Santa Clara County, California, Unit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>United States</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>Springfield, Illinois</td>\n",
       "      <td>Springfield, Illinois</td>\n",
       "      <td>39.799017</td>\n",
       "      <td>-89.643957</td>\n",
       "      <td>Springfield, Sangamon County, Illinois, United...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>United States</td>\n",
       "      <td>Tacoma</td>\n",
       "      <td>Tacoma, Washington, U.S.</td>\n",
       "      <td>Tacoma, Washington, US</td>\n",
       "      <td>47.245501</td>\n",
       "      <td>-122.438329</td>\n",
       "      <td>Tacoma, Pierce County, Washington, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  country         city                             origin  \\\n",
       "0  New Zealand / Aotearoa  New Zealand                        New Zealand   \n",
       "1          United Kingdom     Brighton              Brighton, England, UK   \n",
       "2           United States    Champaign          Champaign, Illinois, U.S.   \n",
       "3           United States      Madison  Madison, Wisconsin, United States   \n",
       "4           United States      Oakland                Oakland, California   \n",
       "5           United States    Rochester          Rochester, New York, U.S.   \n",
       "6           United States    San Diego       San Diego, CA, United States   \n",
       "7           United States     San Jose         San Jose, California, U.S.   \n",
       "8           United States  Springfield              Springfield, Illinois   \n",
       "9           United States       Tacoma           Tacoma, Washington, U.S.   \n",
       "\n",
       "                        origin_clean   latitude   longitude  \\\n",
       "0                        New Zealand -41.500083  172.834408   \n",
       "1              Brighton, England, UK  50.821463   -0.140056   \n",
       "2            Champaign, Illinois, US  40.116484  -88.243093   \n",
       "3  Madison, Wisconsin, United States  43.074761  -89.383761   \n",
       "4                Oakland, California  37.804456 -122.271356   \n",
       "5            Rochester, New York, US  43.157285  -77.615214   \n",
       "6       San Diego, CA, United States  32.717420 -117.162772   \n",
       "7           San Jose, California, US  37.336166 -121.890591   \n",
       "8              Springfield, Illinois  39.799017  -89.643957   \n",
       "9             Tacoma, Washington, US  47.245501 -122.438329   \n",
       "\n",
       "                                             address  \n",
       "0                             New Zealand / Aotearoa  \n",
       "1  Brighton, Brighton and Hove, England, BN1 1HH,...  \n",
       "2  Champaign, Champaign County, Illinois, United ...  \n",
       "3     Madison, Dane County, Wisconsin, United States  \n",
       "4  Oakland, Alameda County, California, United St...  \n",
       "5  City of Rochester, Monroe County, New York, Un...  \n",
       "6  San Diego, San Diego County, California, Unite...  \n",
       "7  San Jose, Santa Clara County, California, Unit...  \n",
       "8  Springfield, Sangamon County, Illinois, United...  \n",
       "9   Tacoma, Pierce County, Washington, United States  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates = get_coordinates_geopy(df_new_artists)\n",
    "df_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_coordinates_scraped: (2089, 7)\n",
      "\n",
      "Found 8 duplicates:\n",
      "             city                 country\n",
      "231   New Zealand  New Zealand / Aotearoa\n",
      "424      Brighton          United Kingdom\n",
      "1122    Champaign           United States\n",
      "1643      Oakland           United States\n",
      "1792    Rochester           United States\n",
      "1825    San Diego           United States\n",
      "1841     San Jose           United States\n",
      "1923       Tacoma           United States\n",
      "\n",
      "Resulting dataset: (2091, 7)\n",
      "Merged artists with coordinates! Found 2 new locations\n",
      "df_coordinates_concat exported to .csv\n"
     ]
    }
   ],
   "source": [
    "export_coordinates_concat(df_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to a .csv file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4883</th>\n",
       "      <td>Park</td>\n",
       "      <td>United States</td>\n",
       "      <td>Springfield</td>\n",
       "      <td>39.799017</td>\n",
       "      <td>-89.643957</td>\n",
       "      <td>Springfield, Sangamon County, Illinois, United...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4884</th>\n",
       "      <td>Idiot Flesh</td>\n",
       "      <td>United States</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>37.804456</td>\n",
       "      <td>-122.271356</td>\n",
       "      <td>Oakland, Alameda County, California, United St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4885</th>\n",
       "      <td>Lethargy</td>\n",
       "      <td>United States</td>\n",
       "      <td>Rochester</td>\n",
       "      <td>43.157285</td>\n",
       "      <td>-77.615214</td>\n",
       "      <td>City of Rochester, Monroe County, New York, Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4886</th>\n",
       "      <td>Valium Aggelein</td>\n",
       "      <td>United States</td>\n",
       "      <td>San Jose</td>\n",
       "      <td>37.336166</td>\n",
       "      <td>-121.890591</td>\n",
       "      <td>San Jose, Santa Clara County, California, Unit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4887</th>\n",
       "      <td>Malady</td>\n",
       "      <td>United States</td>\n",
       "      <td>San Diego</td>\n",
       "      <td>32.717420</td>\n",
       "      <td>-117.162772</td>\n",
       "      <td>San Diego, San Diego County, California, Unite...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist        country         city   latitude   longitude  \\\n",
       "4883             Park  United States  Springfield  39.799017  -89.643957   \n",
       "4884      Idiot Flesh  United States      Oakland  37.804456 -122.271356   \n",
       "4885         Lethargy  United States    Rochester  43.157285  -77.615214   \n",
       "4886  Valium Aggelein  United States     San Jose  37.336166 -121.890591   \n",
       "4887           Malady  United States    San Diego  32.717420 -117.162772   \n",
       "\n",
       "                                                address  \n",
       "4883  Springfield, Sangamon County, Illinois, United...  \n",
       "4884  Oakland, Alameda County, California, United St...  \n",
       "4885  City of Rochester, Monroe County, New York, Un...  \n",
       "4886  San Jose, Santa Clara County, California, Unit...  \n",
       "4887  San Diego, San Diego County, California, Unite...  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with the dataframe containing all the artists and their origins\n",
    "df_artists_origins_coordinates_concat = merge_origins_coordinates(df_new_artists)\n",
    "df_artists_origins_coordinates_concat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4888, 6)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins_coordinates_concat = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')\n",
    "df_artists_origins_coordinates_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "brittish_cities = df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United Kingdom']\n",
    "american_cities = df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "United States     2622\n",
      "United Kingdom    1473\n",
      "Canada             159\n",
      "Australia          110\n",
      "Sverige            107\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "order = df_artists_origins_coordinates_concat['country'].value_counts().index\n",
    "print(df_artists_origins_coordinates_concat['country'].value_counts().head())\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.countplot(df_artists_origins_coordinates_concat['country'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1473 Brittish artists\n",
      "425 Brittish cities\n",
      "\n",
      "city\n",
      "London         398\n",
      "Glasgow         40\n",
      "Birmingham      39\n",
      "Manchester      39\n",
      "Brighton        38\n",
      "Leeds           36\n",
      "Liverpool       30\n",
      "Bristol         25\n",
      "Nottingham      21\n",
      "Sheffield       19\n",
      "Cardiff         16\n",
      "Edinburgh       16\n",
      "Cambridge       15\n",
      "Reading         13\n",
      "Southampton     12\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{brittish_cities.shape[0]} Brittish artists\")\n",
    "order = brittish_cities['city'].value_counts().index\n",
    "print(f\"{brittish_cities['city'].nunique()} Brittish cities\\n\")\n",
    "print(brittish_cities['city'].value_counts().head(15))\n",
    "\n",
    "# plt.figure(figsize=(9,45))\n",
    "# sns.countplot(brittish_cities['city'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2622 American artists\n",
      "674 American cities\n",
      "\n",
      "city\n",
      "Los Angeles      268\n",
      "New York City    160\n",
      "Chicago           96\n",
      "San Francisco     78\n",
      "Seattle           62\n",
      "Brooklyn          57\n",
      "Boston            52\n",
      "Philadelphia      44\n",
      "San Diego         39\n",
      "Portland          35\n",
      "Washington        34\n",
      "New York          30\n",
      "Austin            29\n",
      "Detroit           28\n",
      "Atlanta           27\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{american_cities.shape[0]} American artists\")\n",
    "order = american_cities['city'].value_counts().index\n",
    "print(f\"{american_cities['city'].nunique()} American cities\\n\")\n",
    "print(american_cities['city'].value_counts().head(15))\n",
    "\n",
    "# plt.figure(figsize=(5,55))\n",
    "# sns.countplot(df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United States']['city'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
