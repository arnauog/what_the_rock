{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import time\n",
    "import re\n",
    "\n",
    "# pip install geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from geopy_functions import *\n",
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56660, 13): df_uk_masters\n",
      "(48690, 13): df_us_masters\n",
      "(74652, 13): df_us_new_masters\n",
      "(6708, 13): df_us_new_masters_clean\n",
      "(51222, 5): df_ratings_20\n",
      "(9667, 13): df_masters_blended\n"
     ]
    }
   ],
   "source": [
    "# import the dataframes\n",
    "df_uk_masters = pd.read_csv('Datasets/df_uk_masters.csv')                         # all the albums from the UK\n",
    "df_us_masters = pd.read_csv('Datasets/df_us_masters.csv')                         # albums from the US until 1996, 1998 and 2000\n",
    "df_us_new_masters = pd.read_csv('Datasets/df_us_new_masters.csv')                         # albums from the US from 1997, 1999 and 2001\n",
    "df_us_new_masters_clean = pd.read_csv('Datasets/df_us_new_masters_clean.csv')             # albums from the US from 1997, 1999 and 2001, cleaned, merged with df_ratings_20\n",
    "df_ratings_20 = pd.read_csv('Datasets/df_ratings_20.csv', keep_default_na=False)  # albums with >= 20 votes, mostly from rock, worldwide\n",
    "df_masters_blended = pd.read_csv('Datasets/df_masters_blended.csv')               # albums from the UK and US (and others) with >= 20 votes until 2000 aprox\n",
    "df_artists_origins_coordinates = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')               # merge of df_masters_blended with their locations\n",
    "\n",
    "# print information\n",
    "print(f'{df_uk_masters.shape}: df_uk_masters')\n",
    "print(f'{df_us_masters.shape}: df_us_masters')\n",
    "print(f'{df_us_new_masters.shape}: df_us_new_masters')\n",
    "print(f'{df_us_new_masters_clean.shape}: df_us_new_masters_clean')\n",
    "print(f'{df_ratings_20.shape}: df_ratings_20')\n",
    "print(f'{df_masters_blended.shape}: df_masters_blended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15152368</td>\n",
       "      <td>3747909</td>\n",
       "      <td>31909420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Living Arrows</td>\n",
       "      <td>Hope and Ruin</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Post-Hardcore']</td>\n",
       "      <td>Post-screamo band from Brighton, UK\\r\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id  master_id  main_release_id release_country            artist  \\\n",
       "0   15152368    3747909         31909420             NaN  As Living Arrows   \n",
       "\n",
       "           title  year  album_length  tracks     release_type    genres  \\\n",
       "0  Hope and Ruin  2024           0.0       8  ['LP', 'Album']  ['Rock']   \n",
       "\n",
       "              styles                            artist_profile  \n",
       "0  ['Post-Hardcore']  Post-screamo band from Brighton, UK\\r\\n   "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1441645</td>\n",
       "      <td>396963</td>\n",
       "      <td>3314361</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Devin Townsend Project</td>\n",
       "      <td>Contain Us</td>\n",
       "      <td>2011</td>\n",
       "      <td>1177.03</td>\n",
       "      <td>219</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Electronic', 'Rock', 'Pop']</td>\n",
       "      <td>['Alternative Rock', 'Industrial', 'Prog Rock'...</td>\n",
       "      <td>Rock/metal project of [a251249]. It was founde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id  master_id  main_release_id release_country  \\\n",
       "0    1441645     396963          3314361          Europe   \n",
       "\n",
       "                   artist       title  year  album_length  tracks  \\\n",
       "0  Devin Townsend Project  Contain Us  2011       1177.03     219   \n",
       "\n",
       "  release_type                         genres  \\\n",
       "0    ['Album']  ['Electronic', 'Rock', 'Pop']   \n",
       "\n",
       "                                              styles  \\\n",
       "0  ['Alternative Rock', 'Industrial', 'Prog Rock'...   \n",
       "\n",
       "                                      artist_profile  \n",
       "0  Rock/metal project of [a251249]. It was founde...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_new_masters_clean.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations Wikipedia scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Datasets/df_rock_ratings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets/df_rock_ratings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, keep_default_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m artists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m albums\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Datasets/df_rock_ratings.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/df_rock_ratings.csv', keep_default_na=False)\n",
    "\n",
    "print(f\"{df['artist'].nunique()} artists\")\n",
    "print(f\"{df.shape[0]} albums\")\n",
    "print(f\"Average of {round(df.shape[0] / df['artist'].nunique(), 2)} albums per artist in the subset with the (mostly UK) albums with more than 10 votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3823 artists\n",
      "9380 albums\n",
      "Average of 2.45 albums per artist in the subset with the (mostly UK) albums with more than 20 votes\n"
     ]
    }
   ],
   "source": [
    "df_20 = pd.read_csv('Datasets/df_rock_ratings_20.csv', keep_default_na=False)\n",
    "\n",
    "print(f\"{df_20['artist'].nunique()} artists\")\n",
    "print(f\"{df_20.shape[0]} albums\")\n",
    "print(f\"Average of {round(df_20.shape[0] / df_20['artist'].nunique(), 2)} albums per artist in the subset with the (mostly UK) albums with more than 20 votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51252, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ratings_20 = pd.read_csv('Datasets/df_ratings_20.csv')\n",
    "df_ratings_20.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10580</th>\n",
       "      <td>The 1975</td>\n",
       "      <td>A Brief Inquiry into Online Relationships</td>\n",
       "      <td>2018</td>\n",
       "      <td>58.43</td>\n",
       "      <td>15</td>\n",
       "      <td>['Rock', 'Pop']</td>\n",
       "      <td>['Indie Rock', 'Alternative Rock', 'Indie Pop']</td>\n",
       "      <td>UK &amp; Europe</td>\n",
       "      <td>British indie rock band. \\r\\n\\r\\nPop-rock band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>Le Butcherettes</td>\n",
       "      <td>A Raw Youth</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>Formed by Teri Gender Bender and Auryn Jolene ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>John Fogerty</td>\n",
       "      <td>Centerfield</td>\n",
       "      <td>1985</td>\n",
       "      <td>35.33</td>\n",
       "      <td>9</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Pop Rock', 'Folk Rock', 'Country Rock']</td>\n",
       "      <td>US</td>\n",
       "      <td>American musician, songwriter, and guitarist (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>L7</td>\n",
       "      <td>The Beauty Process: Triple Platinum</td>\n",
       "      <td>1997</td>\n",
       "      <td>41.57</td>\n",
       "      <td>12</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Punk', 'Grunge']</td>\n",
       "      <td>US</td>\n",
       "      <td>American grunge punk/alternative rock band fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>The Fall</td>\n",
       "      <td>Are You Are Missing Winner</td>\n",
       "      <td>2001</td>\n",
       "      <td>47.68</td>\n",
       "      <td>10</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Garage Rock', 'Punk', 'Rockabilly']</td>\n",
       "      <td>UK</td>\n",
       "      <td>Post-punk band from Greater Manchester, UK. 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist                                      title  year  \\\n",
       "10580         The 1975  A Brief Inquiry into Online Relationships  2018   \n",
       "9889   Le Butcherettes                                A Raw Youth  2015   \n",
       "6394      John Fogerty                                Centerfield  1985   \n",
       "4498                L7        The Beauty Process: Triple Platinum  1997   \n",
       "5742          The Fall                 Are You Are Missing Winner  2001   \n",
       "\n",
       "       album_length  tracks           genres  \\\n",
       "10580         58.43      15  ['Rock', 'Pop']   \n",
       "9889           0.00      12         ['Rock']   \n",
       "6394          35.33       9         ['Rock']   \n",
       "4498          41.57      12         ['Rock']   \n",
       "5742          47.68      10         ['Rock']   \n",
       "\n",
       "                                                styles release_country  \\\n",
       "10580  ['Indie Rock', 'Alternative Rock', 'Indie Pop']     UK & Europe   \n",
       "9889                                                []              US   \n",
       "6394         ['Pop Rock', 'Folk Rock', 'Country Rock']              US   \n",
       "4498                                ['Punk', 'Grunge']              US   \n",
       "5742             ['Garage Rock', 'Punk', 'Rockabilly']              UK   \n",
       "\n",
       "                                          artist_profile  \n",
       "10580  British indie rock band. \\r\\n\\r\\nPop-rock band...  \n",
       "9889   Formed by Teri Gender Bender and Auryn Jolene ...  \n",
       "6394   American musician, songwriter, and guitarist (...  \n",
       "4498   American grunge punk/alternative rock band fro...  \n",
       "5742   Post-punk band from Greater Manchester, UK. 19...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9616"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = df['artist'].unique()\n",
    "len(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Life at These Speeds'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[4155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aabsinthe'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist = \"AABSINTHE\"\n",
    "name_changed = artist.title().replace(' ', '_')\n",
    "name_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres\n"
     ]
    }
   ],
   "source": [
    "artist = \"John Grant\"\n",
    "name_changed = artist.replace(' ', '_')\n",
    "name_changed_band = artist.replace(' ', '_') + ('_(band)')\n",
    "name_changed_musician = name_changed + ('_(musician)')\n",
    "\n",
    "url = f\"https://en.wikipedia.org/wiki/{name_changed_musician}\"\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "try:\n",
    "    text = table[0].text\n",
    "\n",
    "    # Step 1: Extract the part after 'Born'\n",
    "    after_born = text.split(\"Born\", 1)[1]\n",
    "\n",
    "    text_age = re.search(\"aged\", after_born)\n",
    "\n",
    "    if text_age:\n",
    "        # This means the musician is dead\n",
    "        location = re.split(r'(19\\d{2})', after_born)[4].split('Died')[0].strip()\n",
    "    else:\n",
    "        try:\n",
    "            text = re.split(r'(19\\d{2})', after_born)[4].split(')')[1]\n",
    "\n",
    "            if \"Other\\xa0names\" in text:\n",
    "                location = text.split('Other\\xa0names')[0]\n",
    "            else:\n",
    "                if \"Citizenship\" in text:\n",
    "                    location = text.split('Citizenship')[0]\n",
    "                else:\n",
    "                    if \"Genres\" in text:\n",
    "                        location = text.split('Genres')[0]\n",
    "                        print('Genres')\n",
    "                    else:\n",
    "                        if \"Occupations\" in text:\n",
    "                            location = text.split('Occupations')[0]\n",
    "                            print('Occupations')\n",
    "                        else:\n",
    "                            location = np.nan\n",
    "        except:  \n",
    "            location = np.nan\n",
    "except:\n",
    "    print('fuck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buchanan, Michigan, U.S.'"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John_Grant_(musician)'"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_changed_musician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = \"Stone Gossard\"\n",
    "name_changed = artist.replace(' ', '_')\n",
    "name_changed_band = artist.replace(' ', '_') + ('_(band)')\n",
    "\n",
    "url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "try:\n",
    "    location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "\n",
    "# save info in lists\n",
    "    print('origin')\n",
    "\n",
    "except:\n",
    "    text = table[0].text\n",
    "\n",
    "    # Step 1: Extract the part after 'Born'\n",
    "    after_born = text.split(\"Born\", 1)[1]\n",
    "\n",
    "    text_age = re.search(\"aged\", after_born)\n",
    "\n",
    "    if text_age:\n",
    "        # This means the artist is dead\n",
    "        print('dead')\n",
    "        location = re.split(r'(19\\d{2})', after_born)[4].split('Died')[0].strip()\n",
    "    else:\n",
    "        try:\n",
    "            text = re.split(r'(19\\d{2})', after_born)[4].split(')')[1]\n",
    "\n",
    "            if \"Other\\xa0names\" in text:\n",
    "                location = text.split('Other\\xa0names')[0]\n",
    "            else:\n",
    "                if \"Citizenship\" in text:\n",
    "                    location = text.split('Citizenship')[0]\n",
    "                else:\n",
    "                    if \"Occupations\" in text:\n",
    "                        location = text.split('Occupations')[0]\n",
    "                    else:\n",
    "                        if \"Genres\" in text:\n",
    "                            location = text.split('Genres')[0]\n",
    "                            print(repr(location))\n",
    "                        else:\n",
    "                            location = np.nan\n",
    "        except:  \n",
    "            location = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seattle, Washington, U.S.GenresAlternative rockgrungeglam punkpunk rockhard rockheavy metalglam metalOccupationsMusiciansongwriterInstrumentsGuitarvocalsYears active'"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seattle, Washington, U.S.GenresAlternative rockgrungeglam punkpunk rockhard rockheavy metalglam metal'"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>Less Than Jake</td>\n",
       "      <td>Losing Streak</td>\n",
       "      <td>3.90</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Sparta</td>\n",
       "      <td>Wiretap Scars</td>\n",
       "      <td>3.79</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Muse</td>\n",
       "      <td>Absolution</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>Muse</td>\n",
       "      <td>Showbiz</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>Finch</td>\n",
       "      <td>What It Is to Burn</td>\n",
       "      <td>3.69</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   album_id          artist               album  rating  votes\n",
       "0        37  Less Than Jake       Losing Streak    3.90    414\n",
       "1        40          Sparta       Wiretap Scars    3.79    431\n",
       "2        41            Muse          Absolution    3.99   4411\n",
       "3        42            Muse             Showbiz    3.50   2181\n",
       "4        45           Finch  What It Is to Burn    3.69    864"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_artists_origins``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3251, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "df_artists_origins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sparta</td>\n",
       "      <td>El Paso, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muse</td>\n",
       "      <td>Teignmouth, Devon, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finch</td>\n",
       "      <td>Temecula, California, Estados Unidos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transplants</td>\n",
       "      <td>Los Angeles, California, United States[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rooney</td>\n",
       "      <td>Los Angeles, California, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist                                     origin\n",
       "0       Sparta                             El Paso, Texas\n",
       "1         Muse                 Teignmouth, Devon, England\n",
       "2        Finch       Temecula, California, Estados Unidos\n",
       "3  Transplants  Los Angeles, California, United States[1]\n",
       "4       Rooney              Los Angeles, California, U.S."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins[df_artists_origins['origin']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists = df_artists_origins[df_artists_origins['origin']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>Son of Dork</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Mojave 3</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>Crippled Black Phoenix</td>\n",
       "      <td>Bristol, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>This Mortal Coil</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>Jade Warrior</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>The Waterboys</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>Blackmore's Night</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>Atomic Rooster</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>The Nefilim</td>\n",
       "      <td>Lambeth, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>Black Spiders</td>\n",
       "      <td>Sheffield, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>Brontide</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>Gilgamesh</td>\n",
       "      <td>Hampstead, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>Young Legionnaire</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>The Deviants</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>Head of David</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>Quintessence</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      artist                                 origin\n",
       "1059             Son of Dork                        London, England\n",
       "1192                Mojave 3                        London, England\n",
       "1326  Crippled Black Phoenix                       Bristol, England\n",
       "1597        This Mortal Coil                    Wandsworth, England\n",
       "2191                 Arcadia                        London, England\n",
       "2300            Jade Warrior                        London, England\n",
       "2348           The Waterboys                        London, England\n",
       "2469       Blackmore's Night         Mount Sinai, NY, United States\n",
       "2556          Atomic Rooster                        London, England\n",
       "2609             The Nefilim                       Lambeth, England\n",
       "2715           Black Spiders                     Sheffield, England\n",
       "2822                Brontide                        London, England\n",
       "2878               Gilgamesh                     Hampstead, England\n",
       "2914       Young Legionnaire                        London, England\n",
       "2924            The Deviants        Ladbroke Grove, London, England\n",
       "2956           Head of David  Dudley, West Midlands, United Kingdom\n",
       "3157            Quintessence                        London, England"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Son of Dork\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Mojave 3\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Crippled Black Phoenix\", \"Bristol, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"This Mortal Coil\", \"Wandsworth, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Arcadia\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Jade Warrior\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Waterboys\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Blackmore's Night\", \"Mount Sinai, NY, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Atomic Rooster\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Nefilim\", \"Lambeth, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Black Spiders\", \"Sheffield, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Brontide\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Gilgamesh\", \"Hampstead, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Young Legionnaire\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Deviants\", \"Ladbroke Grove, London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Head of David\", \"Dudley, West Midlands, United Kingdom\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Quintessence\", \"London, England\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formed in 1969, they played a blend of jazz, progressive rock, Indian Music, and new age rock.   Members included:\n",
      "Sambhu Babaji : Bass  Dave Codling : Guitar  Shiva Shankar Jones : Keyboards, Vocals  Jake Milton : Drums  Alan Mostert\n",
      ": Guitar  Raja Ram : Flute, Piano, Vocals\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[8016]['artist_profile']\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>styles</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>1969</td>\n",
       "      <td>Quintessence</td>\n",
       "      <td>In Blissful Company</td>\n",
       "      <td>3.88</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['Psychedelic Rock']</td>\n",
       "      <td>UK</td>\n",
       "      <td>Formed in 1969, they played a blend of jazz, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year        artist                title  rating  votes  album_length  \\\n",
       "8016  1969  Quintessence  In Blissful Company    3.88     16           0.0   \n",
       "\n",
       "      tracks                styles release_country  \\\n",
       "8016       8  ['Psychedelic Rock']              UK   \n",
       "\n",
       "                                         artist_profile  \n",
       "8016  Formed in 1969, they played a blend of jazz, p...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Quintessence\".strip()].sort_values('votes', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3234, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = df_artists_origins[df_artists_origins['origin']!='United Kingdom']\n",
    "df_artists_origins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists_origins.to_csv('Datasets/df_artists_origins.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_artists_origins_concat exported to .csv\n",
      "(3251, 2)\n"
     ]
    }
   ],
   "source": [
    "export_artists_origins_concat(df_new_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 - London, Greater London, England, United Kingdom\n",
      "2/9 - Bristol, City of Bristol, West of England, England, United Kingdom\n",
      "3/9 - Wandsworth, London Borough of Wandsworth, London, Greater London, England, SW18 1UJ, United Kingdom\n",
      "4/9 - Mount Sinai, Miller Place, Town of Brookhaven, Suffolk County, New York, 11766, United States\n",
      "5/9 - Lambeth, London Borough of Lambeth, London, Greater London, England, SE1 7JW, United Kingdom\n",
      "6/9 - Sheffield, South Yorkshire, England, United Kingdom\n",
      "7/9 - Hampstead, Greater London, England, NW3 1QG, United Kingdom\n",
      "8/9 - Ladbroke Grove, Westway, Lancaster West Estate, North Kensington, Royal Borough of Kensington and Chelsea, London, Greater London, England, W10 5YG, United Kingdom\n",
      "9/9 - Dudley, West Midlands, England, United Kingdom\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Bristol, England</td>\n",
       "      <td>Bristol, England</td>\n",
       "      <td>51.453802</td>\n",
       "      <td>-2.597298</td>\n",
       "      <td>Bristol, City of Bristol, West of England, Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Dudley</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "      <td>52.511083</td>\n",
       "      <td>-2.081681</td>\n",
       "      <td>Dudley, West Midlands, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Hampstead</td>\n",
       "      <td>Hampstead, England</td>\n",
       "      <td>Hampstead, England</td>\n",
       "      <td>51.556530</td>\n",
       "      <td>-0.178301</td>\n",
       "      <td>Hampstead, Greater London, England, NW3 1QG, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Ladbroke Grove</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "      <td>51.517264</td>\n",
       "      <td>-0.211102</td>\n",
       "      <td>Ladbroke Grove, Westway, Lancaster West Estate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Lambeth, England</td>\n",
       "      <td>Lambeth, England</td>\n",
       "      <td>51.495211</td>\n",
       "      <td>-0.116335</td>\n",
       "      <td>Lambeth, London Borough of Lambeth, London, Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>London, England</td>\n",
       "      <td>London, England</td>\n",
       "      <td>51.507446</td>\n",
       "      <td>-0.127765</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>Sheffield, England</td>\n",
       "      <td>Sheffield, England</td>\n",
       "      <td>53.380663</td>\n",
       "      <td>-1.470228</td>\n",
       "      <td>Sheffield, South Yorkshire, England, United Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "      <td>51.457027</td>\n",
       "      <td>-0.193261</td>\n",
       "      <td>Wandsworth, London Borough of Wandsworth, Lond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>United States</td>\n",
       "      <td>Mount Sinai</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "      <td>40.941066</td>\n",
       "      <td>-73.019455</td>\n",
       "      <td>Mount Sinai, Miller Place, Town of Brookhaven,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country            city                                 origin  \\\n",
       "0  United Kingdom         Bristol                       Bristol, England   \n",
       "1  United Kingdom          Dudley  Dudley, West Midlands, United Kingdom   \n",
       "2  United Kingdom       Hampstead                     Hampstead, England   \n",
       "3  United Kingdom  Ladbroke Grove        Ladbroke Grove, London, England   \n",
       "4  United Kingdom         Lambeth                       Lambeth, England   \n",
       "5  United Kingdom          London                        London, England   \n",
       "6  United Kingdom       Sheffield                     Sheffield, England   \n",
       "7  United Kingdom      Wandsworth                    Wandsworth, England   \n",
       "8   United States     Mount Sinai         Mount Sinai, NY, United States   \n",
       "\n",
       "                            origin_clean   latitude  longitude  \\\n",
       "0                       Bristol, England  51.453802  -2.597298   \n",
       "1  Dudley, West Midlands, United Kingdom  52.511083  -2.081681   \n",
       "2                     Hampstead, England  51.556530  -0.178301   \n",
       "3        Ladbroke Grove, London, England  51.517264  -0.211102   \n",
       "4                       Lambeth, England  51.495211  -0.116335   \n",
       "5                        London, England  51.507446  -0.127765   \n",
       "6                     Sheffield, England  53.380663  -1.470228   \n",
       "7                    Wandsworth, England  51.457027  -0.193261   \n",
       "8         Mount Sinai, NY, United States  40.941066 -73.019455   \n",
       "\n",
       "                                             address  \n",
       "0  Bristol, City of Bristol, West of England, Eng...  \n",
       "1     Dudley, West Midlands, England, United Kingdom  \n",
       "2  Hampstead, Greater London, England, NW3 1QG, U...  \n",
       "3  Ladbroke Grove, Westway, Lancaster West Estate...  \n",
       "4  Lambeth, London Borough of Lambeth, London, Gr...  \n",
       "5    London, Greater London, England, United Kingdom  \n",
       "6  Sheffield, South Yorkshire, England, United Ki...  \n",
       "7  Wandsworth, London Borough of Wandsworth, Lond...  \n",
       "8  Mount Sinai, Miller Place, Town of Brookhaven,...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates = get_coordinates_geopy(df_new_artists)\n",
    "df_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_coordinates``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527, 7)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "df_coordinates_scraped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Adelaide, South Australia, Australia</td>\n",
       "      <td>Adelaide, South Australia, Australia</td>\n",
       "      <td>-34.928181</td>\n",
       "      <td>138.599931</td>\n",
       "      <td>Adelaide, Adelaide City Council, South Austral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Adelaide, South Australia</td>\n",
       "      <td>Adelaide, South Australia</td>\n",
       "      <td>-34.928181</td>\n",
       "      <td>138.599931</td>\n",
       "      <td>Adelaide, Adelaide City Council, South Austral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Blue Mountains</td>\n",
       "      <td>Blue Mountains, NSW, Australia</td>\n",
       "      <td>Blue Mountains, NSW, Australia</td>\n",
       "      <td>-33.609741</td>\n",
       "      <td>150.405224</td>\n",
       "      <td>Blue Mountains, New South Wales, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane, Queensland, Australia</td>\n",
       "      <td>Brisbane, Queensland, Australia</td>\n",
       "      <td>-27.468968</td>\n",
       "      <td>153.023499</td>\n",
       "      <td>City of Brisbane, Queensland, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Byron Bay</td>\n",
       "      <td>Byron Bay, New South Wales, Australia</td>\n",
       "      <td>Byron Bay, New South Wales, Australia</td>\n",
       "      <td>-28.648333</td>\n",
       "      <td>153.617778</td>\n",
       "      <td>Byron Bay, Byron Shire Council, New South Wale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country            city                                 origin  \\\n",
       "0  Australia        Adelaide   Adelaide, South Australia, Australia   \n",
       "1  Australia        Adelaide              Adelaide, South Australia   \n",
       "2  Australia  Blue Mountains         Blue Mountains, NSW, Australia   \n",
       "3  Australia        Brisbane        Brisbane, Queensland, Australia   \n",
       "4  Australia       Byron Bay  Byron Bay, New South Wales, Australia   \n",
       "\n",
       "                            origin_clean   latitude   longitude  \\\n",
       "0   Adelaide, South Australia, Australia -34.928181  138.599931   \n",
       "1              Adelaide, South Australia -34.928181  138.599931   \n",
       "2         Blue Mountains, NSW, Australia -33.609741  150.405224   \n",
       "3        Brisbane, Queensland, Australia -27.468968  153.023499   \n",
       "4  Byron Bay, New South Wales, Australia -28.648333  153.617778   \n",
       "\n",
       "                                             address  \n",
       "0  Adelaide, Adelaide City Council, South Austral...  \n",
       "1  Adelaide, Adelaide City Council, South Austral...  \n",
       "2         Blue Mountains, New South Wales, Australia  \n",
       "3            City of Brisbane, Queensland, Australia  \n",
       "4  Byron Bay, Byron Shire Council, New South Wale...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>54.702354</td>\n",
       "      <td>-3.276575</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            country            city          origin    origin_clean  \\\n",
       "702  United Kingdom  United Kingdom  United Kingdom  United Kingdom   \n",
       "\n",
       "      latitude  longitude         address  \n",
       "702  54.702354  -3.276575  United Kingdom  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped[df_coordinates_scraped['city']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country, city, origin, origin_clean, latitude, longitude, address]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped.drop(702, axis=0, inplace=True)\n",
    "df_coordinates_scraped[df_coordinates_scraped['city']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinates_scraped.to_csv('Datasets/df_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_coordinates_scraped: (1526, 7)\n",
      "\n",
      "Found 4 duplicates:\n",
      "               city         country\n",
      "324         Bristol  United Kingdom\n",
      "515  Ladbroke Grove  United Kingdom\n",
      "542          London  United Kingdom\n",
      "650       Sheffield  United Kingdom\n",
      "\n",
      "Resulting dataset: (1531, 7)\n",
      "Merged artists with coordinates! Found 5 new locations\n",
      "df_coordinates_concat exported to .csv\n"
     ]
    }
   ],
   "source": [
    "export_coordinates_concat(df_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_artists_origins_coordinates_concat``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to a .csv file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>Gilgamesh</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Hampstead</td>\n",
       "      <td>51.556530</td>\n",
       "      <td>-0.178301</td>\n",
       "      <td>Hampstead, Greater London, England, NW3 1QG, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>Young Legionnaire</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>51.489334</td>\n",
       "      <td>-0.144055</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>The Deviants</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Ladbroke Grove</td>\n",
       "      <td>51.517264</td>\n",
       "      <td>-0.211102</td>\n",
       "      <td>Ladbroke Grove, Westway, Lancaster West Estate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>Head of David</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Dudley</td>\n",
       "      <td>52.511083</td>\n",
       "      <td>-2.081681</td>\n",
       "      <td>Dudley, West Midlands, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Quintessence</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>51.489334</td>\n",
       "      <td>-0.144055</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist         country            city   latitude  longitude  \\\n",
       "3246          Gilgamesh  United Kingdom       Hampstead  51.556530  -0.178301   \n",
       "3247  Young Legionnaire  United Kingdom          London  51.489334  -0.144055   \n",
       "3248       The Deviants  United Kingdom  Ladbroke Grove  51.517264  -0.211102   \n",
       "3249      Head of David  United Kingdom          Dudley  52.511083  -2.081681   \n",
       "3250       Quintessence  United Kingdom          London  51.489334  -0.144055   \n",
       "\n",
       "                                                address  \n",
       "3246  Hampstead, Greater London, England, NW3 1QG, U...  \n",
       "3247    London, Greater London, England, United Kingdom  \n",
       "3248  Ladbroke Grove, Westway, Lancaster West Estate...  \n",
       "3249     Dudley, West Midlands, England, United Kingdom  \n",
       "3250    London, Greater London, England, United Kingdom  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins_coordinates_concat = merge_origins_coordinates(df_new_artists)\n",
    "df_artists_origins_coordinates_concat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>3821235</td>\n",
       "      <td>1537522</td>\n",
       "      <td>13529787</td>\n",
       "      <td>US</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Entity</td>\n",
       "      <td>2019</td>\n",
       "      <td>38.42</td>\n",
       "      <td>8</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Death Metal']</td>\n",
       "      <td>Death Metal band from Chicago, Illinois, USA. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>3821235</td>\n",
       "      <td>1094310</td>\n",
       "      <td>8362817</td>\n",
       "      <td>US</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Sentient</td>\n",
       "      <td>2016</td>\n",
       "      <td>37.92</td>\n",
       "      <td>9</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Death Metal']</td>\n",
       "      <td>Death Metal band from Chicago, Illinois, USA. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>184256</td>\n",
       "      <td>175620</td>\n",
       "      <td>279855</td>\n",
       "      <td>UK</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>We'll Talk About It Later</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Jazz', 'Rock']</td>\n",
       "      <td>['Fusion', 'Jazz-Funk', 'Jazz-Rock', 'Prog Rock']</td>\n",
       "      <td>Pioneering jazz-rock, progressive, psychedelic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>184256</td>\n",
       "      <td>23574</td>\n",
       "      <td>465143</td>\n",
       "      <td>UK</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Elastic Rock</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Jazz', 'Rock']</td>\n",
       "      <td>['Jazz-Rock', 'Fusion', 'Prog Rock']</td>\n",
       "      <td>Pioneering jazz-rock, progressive, psychedelic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist_id  master_id  main_release_id release_country        artist  \\\n",
       "1004     3821235    1537522         13529787              US  Nucleus (US)   \n",
       "1592     3821235    1094310          8362817              US  Nucleus (US)   \n",
       "5257      184256     175620           279855              UK  Nucleus (UK)   \n",
       "10195     184256      23574           465143              UK  Nucleus (UK)   \n",
       "\n",
       "                           title  year  album_length  tracks     release_type  \\\n",
       "1004                      Entity  2019         38.42       8        ['Album']   \n",
       "1592                    Sentient  2016         37.92       9        ['Album']   \n",
       "5257   We'll Talk About It Later  1971          0.00       7  ['LP', 'Album']   \n",
       "10195               Elastic Rock  1970          0.00      13  ['LP', 'Album']   \n",
       "\n",
       "                 genres                                             styles  \\\n",
       "1004           ['Rock']                                    ['Death Metal']   \n",
       "1592           ['Rock']                                    ['Death Metal']   \n",
       "5257   ['Jazz', 'Rock']  ['Fusion', 'Jazz-Funk', 'Jazz-Rock', 'Prog Rock']   \n",
       "10195  ['Jazz', 'Rock']               ['Jazz-Rock', 'Fusion', 'Prog Rock']   \n",
       "\n",
       "                                          artist_profile  \n",
       "1004   Death Metal band from Chicago, Illinois, USA. ...  \n",
       "1592   Death Metal band from Chicago, Illinois, USA. ...  \n",
       "5257   Pioneering jazz-rock, progressive, psychedelic...  \n",
       "10195  Pioneering jazz-rock, progressive, psychedelic...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended[df_masters_blended['artist'].str.contains('Nucleus')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist_id, master_id, main_release_id, release_country, artist, title, year, album_length, tracks, release_type, genres, styles, artist_profile]\n",
       "Index: []"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended[df_masters_blended['title'].str.contains('Alleycat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29004</th>\n",
       "      <td>86398</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Elastic Rock</td>\n",
       "      <td>3.55</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29120</th>\n",
       "      <td>87140</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>We'll Talk About It Later</td>\n",
       "      <td>3.79</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39636</th>\n",
       "      <td>216509</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Sentient</td>\n",
       "      <td>3.29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45524</th>\n",
       "      <td>333839</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Entity</td>\n",
       "      <td>3.68</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46380</th>\n",
       "      <td>352917</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Alleycat</td>\n",
       "      <td>3.52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       album_id        artist                      title  rating  votes\n",
       "29004     86398  Nucleus (UK)               Elastic Rock    3.55     20\n",
       "29120     87140  Nucleus (UK)  We'll Talk About It Later    3.79     21\n",
       "39636    216509  Nucleus (US)                   Sentient    3.29     29\n",
       "45524    333839  Nucleus (US)                     Entity    3.68     40\n",
       "46380    352917  Nucleus (UK)                   Alleycat    3.52     20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_20[df_ratings_20['artist'].str.contains('Nucleus')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.loc[46380, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[29004, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[29120, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[39636, 'artist'] = 'Nucleus (US)'\n",
    "df_ratings_20.loc[45524, 'artist'] = 'Nucleus (US)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12059, 10)"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([7660, 8037], axis=0, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [album_id, artist, album, rating, votes]\n",
       "Index: []"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist'] = np.where(df['artist']=='pg.99 / Majority Rule', 'Majority Rule', df['artist'])\n",
    "df[df['artist']=='pg.99 / Majority Rule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.to_csv('Datasets/df_ratings_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12059, 10)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing code for strange cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Funeral_for_a_Friend_(band): Bridgend, Wales\n",
      "1 - Millencolin_(band): multiple issues - rebro, Sweden\n",
      "2 - The_Flaming_Lips_(band): Oklahoma City, Oklahoma, U.S.\n",
      "3 - Feeder_(band): Feeder in 2008\n",
      "4 - Descendents_(band): Manhattan Beach, California, U.S.\n",
      "5 - PJ Harvey: no location found\n",
      "6 - Godsmack_(band): Lawrence, Massachusetts U.S.\n",
      "7 - Blind_Faith_(band): Ripley, Surrey, England\n",
      "8 - Van_Halen_(band): Pasadena, California, U.S.\n",
      "9 - Damageplan_(band): Dallas, Texas, U.S.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/df_ratings.csv')\n",
    "artists = df['artist'].unique()\n",
    "\n",
    "artists_list = []\n",
    "origin_list = []\n",
    "count=0\n",
    "\n",
    "for index in artists[140:150]:\n",
    "\n",
    "    artists_list.append(index)\n",
    "    name_changed = index.replace(' ', '_')\n",
    "    name_changed_band = name_changed + ('_(band)')\n",
    "\n",
    "    try:\n",
    "        url = f\"https://en.wikipedia.org/wiki/{name_changed_band}\"\n",
    "        response = requests.get(url).content\n",
    "        soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "        origin = soup.select('table tr th', class_='infobox-label')\n",
    "\n",
    "        if len(origin) > 0:\n",
    "            try:\n",
    "                if origin[2].text == 'Origin':\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[1].text\n",
    "                elif origin[3].text == 'Origin':\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[2].text\n",
    "                # else:\n",
    "                    \n",
    "                if 'multiple issues' in location:\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[7].text        \n",
    "                    print(f'{count} - {name_changed_band}: multiple issues - {location}')\n",
    "                    origin_list.append(location)\n",
    "                elif 'additional citations' in location:\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[3].text        \n",
    "                    print(f'{count} - {name_changed_band}: additional citations - {location}')\n",
    "                    origin_list.append(location)\n",
    "\n",
    "                else:\n",
    "                    print(f'{count} - {name_changed_band}: {location}')\n",
    "                    origin_list.append(location)\n",
    "            except:\n",
    "                print(f'{count} - {name_changed_band}: {location}')\n",
    "                origin_list.append(location)      \n",
    "        else:\n",
    "            try:\n",
    "                url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "                response = requests.get(url).content\n",
    "                soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "                origin = soup.select('table tr th', class_='infobox-label')\n",
    "\n",
    "                if len(origin) > 0:\n",
    "                    if origin[2].text == 'Origin':\n",
    "                        location = soup.select('table tr td', class_='infobox-data')[1].text\n",
    "\n",
    "                        if 'multiple issues' in location:\n",
    "                            location = soup.select('table tr td', class_='infobox-data')[7].text        \n",
    "                            print(f'{count} - {name_changed_band}: multiple issues - {location}')\n",
    "                            origin_list.append(location)\n",
    "                        elif 'additional citations' in location:\n",
    "                            location = soup.select('table tr td', class_='infobox-data')[3].text        \n",
    "                            print(f'{count} - {name_changed_band}: additional citations - {location}')\n",
    "                            origin_list.append(location)\n",
    "                        else:\n",
    "                            print(f'{count} - {name_changed_band}: {location}')\n",
    "                            origin_list.append(location)\n",
    "\n",
    "                    elif origin[3].text == 'Origin':\n",
    "                        location = soup.select('table tr td', class_='infobox-data')[2].text\n",
    "                        print(f'{count} - {name_changed_band}: {location}')\n",
    "                        origin_list.append(location) \n",
    "\n",
    "                    else:\n",
    "                        print(f'{count} - {index}: no location found')\n",
    "                        origin_list.append(np.nan)  \n",
    "                else:\n",
    "                    print(f'{count} - {index}: short length')\n",
    "                    origin_list.append(np.nan)\n",
    "            except:\n",
    "                print(f'{count} - {index}: error')\n",
    "                origin_list.append(np.nan)\n",
    "    except:\n",
    "        print(f'{count} - {index}: error')\n",
    "        origin_list.append(np.nan)\n",
    "\n",
    "    if len(artists_list) != len(origin_list):\n",
    "        print('different lengths')\n",
    "        break\n",
    "\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_origins_wikipedia(df, start_index, final_index):\n",
    "    df = pd.read_csv('Datasets/df_rock_ratings_20.csv')\n",
    "    artists = df['artist'].unique()\n",
    "\n",
    "    try:\n",
    "    # import the DataFrame with the locations whose coordinates I already have\n",
    "        df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "        print('Bingo! df_coordinates.csv found \\n')\n",
    "    except: \n",
    "        print('df_coordinates.csv not found \\n')\n",
    "\n",
    "    artists_list = []\n",
    "    origin_list = []\n",
    "    count=0\n",
    "    scraped=0\n",
    "\n",
    "    for index in artists_us_to_do[start_index:final_index]:\n",
    "\n",
    "        name_changed = index.replace(' ', '_')\n",
    "        name_changed_band = name_changed + ('_(band)')\n",
    "\n",
    "        try:\n",
    "            url = f\"https://en.wikipedia.org/wiki/{name_changed_band}\"\n",
    "            response = requests.get(url).content\n",
    "            soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "            table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "            location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "            city = location.split(', ')[0]\n",
    "            count+=1\n",
    "            \n",
    "        # save info in lists\n",
    "            artists_list.append(index)  \n",
    "            origin_list.append(location)\n",
    "            scraped+=1\n",
    "            print(f'{scraped}/{count} - {name_changed_band}: {location}')\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "                response = requests.get(url).content\n",
    "                soup = BeautifulSoup(response, \"html.parser\")\n",
    "                table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "                try:\n",
    "                    location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1 \n",
    "    \n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed}: {location}')\n",
    "\n",
    "                except:\n",
    "                    location = table[0].text.split(')')[2].split('Genres')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1\n",
    "\n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed} (individual): {location}')\n",
    "\n",
    "            except:\n",
    "                try:\n",
    "                    url = f\"https://es.wikipedia.org/wiki/{name_changed}\"\n",
    "                    response = requests.get(url).content\n",
    "                    soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "                    table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "                    location = table[0].text.split('Origen\\n')[1].split(' Informacin')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1    \n",
    "    \n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed} (espaol): {location}')\n",
    "\n",
    "                except:\n",
    "                    count+=1\n",
    "                    print(f'{scraped}/{count} - {index}: error')\n",
    "                    artists_list.append(index) \n",
    "                    origin_list.append(np.nan)\n",
    "\n",
    "        if len(artists_list) != len(origin_list):\n",
    "            print('different lengths')\n",
    "            break\n",
    "\n",
    "    df_artists_origins = pd.DataFrame({'artist': artists_list\n",
    "                             , 'origin': origin_list})\n",
    "    \n",
    "    return df_artists_origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_artists(df_artists_origins):\n",
    "\n",
    "# import the df with the artists' origins already scraped\n",
    "    df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "\n",
    "    if df_artists_origins['origin'].isna().sum() == 0:        \n",
    "        print(\"No null values, but let's take a look just in case there are weird locations\")\n",
    "\n",
    "    else: \n",
    "    # take a look at the df with the new artists and make sure there are non null values in origin (when it couldn't find it in Wikipedia)\n",
    "        print(f'{round(df_artists_origins['origin'].isna().sum() / df_artists_origins.shape[0]*100, 2)} % of nulls')\n",
    "    \n",
    "# subset of the new artists I just got, wether there are null values or not\n",
    "    df_new_artists = df_artists_origins[~df_artists_origins['artist'].isin(df_artists_origins_scraped['artist'].values)]\n",
    "\n",
    "    print(\"Here is the dataframe with the new artists, without duplicates\")\n",
    "    return df_new_artists   # so I can take a look at it and then continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_artists_origins_concat(df_new_artists):\n",
    "\n",
    "# import the df with the artists' origins already scraped\n",
    "    df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "\n",
    "# concat with the df I just got\n",
    "    df_artists_origins_concat = pd.concat([df_artists_origins_scraped, df_new_artists])\n",
    "    df_artists_origins_concat.drop_duplicates(inplace=True)     # just in case\n",
    "    df_artists_origins_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# export all the artists and their origins to a .csv file (the ones I got plus the new artists)\n",
    "    df_artists_origins_concat.to_csv('Datasets/df_artists_origins.csv', index=False)\n",
    "    print('df_artists_origins_concat exported to .csv')\n",
    "    print(df_artists_origins_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_geopy(df_new_artists):\n",
    "    \n",
    "# replace special characters for spaces\n",
    "    df_new_artists['origin_clean'] = df_new_artists['origin'].str.replace('.', '')\n",
    "    df_new_artists['origin_clean'] = df_new_artists['origin_clean'].str.replace(r'\\[\\d+\\]', '', regex=True)\n",
    "\n",
    "# run the function that gets the coordinates from the origins from Geopy\n",
    "    geolocator = Nominatim(user_agent=\"music_analysis\", timeout=10)\n",
    "\n",
    "# if they are 'dirty' origins that after the cleaning, they result in the same 'origin_clean'\n",
    "    df_unique = df_new_artists[['origin', 'origin_clean']].drop_duplicates() \n",
    "    unique_origins = df_unique['origin'].values\n",
    "    unique_origins_clean = df_unique['origin_clean'].values\n",
    "\n",
    "    country_list = []\n",
    "    city_list = []\n",
    "    latitude_list = []\n",
    "    longitude_list = []\n",
    "    address_list = []\n",
    "    lists = [country_list, city_list, latitude_list, longitude_list, address_list]\n",
    "    count = 0\n",
    "\n",
    "    for origin in unique_origins_clean:\n",
    "        count+=1\n",
    "        time.sleep(1)\n",
    "        location = geolocator.geocode(origin)\n",
    "\n",
    "        print(f'{count}/{len(unique_origins_clean)} - {location.address}')  \n",
    "\n",
    "    # save the info in lists\n",
    "        country_list.append(location.address.split(', ')[-1])\n",
    "        city_list.append(origin.split(', ')[0])\n",
    "        latitude_list.append(location.latitude)\n",
    "        longitude_list.append(location.longitude)\n",
    "        address_list.append(location.address)\n",
    "\n",
    "        # # Check lengths\n",
    "        # print(f\"{count}/{len(unique_origins_clean)} - {origin}\")\n",
    "        # print(f\"Current list lengths -> country: {len(country_list)}, city: {len(city_list)}, \"\n",
    "        #     f\"lat: {len(latitude_list)}, lon: {len(longitude_list)}, address: {len(address_list)}\")\n",
    "\n",
    "    df_coordinates = pd.DataFrame({'country': country_list\n",
    "                                , 'city': city_list\n",
    "                                , 'origin': unique_origins\n",
    "                                , 'origin_clean': unique_origins_clean\n",
    "                                , 'latitude': latitude_list\n",
    "                                , 'longitude': longitude_list\n",
    "                                , 'address': address_list})\n",
    "    df_coordinates.sort_values(['country', 'city'], inplace=True) # sort by country and city\n",
    "    df_coordinates.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_coordinates_concat(df_coordinates):\n",
    "\n",
    "# import the last df that contains the coordinates of the unique origins\n",
    "    df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "    print(f\"df_coordinates_scraped: {df_coordinates_scraped.shape}\\n\")\n",
    "\n",
    "# concat with the df of the coordinates I just got\n",
    "    df_coordinates_concat = pd.concat([df_coordinates_scraped, df_coordinates])\n",
    "    df_coordinates_concat.sort_values(['country', 'city'], inplace=True) # sort by country and city\n",
    "    df_coordinates_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# look for duplicates in the origin, between the locations I had already gotten and the new ones\n",
    "    check_duplicates_origins(df_coordinates_concat)\n",
    "    new_origins = df_coordinates_concat.shape[0] - df_coordinates_scraped.shape[0]\n",
    "    print(f\"Merged artists with coordinates! Found {new_origins} new locations\")\n",
    "\n",
    "# save it in a csv file (the coordinates I had plus the ones from the new artists I just got)\n",
    "    df_coordinates_concat.to_csv('Datasets/df_coordinates.csv', index=False)\n",
    "    print('df_coordinates_concat exported to .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_origins_coordinates(df_new_artists):\n",
    "\n",
    "# import the last df that contains the coordinates of the unique origins\n",
    "    df_coordinates_concat = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "\n",
    "# merge with the previous df with the artists\n",
    "    df_artists_origins_coordinates = pd.merge(df_new_artists, df_coordinates_concat, on=['origin'])\n",
    "    df_artists_origins_coordinates.drop(columns=['origin', 'origin_clean_x', 'origin_clean_y'], inplace=True)\n",
    "\n",
    "# import the df that contains info of the artists and the coordinates of their origins\n",
    "    df_artists_origins_coordinates_scraped = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')\n",
    "\n",
    "# concat to get the df with all the artists, origins and their coordinates\n",
    "    df_artists_origins_coordinates_concat = pd.concat([df_artists_origins_coordinates_scraped, df_artists_origins_coordinates])\n",
    "    df_artists_origins_coordinates_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# save it in a csv file\n",
    "    df_artists_origins_coordinates_concat.to_csv('Datasets/df_artists_origins_coordinates.csv', index=False)\n",
    "    print(\"Exported to a .csv file\")\n",
    "\n",
    "    return df_artists_origins_coordinates_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dataframes and look for the ``new_artists``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4527"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_blend = df_masters_blended['artist'].unique()\n",
    "len(artists_blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1555"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "artists = df_artists_origins['artist'].unique()\n",
    "artists_usa = []\n",
    "\n",
    "for artist in artists_blend:\n",
    "    if artist not in df_artists_origins['artist'].values:\n",
    "        artists_usa.append(artist)\n",
    "\n",
    "len(artists_usa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As Living Arrows',\n",
       " 'Hidden Mothers',\n",
       " 'Tiny Moving Parts',\n",
       " 'Poppy',\n",
       " 'State Champs',\n",
       " 'Oso Oso',\n",
       " 'Better Lovers',\n",
       " 'Lowen',\n",
       " 'Halsey',\n",
       " 'Amyl and the Sniffers',\n",
       " 'Delta Sleep',\n",
       " 'High Vis',\n",
       " 'Cemetery Skyline',\n",
       " 'Goat',\n",
       " 'Chat Pile',\n",
       " 'Drug Church',\n",
       " 'Origami Angel',\n",
       " 'Heriot',\n",
       " 'Nightwish',\n",
       " 'Foxing',\n",
       " 'Alora Crucible',\n",
       " 'Wage War',\n",
       " 'TURQUOISEDEATH',\n",
       " 'Dawn Treader',\n",
       " 'Boston Manor',\n",
       " 'MJ Lenderman',\n",
       " 'Fat Dog',\n",
       " 'Kingcrow',\n",
       " 'Leprous',\n",
       " 'Wunderhorse',\n",
       " 'thrown',\n",
       " 'Horse Jumper of Love',\n",
       " 'Within the Ruins',\n",
       " 'Magdalena Bay',\n",
       " 'Fontaines D.C.',\n",
       " 'beabadoobee',\n",
       " 'State Faults',\n",
       " 'Graphic Nature',\n",
       " 'The Home Team',\n",
       " 'Speed',\n",
       " 'Remi Wolf',\n",
       " 'Clairo',\n",
       " 'Crippling Alcoholism',\n",
       " 'Cigarettes After Sex',\n",
       " 'Abriction',\n",
       " 'Pijn',\n",
       " 'Outlander',\n",
       " 'Imagine Dragons',\n",
       " 'The Dangerous Summer',\n",
       " 'Pond',\n",
       " 'Hyperdontia',\n",
       " 'Vredehammer',\n",
       " 'Pedro the Lion',\n",
       " 'Weston Super Maim',\n",
       " 'Stand Still',\n",
       " 'Mortal Wound',\n",
       " 'Eye of Solitude',\n",
       " 'Beth Gibbons',\n",
       " 'Contention',\n",
       " 'Knocked Loose',\n",
       " 'Mdou Moctar',\n",
       " 'The Lemon Twigs',\n",
       " 'Mk.Gee',\n",
       " 'Vennart',\n",
       " 'Microwave',\n",
       " 'Mastiff',\n",
       " 'Skycamefalling',\n",
       " 'SeeYouSpaceCowboy',\n",
       " 'Jamie Lenman',\n",
       " 'AVRALIZE',\n",
       " 'Imminence',\n",
       " 'Aaron West and The Roaring Twenties',\n",
       " 'Lo Moon',\n",
       " 'English Teacher',\n",
       " 'Engulfed',\n",
       " 'Khruangbin',\n",
       " 'Coffin Storm',\n",
       " 'Blanket',\n",
       " 'Boundaries',\n",
       " 'Adrianne Lenker',\n",
       " 'samlrc',\n",
       " 'Sticky Fingers',\n",
       " 'Bleachers',\n",
       " 'Stay Inside',\n",
       " 'Mannequin Pussy',\n",
       " 'Yard Act',\n",
       " 'Faye Webster',\n",
       " 'Little Kid',\n",
       " 'Job For A Cowboy',\n",
       " 'IDLES',\n",
       " 'Ihsahn',\n",
       " 'Laura Jane Grace',\n",
       " 'The Chisel',\n",
       " 'The Last Dinner Party',\n",
       " 'NewDad',\n",
       " 'Frank Carter and the Rattlesnakes',\n",
       " 'Tapir!',\n",
       " 'Neck Deep',\n",
       " 'Casey',\n",
       " 'Marika Hackman',\n",
       " 'Slift',\n",
       " 'Sprints',\n",
       " 'Killing Me Softly',\n",
       " 'Rannoch',\n",
       " 'Termina',\n",
       " 'Harp',\n",
       " 'Empty Country',\n",
       " 'Free Throw',\n",
       " 'Psychedelic Porn Crumpets',\n",
       " 'Dying Wish',\n",
       " 'END',\n",
       " 'Wargasm',\n",
       " 'Maria BC',\n",
       " 'Myrkur',\n",
       " 'Knuckle Puck',\n",
       " 'Creeper',\n",
       " 'Beartooth',\n",
       " 'Blood Command',\n",
       " 'Rorcal',\n",
       " 'Yeule',\n",
       " 'Slow Pulp',\n",
       " 'Dead and Dripping',\n",
       " 'Koyo',\n",
       " 'Shade Empire',\n",
       " 'TesseracT',\n",
       " 'Explosions in the Sky',\n",
       " 'Cursetheknife',\n",
       " 'Olivia Rodrigo',\n",
       " 'Uada',\n",
       " 'Pain of Truth',\n",
       " 'Reverence To Paroxysm',\n",
       " 'Royal Blood',\n",
       " 'Celestial Sanctuary',\n",
       " 'Empire State Bastard',\n",
       " 'Jeff Rosenstock',\n",
       " 'Spanish Love Songs',\n",
       " 'Urne',\n",
       " 'Movements',\n",
       " 'Caskets',\n",
       " 'Fiddlehead',\n",
       " 'Sunami',\n",
       " 'Teenage Wrist',\n",
       " 'Deitus',\n",
       " 'Mutoid Man',\n",
       " 'Voyager',\n",
       " 'Dawnwalker',\n",
       " 'PVRIS',\n",
       " 'Julie Byrne',\n",
       " 'Blindfolded and Led to the Woods',\n",
       " 'Nothing But Thieves',\n",
       " 'Grian Chatten',\n",
       " 'Model/Actriz',\n",
       " 'Burner',\n",
       " 'Death Goals',\n",
       " 'King Krule',\n",
       " 'feeble little horse',\n",
       " 'Noah Kahan',\n",
       " 'Squid',\n",
       " 'Tigercub',\n",
       " 'Pupil Slicer',\n",
       " 'Protomartyr',\n",
       " 'Phoxjaw',\n",
       " 'Bully',\n",
       " 'Wytch Hazel',\n",
       " 'Water From Your Eyes',\n",
       " 'Incendiary',\n",
       " 'bar italia',\n",
       " 'Sleep Token',\n",
       " 'Mandy, Indiana',\n",
       " 'Covet',\n",
       " 'The Amity Affliction',\n",
       " 'Veil of Maya',\n",
       " 'Currents',\n",
       " 'Crown the Empire',\n",
       " 'There Will Be Fireworks',\n",
       " 'Waterparks',\n",
       " 'Blondshell',\n",
       " 'HMLTD',\n",
       " 'deathcrash',\n",
       " 'Wednesday',\n",
       " 'Gel',\n",
       " 'Allfather',\n",
       " 'Bury Tomorrow',\n",
       " 'City and Colour',\n",
       " 'Boygenius',\n",
       " \"Dawn Ray'd\",\n",
       " 'BABYMETAL',\n",
       " 'Mork',\n",
       " 'Green Druid',\n",
       " 'M83',\n",
       " '100 Gecs',\n",
       " 'Periphery',\n",
       " 'Sleaford Mods',\n",
       " 'Acres',\n",
       " \"Can't Swim\",\n",
       " 'Pest Control',\n",
       " 'Host',\n",
       " 'U.S. Girls',\n",
       " 'Shame',\n",
       " 'Avatar',\n",
       " 'Hellripper',\n",
       " 'Avey Tare',\n",
       " 'A Wake in Providence',\n",
       " 'Pigs Pigs Pigs Pigs Pigs Pigs Pigs',\n",
       " 'Ihlo',\n",
       " 'Narrow Head',\n",
       " 'Emarosa',\n",
       " 'Molly',\n",
       " 'The Murder Capital',\n",
       " 'Margo Price',\n",
       " 'Weyes Blood',\n",
       " 'Turnover',\n",
       " 'Demon Hunter',\n",
       " \"Arm's Length\",\n",
       " 'Fit for a King',\n",
       " 'Dead Cross',\n",
       " 'Abduction',\n",
       " 'Brutus',\n",
       " 'Dry Cleaning',\n",
       " 'The 1975',\n",
       " 'Lacuna Coil',\n",
       " 'Gilla Band',\n",
       " 'Alvvays',\n",
       " 'Counterparts',\n",
       " 'Vacuous',\n",
       " 'Faceless Burial',\n",
       " 'Drowning Pool',\n",
       " 'Within Destruction',\n",
       " 'Miss May I',\n",
       " 'Escuela Grind',\n",
       " 'No Devotion',\n",
       " 'Holy Fawn',\n",
       " 'Courting',\n",
       " 'Tamino',\n",
       " 'Horsey',\n",
       " 'Inclination',\n",
       " 'Rina Sawayama',\n",
       " 'Electric Callboy',\n",
       " 'Camping In Alaska',\n",
       " 'Slaughterhouse',\n",
       " 'YUNGBLUD',\n",
       " 'Stella Donnelly',\n",
       " 'Julia Jacklin',\n",
       " 'Pale Waves',\n",
       " 'The Halo Effect',\n",
       " 'Sedimentum',\n",
       " 'Pool Kids',\n",
       " 'Ithaca',\n",
       " 'Dance Gavin Dance',\n",
       " 'Molder',\n",
       " 'Black Midi',\n",
       " 'Say Sue Me',\n",
       " 'Viagra Boys',\n",
       " 'Wormrot',\n",
       " 'Momma',\n",
       " 'Petrol Girls',\n",
       " 'Saor',\n",
       " 'Soccer Mommy',\n",
       " 'Sunrise Patriot Motion',\n",
       " 'Nova Twins',\n",
       " 'Ataraxy',\n",
       " 'Otoboke Beaver',\n",
       " 'Motionless In White',\n",
       " 'Corpsessed',\n",
       " 'Blood Youth',\n",
       " 'Horsegirl',\n",
       " 'Just Mustard',\n",
       " 'Malevolence',\n",
       " 'Harry Styles',\n",
       " 'Porridge Radio',\n",
       " 'Toad',\n",
       " 'Rolling Blackouts Coastal Fever',\n",
       " 'Bodysnatcher',\n",
       " 'Static Dress',\n",
       " 'Halestorm',\n",
       " 'Stand Atlantic',\n",
       " 'Proper.',\n",
       " 'Black Sheep Wall',\n",
       " 'Hatchie',\n",
       " 'Prince Daddy and The Hyena',\n",
       " 'Undeath',\n",
       " 'Epitaphe',\n",
       " 'Envy of None',\n",
       " 'Helpless',\n",
       " 'Wet Leg',\n",
       " 'PUP',\n",
       " 'Camp Cope',\n",
       " 'Ditz',\n",
       " 'Aldous Harding',\n",
       " 'Indian Summer',\n",
       " 'Machine Gun Kelly',\n",
       " 'Animals As Leaders',\n",
       " 'Yumi Zouma',\n",
       " 'Twelve Foot Ninja',\n",
       " 'Belmont',\n",
       " 'Messa',\n",
       " 'Chalk Hands',\n",
       " 'Ghost',\n",
       " 'Cryptworm',\n",
       " 'Mountaineer',\n",
       " 'Ecchymosis',\n",
       " 'Bloodywood',\n",
       " 'Sasami',\n",
       " 'Avril Lavigne',\n",
       " 'Mom Jeans.',\n",
       " 'Caroline',\n",
       " 'Scorpions',\n",
       " 'Evergreen',\n",
       " 'Sea Power',\n",
       " 'Big Thief',\n",
       " 'As It Is',\n",
       " 'Grivo',\n",
       " 'Mitski',\n",
       " 'Pinegrove',\n",
       " 'Black Country, New Road',\n",
       " 'Bad Omens',\n",
       " 'Voices',\n",
       " 'Comeback Kid',\n",
       " 'Shadow Of Intent',\n",
       " 'Vertebra Atlantis',\n",
       " 'Slow Crush',\n",
       " 'Unfurl',\n",
       " 'Geese',\n",
       " 'Papangu',\n",
       " 'Damon Albarn',\n",
       " 'Sermon of Flames',\n",
       " 'Springtime',\n",
       " 'Snail Mail',\n",
       " 'Emma Ruth Rundle',\n",
       " 'Courtney Barnett',\n",
       " 'Black Veil Brides',\n",
       " 'Frontierer',\n",
       " 'Monolord',\n",
       " 'Sulphurous',\n",
       " 'Black Marble',\n",
       " 'Ice Nine Kills',\n",
       " 'I Feel Fine',\n",
       " 'Sugar Horse',\n",
       " 'Dean Blunt',\n",
       " 'Sam Fender',\n",
       " \"KK's Priest\",\n",
       " 'Full of Hell',\n",
       " 'Tremonti',\n",
       " 'LLNN',\n",
       " 'Spiritbox',\n",
       " 'Aborted',\n",
       " 'Kacey Musgraves',\n",
       " 'Trna',\n",
       " 'Slaughter To Prevail',\n",
       " 'sonhos tomam conta',\n",
       " 'Bossk',\n",
       " 'Indigo De Souza',\n",
       " 'Deafheaven',\n",
       " 'Wolves in the Throne Room',\n",
       " 'Qrixkuor',\n",
       " 'Trash Boat',\n",
       " 'Galvanizer',\n",
       " 'Yola',\n",
       " 'Torres',\n",
       " 'LUMP',\n",
       " 'The Maine',\n",
       " 'Ophidian I',\n",
       " 'Diabolizer',\n",
       " 'Descendents',\n",
       " 'Lightning Bug',\n",
       " 'Atvm',\n",
       " 'Project 86',\n",
       " 'Lovesliescrushing',\n",
       " 'Hacktivist',\n",
       " 'Lucy Dacus',\n",
       " 'Portal',\n",
       " 'Ceremonium',\n",
       " 'Nexilva',\n",
       " 'Fear Factory',\n",
       " 'Morbific',\n",
       " 'Marina',\n",
       " 'Our Hollow, Our Home',\n",
       " 'Wolf Alice',\n",
       " 'Tilian',\n",
       " 'Bachelor',\n",
       " 'Noctule',\n",
       " 'Japanese Breakfast',\n",
       " 'Home Is Where',\n",
       " 'Manchester Orchestra',\n",
       " 'The Raging Nathans',\n",
       " 'Holding Absence',\n",
       " 'Flock of Dimes',\n",
       " \"'68\",\n",
       " 'Genghis Tron',\n",
       " 'Ominous Ruin',\n",
       " 'Cassandra Jenkins',\n",
       " 'Julien Baker',\n",
       " 'Love and Death',\n",
       " 'Defacement',\n",
       " 'Divide And Dissolve',\n",
       " 'TV Priest',\n",
       " 'Lamp of Murmuur',\n",
       " 'Goat Girl',\n",
       " 'Soen',\n",
       " 'Accept',\n",
       " 'Pom Poko',\n",
       " 'The Casket Lottery',\n",
       " 'Parquet Courts',\n",
       " 'Pearl Charles',\n",
       " 'Respire',\n",
       " 'Teenage Mutant Ninja Turtles',\n",
       " 'Dominic Fike',\n",
       " 'Undergang',\n",
       " 'Edenic Past',\n",
       " 'Red City Radio',\n",
       " 'Palm Reader',\n",
       " 'Bearings',\n",
       " 'Seahaven',\n",
       " 'Black Foxxes',\n",
       " 'Scalp',\n",
       " 'The Menzingers',\n",
       " 'Kingdom of Giants',\n",
       " 'Guitar Fight from Fooly Cooly',\n",
       " 'Miasmatic Necrosis',\n",
       " 'Black Stone Cherry',\n",
       " 'Nothing',\n",
       " 'The Fall of Troy',\n",
       " 'Matt Berninger',\n",
       " 'Gorephilia',\n",
       " 'Joji',\n",
       " 'Corey Taylor',\n",
       " 'Fires in the Distance',\n",
       " 'Obsidian Kingdom',\n",
       " 'Svalbard',\n",
       " 'The Ocean',\n",
       " 'Into It. Over It.',\n",
       " 'Fawn Limbs',\n",
       " 'Vous Autres',\n",
       " 'Carnation',\n",
       " 'Special Interest',\n",
       " 'Declan McKenna',\n",
       " 'Xazraug',\n",
       " 'Necrot',\n",
       " 'Angel Olsen',\n",
       " \"Luna's Call\",\n",
       " 'No Joy',\n",
       " 'Pharmacist',\n",
       " 'Duma',\n",
       " 'Misery Signals',\n",
       " 'Slightly Stoopid',\n",
       " 'Aseitas',\n",
       " 'Paara',\n",
       " 'Greg Puciato',\n",
       " 'The Beths',\n",
       " 'Nation of Language',\n",
       " 'Grey Daze',\n",
       " 'Carach Angren',\n",
       " 'Melt Yourself Down',\n",
       " 'Pottery',\n",
       " 'Sault',\n",
       " 'Calligram',\n",
       " 'Phoebe Bridgers',\n",
       " 'Owen',\n",
       " 'Justice For The Damned',\n",
       " 'Make Them Suffer',\n",
       " 'Westerman',\n",
       " 'Sports Team',\n",
       " 'Muzz',\n",
       " 'Palaye Royale',\n",
       " \"Caligula's Horse\",\n",
       " 'Infant Island',\n",
       " 'VVilderness',\n",
       " 'Car Seat Headrest',\n",
       " 'Elephant Tree',\n",
       " 'Molested Divinity',\n",
       " 'Ellis',\n",
       " 'Kontinuum',\n",
       " 'Yves Tumor',\n",
       " 'Telepathy',\n",
       " '5 Seconds of Summer',\n",
       " 'Brian Fallon',\n",
       " 'Sorry',\n",
       " 'The Chats',\n",
       " 'Malokarpatan',\n",
       " 'Afterbirth',\n",
       " 'Temple of Void',\n",
       " 'Hot Mulligan',\n",
       " 'Horse Lords',\n",
       " 'The Districts',\n",
       " 'Monsters',\n",
       " 'Greg Dulli',\n",
       " 'Panchiko',\n",
       " 'Bambara',\n",
       " 'Giver',\n",
       " 'Loathe',\n",
       " 'Shopping',\n",
       " 'Leeched',\n",
       " 'Lowrider',\n",
       " 'Lovebites',\n",
       " 'Vengeful Spectre',\n",
       " 'Higher Power',\n",
       " 'Slick Shoes',\n",
       " 'Wolf Parade',\n",
       " 'Mura Masa',\n",
       " 'Garganjua',\n",
       " 'Algiers',\n",
       " 'Vomit the Soul',\n",
       " 'The Last Ten Seconds Of Life',\n",
       " 'Blood Incantation',\n",
       " 'Dream State',\n",
       " 'Stray from the Path',\n",
       " 'Rex Orange County',\n",
       " 'Sadisme',\n",
       " 'Patrick Watson',\n",
       " 'Common Holly',\n",
       " 'Car Bomb',\n",
       " 'We Lost the Sea',\n",
       " 'Surf Curse',\n",
       " 'Issues',\n",
       " 'Kim Gordon',\n",
       " 'Alarmist',\n",
       " 'Dayseeker',\n",
       " 'Renounced',\n",
       " 'Post Malone',\n",
       " 'Klone',\n",
       " 'Void of Vision',\n",
       " 'The Agonist',\n",
       " 'Liam Gallagher',\n",
       " 'The Hu',\n",
       " 'Grayscale',\n",
       " 'Chris Farren',\n",
       " 'The Odious',\n",
       " 'Sleeping With Sirens',\n",
       " 'Nocturnal Departure',\n",
       " 'Whitney',\n",
       " 'Jay Som',\n",
       " 'Tropical Fuck Storm',\n",
       " 'King Gizzard and The Lizard Wizard',\n",
       " 'Blanck Mass',\n",
       " 'Richard Henshall',\n",
       " 'Rosalie Cunningham',\n",
       " 'Slaughter Beach, Dog',\n",
       " 'iamthemorning',\n",
       " 'Iniquitous Deeds',\n",
       " 'Throes',\n",
       " 'Abbath',\n",
       " 'Ossuary',\n",
       " 'Shirokuma',\n",
       " 'Puppy',\n",
       " 'Bill Callahan',\n",
       " 'CHON',\n",
       " 'Vanishing Twin',\n",
       " 'Frank Iero and The Future Violents',\n",
       " 'Novo Amor',\n",
       " 'Death Angel',\n",
       " 'Cate Le Bon',\n",
       " 'Plastic Mermaids',\n",
       " 'Black Mountain',\n",
       " 'Alex Lahey',\n",
       " 'Lewis Capaldi',\n",
       " 'Holding Patterns',\n",
       " 'Forests',\n",
       " 'We Never Learned To Live',\n",
       " 'Shin Guard',\n",
       " 'Town Portal',\n",
       " 'Trade Wind',\n",
       " 'Kevin Morby',\n",
       " 'Nucleus',\n",
       " 'Wand',\n",
       " 'Clowns',\n",
       " 'The Raven Age',\n",
       " 'Ceremony Of Silence',\n",
       " 'The Dismemberment Plan',\n",
       " 'CHAI',\n",
       " 'Orville Peck',\n",
       " 'Akasha',\n",
       " 'Venom Prison',\n",
       " 'Oozing Wound',\n",
       " 'Baalsebub',\n",
       " 'Tim Bowness',\n",
       " 'Mammoth Weed Wizard Bastard',\n",
       " 'Hozier',\n",
       " 'Teeth Of The Sea',\n",
       " 'Badflower',\n",
       " 'Drenge',\n",
       " 'Astronauts',\n",
       " 'Homeshake',\n",
       " 'Green Lung',\n",
       " 'Set It Off',\n",
       " 'Minors',\n",
       " 'King 810',\n",
       " 'Mystifier',\n",
       " 'Jade Bird',\n",
       " 'Press Club',\n",
       " 'Mono',\n",
       " 'Palisades',\n",
       " 'Tallies',\n",
       " 'Deuce',\n",
       " 'Napoleon',\n",
       " 'Normandie',\n",
       " 'XXXTENTACION',\n",
       " 'Ex:Re',\n",
       " 'Bliss Signal',\n",
       " 'Portrayal of Guilt',\n",
       " 'The Good, The Bad and The Queen',\n",
       " 'Toska',\n",
       " 'Tenacious D',\n",
       " 'Hippo Campus',\n",
       " 'Mass of the Fermenting Dregs',\n",
       " 'The Struts',\n",
       " 'Frog',\n",
       " 'The Dirty Nil',\n",
       " 'Polyphia',\n",
       " 'Hands Like Houses',\n",
       " 'Tom Morello',\n",
       " 'Pagan',\n",
       " 'Black Peaks',\n",
       " 'Kero Kero Bonito',\n",
       " 'Monuments',\n",
       " 'Exit North',\n",
       " 'Against The Current',\n",
       " 'Windhand',\n",
       " 'All Them Witches',\n",
       " 'Head with Wings',\n",
       " 'Wstr',\n",
       " 'Imperial Triumphant',\n",
       " 'The Skull',\n",
       " 'Gia Margaret',\n",
       " 'Trophy Eyes',\n",
       " 'Regal Worm',\n",
       " 'Talons',\n",
       " 'Like Pacific',\n",
       " 'The Antichrist Imperium',\n",
       " 'Mouse On The Keys',\n",
       " 'Burial Invocation',\n",
       " 'Morrow',\n",
       " 'The Interrupters',\n",
       " 'Panic! at the Disco',\n",
       " 'Mark Kozelek',\n",
       " 'Church of the Cosmic Skull',\n",
       " 'Zeal and Ardor',\n",
       " 'Jonathan Davis',\n",
       " 'Tancred',\n",
       " 'Lunatic Soul',\n",
       " 'Flasher',\n",
       " 'Graveyard',\n",
       " 'Keiji Haino',\n",
       " 'Body Void',\n",
       " 'Middle Kids',\n",
       " 'Pinkshinyultrablast',\n",
       " 'Forth Wanderers',\n",
       " 'Sectioned',\n",
       " 'Speedy Ortiz',\n",
       " 'Cassus',\n",
       " 'Boss Keloid',\n",
       " 'Tangled Hair',\n",
       " 'Ruins',\n",
       " 'Mastersystem',\n",
       " 'Rainbow Kitten Surprise',\n",
       " 'Autokrator',\n",
       " 'Night Flowers',\n",
       " 'Hinds',\n",
       " 'Sunflower Bean',\n",
       " 'Nervus',\n",
       " 'George Ezra',\n",
       " 'King Goat',\n",
       " 'Dead!',\n",
       " 'Moose Blood',\n",
       " \"Ed Schrader's Music Beat\",\n",
       " 'Gleb Kolyadin',\n",
       " 'Slugdge',\n",
       " 'Conjurer',\n",
       " 'Vundabar',\n",
       " 'Dvne',\n",
       " 'S. Carey',\n",
       " 'Pianos Become the Teeth',\n",
       " 'Band-Maid',\n",
       " 'Legend of the Seagullmen',\n",
       " 'Crywank',\n",
       " 'The Plot In You',\n",
       " 'Loma',\n",
       " 'Ezra Furman',\n",
       " 'Son Lux',\n",
       " 'Alpha Male Tea Party',\n",
       " 'Palm',\n",
       " 'Philip H. Anselmo and The Illegals',\n",
       " 'Marmozets',\n",
       " 'Somali Yacht Club',\n",
       " 'Anna Burch',\n",
       " 'Dream Wife',\n",
       " 'Thousand Below',\n",
       " 'Of Mice and Men',\n",
       " \"Leaves' Eyes\",\n",
       " 'Embodyment',\n",
       " 'Five Iron Frenzy',\n",
       " 'Yellow Days',\n",
       " 'Death Toll 80k',\n",
       " 'Sacred Son',\n",
       " 'Peach Pit',\n",
       " 'Beast In Black',\n",
       " 'ROAM',\n",
       " 'Turnpike Troubadours',\n",
       " 'Ibeyi',\n",
       " 'Grave Pleasures',\n",
       " 'IDYLLS',\n",
       " 'With the Dead',\n",
       " 'Nothing More',\n",
       " 'Prawn',\n",
       " 'Seaway',\n",
       " 'Ariel Pink',\n",
       " 'Rostam',\n",
       " 'The Contortionist',\n",
       " 'Prophets of Rage',\n",
       " 'White Moth Black Butterfly',\n",
       " 'Hammock',\n",
       " 'Hungry Ghosts',\n",
       " 'Thy Art Is Murder',\n",
       " 'ostraca',\n",
       " 'Kesha',\n",
       " 'Horrified',\n",
       " 'Agents of Oblivion',\n",
       " 'Sheer Mag',\n",
       " 'Silverstein',\n",
       " 'HAIM',\n",
       " 'Public Service Broadcasting',\n",
       " 'Spaceslug',\n",
       " 'Floating Points',\n",
       " 'Ex Eye',\n",
       " 'Hey Violet',\n",
       " 'Single Mothers',\n",
       " 'Wode',\n",
       " 'Flogging Molly',\n",
       " 'Tricot',\n",
       " 'Pumarosa',\n",
       " 'Employed To Serve',\n",
       " 'Gnarwolves',\n",
       " 'Woods',\n",
       " 'PWR BTTM',\n",
       " 'i hate sex',\n",
       " 'Spotlights',\n",
       " 'Sundara Karma',\n",
       " 'Hoops',\n",
       " 'The Physics House Band',\n",
       " 'Artificial Brain',\n",
       " 'Falling in Reverse',\n",
       " 'Jeromes Dream',\n",
       " 'Richard Cheese',\n",
       " 'Michelle Branch',\n",
       " 'Timber Timbre',\n",
       " 'I Declare War',\n",
       " 'Chinese Football',\n",
       " 'The Smith Street Band',\n",
       " 'Phrenelith',\n",
       " 'Hurray For The Riff Raff',\n",
       " 'Circa Waves',\n",
       " 'Temples',\n",
       " 'Raspberry Bulbs',\n",
       " 'Crystal Fairy',\n",
       " 'Vagabon',\n",
       " 'Peter Silberman',\n",
       " 'Meat Wave',\n",
       " 'The Orwells',\n",
       " 'Andrew McMahon in the Wilderness',\n",
       " 'Starset',\n",
       " 'Mark Eitzel',\n",
       " 'Foxygen',\n",
       " 'The Mayfield Four',\n",
       " 'Tycho',\n",
       " 'Youth Funeral',\n",
       " '40 Watt Sun',\n",
       " 'Attila',\n",
       " 'You Blew It!',\n",
       " 'Voices from the Fuselage',\n",
       " 'Earth Moves',\n",
       " 'D.D Dumbo',\n",
       " 'Lewis Del Mar',\n",
       " 'From Ashes To New',\n",
       " 'Shawn Mendes',\n",
       " 'Airbourne',\n",
       " 'Merchandise',\n",
       " 'Beach Slang',\n",
       " 'Newsboys',\n",
       " 'Preoccupations',\n",
       " 'Okkervil River',\n",
       " 'Dope Lemon',\n",
       " 'Mild High Club',\n",
       " 'David Brent',\n",
       " 'Abhorrent Decimation',\n",
       " 'Bayside',\n",
       " 'SWMRS',\n",
       " 'Gouge Away',\n",
       " 'Young the Giant',\n",
       " 'Monarch',\n",
       " 'Coldrain',\n",
       " \"Bear's Den\",\n",
       " 'Despised Icon',\n",
       " 'Omni',\n",
       " 'McCafferty',\n",
       " 'Dikembe',\n",
       " 'Nonpoint',\n",
       " 'The Avalanches',\n",
       " 'Big Business',\n",
       " 'Martha',\n",
       " 'Fates Warning',\n",
       " 'Lonely the Brave',\n",
       " 'British Theatre',\n",
       " 'Thousand Foot Krutch',\n",
       " 'Art Of Dying',\n",
       " 'With Confidence',\n",
       " 'Jake Bugg',\n",
       " 'The Hotelier',\n",
       " 'Rival Sons',\n",
       " 'The Claypool Lennon Delirium',\n",
       " 'Wicked Innocence',\n",
       " 'Minor Victories',\n",
       " 'Fear of Men',\n",
       " 'Real Friends',\n",
       " 'Catfish and the Bottlemen',\n",
       " 'Pantha Du Prince',\n",
       " 'Crystal Lake',\n",
       " 'Kikagaku Moyo',\n",
       " 'Schammasch',\n",
       " 'Twin Peaks',\n",
       " 'Destruction',\n",
       " 'Eagulls',\n",
       " 'RY X',\n",
       " 'LUH',\n",
       " 'ANOHNI',\n",
       " 'Messenger',\n",
       " 'Annisokay',\n",
       " 'Dowsing',\n",
       " 'Crooks',\n",
       " 'Dehumanized',\n",
       " 'Moonlit Sailor',\n",
       " 'The Comet Is Coming',\n",
       " 'Radical Face',\n",
       " 'King Buffalo',\n",
       " 'The Drones',\n",
       " 'Plague Vendor',\n",
       " 'Richmond Fontaine',\n",
       " 'Sarah Neufeld',\n",
       " 'Heck',\n",
       " 'Wormed',\n",
       " 'ee',\n",
       " 'Guerilla Toss',\n",
       " 'Big Ups',\n",
       " 'Mothers',\n",
       " 'Cindy Lee',\n",
       " 'The Neighbourhood',\n",
       " 'Porches',\n",
       " 'Money',\n",
       " 'Nevermen',\n",
       " 'Savages',\n",
       " 'Intervals',\n",
       " 'Fit for an Autopsy',\n",
       " 'Violet Cold',\n",
       " 'Sam Hunt',\n",
       " 'Nokturnel',\n",
       " 'Good Tiger',\n",
       " 'Sexwitch',\n",
       " 'EL VY',\n",
       " 'Love Lost But Not Forgotten',\n",
       " 'Half Moon Run',\n",
       " 'Shining',\n",
       " 'Marietta',\n",
       " 'Dilly Dally',\n",
       " 'One Ok Rock',\n",
       " 'Cruciamentum',\n",
       " 'Kylesa',\n",
       " 'Caspian',\n",
       " 'Agent Fresco',\n",
       " 'P.O.D.',\n",
       " 'X Ambassadors',\n",
       " 'Hills',\n",
       " 'Soilwork',\n",
       " 'Heartist',\n",
       " 'The Sword',\n",
       " 'Royal Headache',\n",
       " 'Highly Suspect',\n",
       " 'Kings Kaleidoscope',\n",
       " 'Archivist',\n",
       " 'Jason Isbell',\n",
       " 'Dan Andriano in the Emergency Room',\n",
       " 'Years and Years',\n",
       " 'Ethereal Shroud',\n",
       " 'God Damn',\n",
       " 'August Burns Red',\n",
       " 'Human Hands',\n",
       " 'Iwrestledabearonce',\n",
       " 'Mutiny On The Bounty',\n",
       " 'Mylets',\n",
       " 'Lucifer',\n",
       " 'Zella Day',\n",
       " 'FFS',\n",
       " 'Jaga Jazzist',\n",
       " 'Girlpool',\n",
       " 'Pet Symmetry',\n",
       " 'Charlie Simpson',\n",
       " 'Johnny Rebel',\n",
       " 'Surfer Blood',\n",
       " 'Murmur',\n",
       " 'We Are Harlot',\n",
       " 'Nai Harvest',\n",
       " 'Ghost Bath',\n",
       " 'Alabama Shakes',\n",
       " 'Bio-Cancer',\n",
       " 'Neon Trees',\n",
       " 'Say Lou Lou',\n",
       " 'Until The Ribbon Breaks',\n",
       " 'Shizune',\n",
       " 'Lower Dens',\n",
       " 'Ryley Walker',\n",
       " 'James Bay',\n",
       " 'AWOLNATION',\n",
       " 'Ranger',\n",
       " 'Trepalium',\n",
       " 'Houndmouth',\n",
       " 'The Sidekicks',\n",
       " 'Pile',\n",
       " 'Ghostpoet',\n",
       " 'A Textbook Tragedy',\n",
       " 'Colleen Green',\n",
       " 'Butch Walker',\n",
       " 'xRepentancex',\n",
       " 'Peace',\n",
       " 'The Arrogant Sons of Bitches',\n",
       " 'Jessica Pratt',\n",
       " 'This Is A Standoff',\n",
       " 'Planet X',\n",
       " 'Kodaline',\n",
       " 'FACT',\n",
       " 'Abstracter',\n",
       " 'California X',\n",
       " 'Cloakroom',\n",
       " 'Swallowed',\n",
       " 'Charli XCX',\n",
       " 'Clouds',\n",
       " 'TrenchRot',\n",
       " 'Forever Came Calling',\n",
       " 'The Ghost Inside',\n",
       " 'Youngblood Hawke',\n",
       " 'No Bragging Rights',\n",
       " 'Disembarked',\n",
       " 'The Jazz June',\n",
       " 'Wildbirds and Peacedrums',\n",
       " 'Crobot',\n",
       " 'Miroist',\n",
       " 'Climates',\n",
       " 'Tweedy',\n",
       " 'Adult Jazz',\n",
       " 'Benjamin Booker',\n",
       " 'My Brightest Diamond',\n",
       " 'The Hell',\n",
       " 'The Wytches',\n",
       " 'Lay Down Rotten',\n",
       " 'Owl John',\n",
       " 'The Algorithm',\n",
       " 'The Flex',\n",
       " 'Bear Hands',\n",
       " 'Totem Skin',\n",
       " 'Breathe Carolina',\n",
       " 'Braid',\n",
       " 'Total Control',\n",
       " 'Glass Animals',\n",
       " 'White Lung',\n",
       " 'Dreamshade',\n",
       " 'Tombs',\n",
       " 'Harry Pussy',\n",
       " 'Vales',\n",
       " 'Archspire',\n",
       " 'Sickening Gore',\n",
       " 'Mars Red Sky',\n",
       " 'Lewis',\n",
       " 'Sorority Noise',\n",
       " 'Echosmith',\n",
       " 'Brody Dalle',\n",
       " 'Circles',\n",
       " 'Ian Anderson',\n",
       " 'The Mire',\n",
       " \"Avey Tare's Slasher Flicks\",\n",
       " 'Chuck Ragan',\n",
       " 'Scar the Martyr',\n",
       " 'Owls',\n",
       " 'Collide',\n",
       " 'Laibach',\n",
       " 'Tony Molina',\n",
       " 'Adrenaline Mob',\n",
       " 'I See Stars',\n",
       " 'Pan.Thy.Monium',\n",
       " 'Above and Beyond',\n",
       " 'Cheatahs',\n",
       " 'Sahg',\n",
       " 'Harvey Danger',\n",
       " 'Mutual Benefit',\n",
       " 'Marvelous 3',\n",
       " 'Pestilence',\n",
       " 'Beastmilk',\n",
       " 'Hell',\n",
       " 'Steve Von Till',\n",
       " 'Laughing Hyenas',\n",
       " 'Yamantaka // Sonic Titan',\n",
       " 'Sky Ferreira',\n",
       " 'Kind of Like Spitting',\n",
       " 'the GazettE',\n",
       " 'San Fermin',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4249"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I have to import this df for the function to properly work\n",
    "df = pd.read_csv('Datasets/df_blend_ratings.csv')\n",
    "artists = df['artist'].unique()\n",
    "len(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As Living Arrows'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3423"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>Philadelphia, Pennsylvania, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>Death From Above 1979</td>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago, Illinois, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>The Nation of Ulysses</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>Strung Out</td>\n",
       "      <td>Simi Valley, California, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     artist                            origin\n",
       "3419             Cinderella  Philadelphia, Pennsylvania, U.S.\n",
       "3420  Death From Above 1979          Toronto, Ontario, Canada\n",
       "3421                Chicago  Chicago, Illinois, United States\n",
       "3422  The Nation of Ulysses                  Washington, D.C.\n",
       "3423             Strung Out     Simi Valley, California, U.S."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2772], dtype=int64),)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(artists=='July Talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'July Talk'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[2772]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Code to execute the functions from ``geopy_functions.py``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_to_remove = ['Cemetery Skyline', 'Goat', 'Kingcrow', 'Speed', 'Hyperdontia', 'Vredehammer', 'Weston Super Maim',\n",
    "                'Mdou Moctar', 'AVRALIZE', 'Engulfed', 'Coffin Storm', 'samlrc', 'Little Kid', 'Termina', 'Rorcal',\n",
    "                'Reverence To Paroxysm', 'Voyager', 'Blindfolded and Led to the Woods', 'Mork', 'Yeule', 'Pond',\n",
    "                'Empire State Bastard', 'Blood Command', 'Avatar', 'Brutus', 'Faceless Burial', 'Within Destruction',\n",
    "                'Sedimentum', 'Ataraxy', 'Corpsessed', 'Epitaphe', 'Aldous Harding', 'Messa', 'Ghost', 'Ecchymosis',\n",
    "                'Wormrot', 'Vertebra Atlantis', 'Papangu', 'Sermon of Flames', 'Springtime', 'Monolord', 'Sulphurous',\n",
    "                'LLNN', 'Trna', 'Slaughter To Prevail', 'sonhos tomam conta', 'Galvanizer', 'Ophidian I', 'Diabolizer',\n",
    "                'Morbific', 'Defacement', 'Divide And Dissolve', 'Soen', 'Scorpions', 'Accept', 'Respire', 'Undergang',\n",
    "                'Bearings', 'Scalp', 'Miasmatic Necrosis', 'Teenage Mutant Ninja Turtles', 'Gorephilia', 'Vous Autres',\n",
    "                'Carnation', 'Pharmacist', 'Paara', \"Justice For The Damned\", 'VVilderness', 'Molested Divinity', 'Ellis',\n",
    "                'Kontinuum', 'Monsters', 'Giver', 'Lowrider', 'Vengeful Spectre', 'Vomit the Soul', 'Sadisme', 'Alarmist',\n",
    "                'Klone', 'Nocturnal Departure', 'King Gizzard and The Lizard Wizard', 'Make Them Suffer', 'The Chats',\n",
    "                'Patrick Watson', 'Shirokuma', 'Forests', 'Town Portal', 'Ceremony Of Silence', 'CHAI', 'Baalsebub',\n",
    "                'Minors', 'Mono', 'Tallies', 'Normandie', 'Mouse On The Keys', 'Burial Invocation', 'Orville Peck',\n",
    "                'Lunatic Soul', 'Alex Lahey', 'Hozier', 'Mystifier', 'Hands Like Houses', 'Ruins', 'Autokrator',\n",
    "                'Legend of the Seagullmen', 'Death Toll 80k', 'IDYLLS', 'Spaceslug', 'i hate sex', 'Band-Maid',\n",
    "                'With the Dead', 'Hungry Ghosts', 'Middle Kids', 'Gleb Kolyadin', \"Leaves' Eyes\", \"Phrenelith\",\n",
    "                \"David Brent\", \"Art Of Dying\", \"Minor Victories\", \"Pantha Du Prince\", \"Schammasch\", 'LUH',\n",
    "                'Violet Cold', 'EL VY', 'Shining', 'Hills', \"Mutiny On The Bounty\", 'Lucifer', 'FFS', 'Ranger',\n",
    "                'Trepalium', 'A Textbook Tragedy', 'This Is A Standoff', 'FACT', 'Swallowed', 'Disembarked',\n",
    "                'Wildbirds and Peacedrums', 'Archivist', 'Timber Timbre', 'Newsboys', 'Dope Lemon', 'Vagabon',\n",
    "                'RY X', 'Moonlit Sailor', 'The Drones', 'Sarah Neufeld', 'Say Lou Lou', 'Cruciamentum', 'Lay Down Rotten',\n",
    "                'Dreamshade', 'Sickening Gore', 'Circles', \"Avey Tare's Slasher Flicks\", 'Forest Silence',\n",
    "                \"One Eyed God Prophecy\", 'Coffins', 'Osamu Kitajima', 'Living With Lions', 'Ansur', 'Parades',\n",
    "                \"Intestine Baalism\", 'Comity', 'No Omega', 'Wolverine', 'Disavowed', 'Angel Dust', \"!T.O.O.H.!\",\n",
    "                'Hypnosia', 'Hexenhaus', 'Paradox', 'Deathrow', 'Excruciate', 'FareWell Poetry', 'Sights and Sounds',\n",
    "                'Supersister', \"Birds Of Tokyo\", 'Ark', \"The Flower Kings\", 'Beardfish', 'Graveworm', 'Acid',\n",
    "                'Ladyhawke', 'Geddy Lee', 'Yngwie Malmsteen', \"World's End Girlfriend\", 'Totem Skin', 'Lewis',\n",
    "                'I Hate Sally', \"The Band\", 'Lisa Hannigan', 'Lethal', 'Bubu', 'Van She', 'Mooncake', 'The Haunted',\n",
    "                \"Orphaned Land\", 'Madder Mortem', 'Kataxu', 'Gilberto Gil', 'Vendetta', 'Kvist', 'Acrostichon', 'Pain',\n",
    "                'Obliteration', 'Flames of Hell', 'Wombbath', 'Stone', 'Disgrace', 'Fionn Regan', 'Disastrous Murmur',\n",
    "                'Urfaust', 'Sleepingdog', 'Island', 'Bethlehem', 'Subterranean Masquerade', 'After Dinner', \n",
    "                'Black Boned Angel', 'FM', 'Embrace', 'Solefald', 'Maneige', 'Amberian Dawn', 'OOIOO', 'Anekdoten',\n",
    "                \"Aphrodite's Child\", 'Hollenthon', 'Lykke Li', 'Lenka', 'Sarah McLachlan', 'Owen Pallett',\n",
    "                'Devin Townsend Project', 'Missy Higgins', 'The Devin Townsend Band', 'Selda', 'Massacra', \"Rory Gallagher\",\n",
    "                'Taste', 'Celestial Season', 'Ida Maria', 'Dark Tranquillity', 'Cadaver', 'Pele', 'Exuma',\n",
    "                'Great Lake Swimmers', 'Dawn', 'The Bats', 'Yoko Ono', 'Illogicist', 'The Saints', 'Final Fantasy',\n",
    "                'Pendulum', 'Lunar Aurora', 'Bee Gees', 'Stars', \"David Sylvian and Robert Fripp\", 'Afflicted', 'Lengsel',\n",
    "                'Extol', 'MDFMK', 'Univers Zero', 'Mortuary Drape', 'Zyklon', 'Winds', 'Zyklon-B', 'The Sins of Thy Beloved',\n",
    "                'Lords of Acid', 'Devin Townsend', 'Diablo Swing Orchestra', 'Arcturus', 'Cornelius', 'Manu Chao',\n",
    "                'Bryan Adams', 'Peaches', 'Doro', 'Kingdom Come', 'Pekka Pohjola', 'Shakira', 'Massacre', 'Subhumans',\n",
    "                'Set Fire to Flames', 'Gorgoroth', 'Gandalf', 'Klaus Schulze', 'The Ecstasy of Saint Theresa',\n",
    "                \"Lou Reed and John Cale\", 'Brian Eno and David Byrne', 'Bob Dylan and The Band', 'Era', 'Devil Doll',\n",
    "                'Cauterize', 'Roadrunner United', 'Circus Maximus', 'Crowpath', 'Raunchy', 'Tad Morose', 'Kenna',\n",
    "                'Head Control System', 'Torchbearer', 'Rosesdead', 'Angtoria', 'Nightrage', 'Necros Christos', 'Hypnos 69',\n",
    "                'Wold', 'Andromeda', 'Chad VanGaalen', 'Melechesh', 'Spheric Universe Experience', 'Anubis Gate',\n",
    "                'The Project Hate MCMXCIX', 'Myrath', 'Savage Circus', 'Hartfield', 'Evereve', 'Daturah', 'Ad Infinitum',\n",
    "                'Tash Sultana', 'Tarja Turunen', 'Ram-Zet', 'Sweven', 'Arcane', 'Sons of Apollo', 'Celesty', 'Brainstorm',\n",
    "                'Unleash The Archers', 'Prostitute Disfigurement', 'The Psyke Project', 'Dornenreich', 'Watain', 'Funeral',\n",
    "                'Cultes Des Ghoules', 'Revolting', 'Igorrr', 'Symfonia', 'Darkestrah', 'Sarah Blasko', 'Fractal Universe',\n",
    "                'The End', 'Apotheosis', 'Drautran', 'Monolithe', 'CrazyEightyEight', 'Black Hole', 'Polaris', 'Nug',\n",
    "                'Klabautamann', 'James LaBrie', 'Vance Joy', 'Helena Deland', 'Authorize', 'Blazon Stone', 'Rapture',\n",
    "                'Worship', 'Conqueror', 'Swan Lake', 'Yyrkoon', 'Inquisition', 'Kerli', 'Keldian', 'Wake', 'Megiddo',\n",
    "                'Juanes', 'William Hung', 'Votum', 'Atramentus', 'Abysmal Torment', 'Paul Dempsey', 'Cytotoxin',\n",
    "                'Vulture Industries', 'Entrails', 'Jorn', 'Conception', 'Centaurus-A', 'Gezan', 'Blood Tsunami',\n",
    "                'Machinemade God', 'Proscription', 'Ragnarok', 'Zeromancer', 'Satariel', 'Circle of Ouroborus', 'Emeth',\n",
    "                'Before The Dawn', 'Near Death Condition', 'Ignivomous', 'MEANS', 'Svart Crown', 'Alan Sorrenti', 'Chthonic',\n",
    "                'Blues Pills', 'Majestica', 'Bedsore', 'Ravencult', 'William Shatner', 'Cheval De Frise', 'Emptiness',\n",
    "                'WHOURKR', 'Jet Black Stare', 'Despondency', 'October Falls', 'Istapp', 'Slumber', 'Night in Gales',\n",
    "                'Ov HELL', 'Aficionado', 'Old Silver Key', 'Junior Battles', 'Adversarial', 'Shugo Tokumaru', 'North',\n",
    "                'Fuck on the Beach', 'Anoice', 'Viscera', 'Two Tongues', 'The Last Felony', 'Revenge', 'The Secret',\n",
    "                'Cosmic Putrefaction', 'Miseration', 'Azusa', 'Stalaggh', 'Cerebral Effusion', 'Nekromantheon', 'Blasphemer',\n",
    "                'Pyaemia', 'Inveracity', 'Orchidectomy', 'Kraanium', 'Human Mincer', 'Deformity', 'Kaospilot',\n",
    "                'Abominable Putridity', 'Iskra', 'Das Oath', 'Torsofuck', 'Internal Suffering', 'Nerlich', 'Blasphemophagher',\n",
    "                'Head Wound City', 'Inanna', 'Disperse', 'Dishammer', 'Damaar', 'Extortion', 'Starring Janet Leigh',\n",
    "                'The Arcane Order', \"D'espairsRay\", 'Demians', \"Dave Matthews\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_new_masters_clean = pd.read_csv('Datasets/df_us_new_masters_clean.csv')\n",
    "unique_artists = df_us_new_masters_clean[df_us_new_masters_clean['year']<2011]['artist'].unique()\n",
    "\n",
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "artists = df_artists_origins['artist'].unique()\n",
    "artists_to_do = []\n",
    "\n",
    "for artist in unique_artists:\n",
    "    if artist not in artists and artist not in artists_to_remove:\n",
    "        artists_to_do.append(artist)\n",
    "\n",
    "len(artists_to_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dark Castle',\n",
       " 'The Pine',\n",
       " 'Viral Load',\n",
       " 'Turbid North',\n",
       " 'Blood Has Been Shed']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first next 5 artists I'm going to scrape\n",
    "artists_to_do[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bingo! df_coordinates.csv found \n",
      "\n",
      "1/1 - Dark_Castle_(band): St. Augustine, Florida\n",
      "1/2 - The Pine: error\n",
      "1/3 - Viral Load: error\n",
      "1/4 - Turbid North: error\n",
      "2/5 - Blood_Has_Been_Shed: Granby, Connecticut\n",
      "3/6 - Run_Kid_Run: Carmi, Illinois, U.S.\n",
      "4/7 - Alda: Hellissandur, Iceland\n",
      "5/8 - Derek_Sherinian (individual): Laguna Beach, California, U.S.GenresHard rockheavy metalprogressive metalprogressive rockjazz fusionneoclassical metal\n",
      "5/9 - Palms: error\n",
      "6/10 - The_Empire_Shall_Fall: Providence, Rhode Island, U.S.\n",
      "7/11 - Pizzicato_Five: Tokyo, Japan\n",
      "7/12 - Century: error\n",
      "8/13 - Loma_Prieta_(band): San Francisco, California, U.S.\n",
      "9/14 - A_Thorn_For_Every_Heart: Chino Hills, California\n",
      "9/15 - Nerlich: error\n",
      "10/16 - Latterman_(band): Huntington Station, New York, United States\n",
      "11/17 - Heartsounds: al languageEnglishProductionExecutive producerNorman LearProducers\n",
      "Fay Kanin\n",
      "Fern Field\n",
      "CinematographyRichard CiupkaEditorJohn WrightRunning time128 minutesProduction companyEmbassy Television\n",
      "12/18 - Eagle_Twin_(band): Salt Lake City, Utah\n",
      "13/19 - Suicide_Silence: Riverside, California, U.S.\n",
      "13/20 - Age Sixteen: error\n",
      "14/21 - This_Bike_Is_A_Pipe_Bomb: Pensacola, Florida, United States\n",
      "14/22 - Rifles at Recess: error\n",
      "14/23 - Ares Kingdom: error\n",
      "15/24 - Only_Crime: U.S.\n",
      "15/25 - Blasphemophagher: error\n",
      "16/26 - Hail_of_Bullets: Rotterdam, Netherlands\n",
      "16/27 - My Hero Is Me: error\n",
      "16/28 - Head Wound City: error\n",
      "16/29 - The Syncope Threshold: error\n",
      "17/30 - PlayRadioPlay!: Aledo, Texas, United States\n",
      "18/31 - DYS_(band): Boston, Massachusetts, U.S.\n",
      "18/32 - Typhoon: error\n",
      "19/33 - True_Widow: Dallas, Texas, United States\n",
      "19/34 - Guns Up!: error\n",
      "20/35 - Dave_Matthews (individual): Johannesburg, South AfricaGenres\n",
      "Acoustic rock\n",
      "jazz rock\n",
      "alternative rock\n",
      "blues rock\n",
      "roots rock\n",
      "\n",
      "21/36 - Heartless_Bastards: Cincinnati, Ohio, U.S.\n",
      "22/37 - Miles_Away_(band): Perth, Western Australia\n",
      "23/38 - Gates_of_Ishtar: Lule, Sweden\n",
      "23/39 - In First Person: error\n",
      "24/40 - The_Rural_Alberta_Advantage: Toronto, Ontario, Canada\n",
      "24/41 - An Embrace of Angels: error\n",
      "25/42 - The_Company_Band: Los Angeles, California, U.S.\n",
      "26/43 - Full_Blown_Chaos: Floral Park, Queens, New York, U.S.\n",
      "27/44 - Burn_Halo: Orange County, California / Tulsa, Oklahoma, U.S.\n",
      "28/45 - Ace_Enders_and_a_Million_Different_People: Hammonton, New Jersey, United States\n",
      "29/46 - The_Sleeping: Long Island, New York, U.S.\n",
      "29/47 - Inanna: error\n",
      "29/48 - Disperse: error\n",
      "29/49 - His Name Was Iron: error\n",
      "29/50 - Continuance: error\n",
      "30/51 - Gayngs: Minneapolis, MinnesotaEau Claire, Wisconsin\n",
      "31/52 - Rosaline_(band): Chicago, Illinois\n",
      "31/53 - Your Best Friend: error\n",
      "32/54 - Shaman's_Harvest: Jefferson City, Missouri, U.S.\n",
      "33/55 - Trapped_Under_Ice_(band): Baltimore, Maryland, U.S.\n",
      "34/56 - The_Mint_Chicks: Auckland, New Zealand\n",
      "34/57 - Battlefields: error\n",
      "34/58 - Cloud Rat: error\n",
      "34/59 - Aftershock: error\n",
      "34/60 - Coke Bust: error\n",
      "35/61 - Death_Before_Dishonor_(band): Boston, Massachusetts, U.S.\n",
      "36/62 - Exmortus: Whittier, California, U.S.\n",
      "37/63 - Jeff_Loomis (individual): Appleton, Wisconsin, U.S.GenresProgressive metal, melodic death metal, thrash metal, groove metal, neoclassical metal, death metal, instrumental rock, black metal\n",
      "38/64 - Consider_the_Thief: Sacramento, California, United States\n",
      "39/65 - Ankla: Los Angeles, California, United States\n",
      "39/66 - Every Bridge Burned: error\n",
      "40/67 - Gaza_(band): Salt Lake City, Utah, U.S.\n",
      "41/68 - Sound_Tribe_Sector_9: Santa Cruz, CaliforniaAtlanta/Athens, Georgia\n",
      "41/69 - Arizmenda: error\n",
      "41/70 - Emptyself: error\n",
      "41/71 - Her Demise My Rise: error\n",
      "42/72 - This_Time_Next_Year_(band): Walnut Creek, California\n",
      "43/73 - The_Dopamines: Cincinnati, Ohio\n",
      "44/74 - Lions_Lions: Boston, Massachusetts\n",
      "45/75 - Johnny_Hobo_and_the_Freight_Trains (individual): Brattleboro, Vermont, United StatesGenres\n",
      "Anarcho-punk\n",
      "folk punk[1]\n",
      "riot-folk\n",
      "Hip-Hop\n",
      "\n",
      "46/76 - Sundowner_(band): Chicago, Illinois, U.S.\n",
      "47/77 - Artifex_Pereo: Louisville, Kentucky, U.S.[1][2]\n",
      "47/78 - Midsummer: error\n",
      "47/79 - Cold World: error\n",
      "47/80 - SQRM: error\n",
      "48/81 - Infest_(band): Valencia, California, U.S.\n",
      "49/82 - Kids_in_the_Way: Noblesville, Indiana, United States\n",
      "50/83 - The_Rocket_Summer: DallasFort Worth, Texas, United States\n",
      "50/84 - Dishammer: error\n",
      "51/85 - Dead_Hearts: Hemel Hempstead, England\n",
      "51/86 - Evil Army: error\n",
      "52/87 - Trampled_By_Turtles: Duluth, Minnesota, U.S.\n",
      "53/88 - Viza: Los Angeles, California\n",
      "54/89 - Outbreak_(band): Maine, U.S.\n",
      "55/90 - Gregory_Alan_Isakov: Philadelphia, Pennsylvania, U.S.\n",
      "55/91 - Samothrace: error\n",
      "56/92 - My_American_Heart: San Diego, California, United States\n",
      "57/93 - The_Carrier_(band): Boston, Massachusetts, U.S.\n",
      "58/94 - Our_Last_Night: Hollis, New Hampshire, U.S.\n",
      "58/95 - Hightide Hotel: error\n",
      "58/96 - Total Abuse: error\n",
      "59/97 - Cheap_Girls: Lansing, Michigan, United States\n",
      "59/98 - Infant Sorrow: error\n",
      "60/99 - This_Is_Hell_(band): Long Island, New York, U.S.\n",
      "61/100 - Mansions_(band): Louisville, Kentucky\n",
      "62/101 - His_Hero_Is_Gone_(band): Memphis, Tennessee, U.S.\n",
      "63/102 - The_Color_of_Violence: Tampa, Florida, U.S.\n",
      "64/103 - Brazil_(band): Indiana, USA\n",
      "65/104 - Mitochondrion_(band): Victoria, British Columbia, Canada\n",
      "66/105 - Reversal_Of_Man: Tampa, Florida, United States\n",
      "67/106 - Barcelona_(band): Arlington, Virginia, U.S.\n",
      "67/107 - The State Lottery: error\n",
      "68/108 - Engel_(band): Gothenburg, Sweden\n",
      "68/109 - Reign Supreme: error\n",
      "69/110 - Automatic_Loveletter: Tampa, Florida, U.S.\n",
      "70/111 - The_County_Medical_Examiners: Scotts Valley, California, U.S.\n",
      "70/112 - Bone Awl: error\n",
      "70/113 - Last Winter: error\n",
      "70/114 - Outworld: error\n",
      "71/115 - A_Great_Big_Pile_of_Leaves: Brooklyn, New York, U.S.\n",
      "72/116 - Hooded_Menace_(band): Joensuu, Finland[1]\n",
      "72/117 - Lack of Interest: error\n",
      "73/118 - On_The_Last_Day: Seattle, Washington, U.S.\n",
      "74/119 - Gama_Bomb: Newry, Northern Ireland\n",
      "75/120 - Wild_Sweet_Orange: Homewood, Alabama, United States\n",
      "75/121 - Cinemechanica: error\n",
      "76/122 - Yesterdays_Rising: Murrieta, California, U.S.\n",
      "76/123 - The Taxpayers: error\n",
      "77/124 - Magrudergrind: Washington, D.C., United States\n",
      "78/125 - Handguns_(band): Harrisburg, Pennsylvania, United States\n",
      "78/126 - Rusted Shut: error\n",
      "79/127 - Algernon_Cadwallader: Yardley, Pennsylvania, U.S.\n",
      "80/128 - Bumblefoot (musician): Brooklyn, New York, U.S.GenresHard rockheavy metalgrungealternative rockavant garde musicprogressive rockfilm scores\n",
      "81/129 - Those_Poor_Bastards: Madison, Wisconsin, United States\n",
      "81/130 - Mind Eraser: error\n",
      "81/131 - New Lows: error\n",
      "81/132 - Oskoreien: error\n",
      "82/133 - Helms_Alee: Seattle, Washington, U.S.\n",
      "82/134 - Windmills By the Ocean: error\n",
      "82/135 - Damaar: error\n",
      "82/136 - Mother of Mercy: error\n",
      "83/137 - Gal_Costa (individual): Salvador, Bahia, Brazil\n",
      "83/138 - Rune: error\n",
      "83/139 - Kolya: error\n",
      "83/140 - Blaspherian: error\n",
      "84/141 - Sleeping_People: San Diego, California\n",
      "85/142 - Colour_Revolt: Oxford, Mississippi\n",
      "85/143 - You and I: error\n",
      "85/144 - The Effort: error\n",
      "85/145 - Dekapitator: error\n",
      "86/146 - Past_Lives_(band): Seattle, Washington, U.S.\n",
      "87/147 - Driftless_Pony_Club: Chicago, Illinois, United States\n",
      "88/148 - Make_Do_and_Mend_(band): West Hartford, Connecticut, United States\n",
      "89/149 - Charles_Bronson_(band): DeKalb, Illinois, U.S.\n",
      "89/150 - Lewd Acts: error\n",
      "89/151 - Bracewar: error\n",
      "90/152 - Carpathian_(band): Melbourne, Victoria, Australia\n",
      "91/153 - D'espairsRay: Japan\n",
      "92/154 - A_Pale_Horse_Named_Death: Brooklyn, New York, U.S.\n",
      "93/155 - Paul_Baribeau: Grand Ledge, Michigan, U.S.\n",
      "93/156 - Hexen: error\n",
      "94/157 - Demians: Normandy,\n",
      "95/158 - I_Shalt_Become: Illinois, United States\n",
      "96/159 - Breather_Resist: Louisville, Kentucky, U.S.\n",
      "97/160 - Dommin: Los Angeles, California, U.S.\n",
      "98/161 - The_Protomen: Murfreesboro, Tennessee, U.S.\n",
      "99/162 - Beyond_Twilight: Horsens, Denmark\n",
      "99/163 - Wrath and Rapture: error\n",
      "99/164 - Carry On: error\n",
      "100/165 - Paper_Tongues: Charlotte, North Carolina\n",
      "100/166 - House Boat: error\n",
      "101/167 - Scars_of_Tomorrow: Orange County, California, United States\n",
      "101/168 - Extortion: error\n",
      "102/169 - Ill_Bill (individual): New York City, U.S.GenresHip hoprap metaldeath metal\n",
      "103/170 - International_Superheroes_of_Hardcore: Coral Springs, Florida, U.S.\n",
      "103/171 - Starring Janet Leigh: error\n",
      "104/172 - Hala_Strana: Los Angeles, California\n",
      "105/173 - Casey_Jones_(band): Jacksonville, Florida\n",
      "106/174 - The_Killing_Tree: Chicago, Illinois, United States\n",
      "107/175 - The_Flying_Luttenbachers: Chicago, Illinois, U.S.\n",
      "108/176 - Hey_Mercedes: Milwaukee/Illinois, United States\n",
      "109/177 - The_Bunny_The_Bear: Buffalo, New York\n",
      "109/178 - Takaru: error\n",
      "110/179 - The_Suicide_File: Boston\n",
      "111/180 - Big_Kids: al languageEnglishNo. of series1No. of episodes13ProductionExecutive producerCas LesterProducerJacinta PeelEditorIan WilliamsCamera setupPeter WoodleyRunning time24 minutes\n",
      "111/181 - Shipwreck A.D.: error\n",
      "111/182 - Righteous Jams: error\n",
      "112/183 - G.I.S.M.: Tokyo, Japan\n",
      "112/184 - Howl: error\n",
      "112/185 - Fueled by Fire: error\n",
      "112/186 - Some Girls: error\n",
      "113/187 - Baths_(band): Culver City, Los Angeles, California, United States\n",
      "114/188 - Lifelover: Stockholm, Sweden\n",
      "114/189 - With Dead Hands Rising: error\n",
      "115/190 - Tickle_Me_Pink: Fort Collins, Colorado\n",
      "116/191 - Home_Grown_(band): Orange County, California, U.S.\n",
      "116/192 - Nechochwen: error\n",
      "116/193 - Black Math Horseman: error\n",
      "117/194 - Deathspell_Omega: Poitiers, France\n",
      "117/195 - Broken Water: error\n",
      "118/196 - The_Reign_of_Kindo: Buffalo, New York, U.S.\n",
      "119/197 - The_Sorrow: Vorarlberg, Austria\n",
      "119/198 - Cire: error\n",
      "120/199 - Strictly_Ballroom_(band): Los Angeles, California\n",
      "121/200 - Karl_Sanders (individual): San Francisco, California, U.S.GenresTechnical death metal, death metal, thrash metal, folk, ambient, post-rock\n",
      "121/201 - The Arcane Order: error\n",
      "121/202 - The Reptilian: error\n",
      "122/203 - Secrets_of_the_Moon: Osnabrck, Germany\n",
      "123/204 - The_Alter_Boys: Cleveland, Ohio, U.S.\n",
      "124/205 - Damiera: Buffalo, New York\n",
      "125/206 - P.S._Eliot: Birmingham, Alabama, U.S.\n",
      "125/207 - The Riot Before: error\n",
      "126/208 - While_Heaven_Wept: Virginia\n",
      "126/209 - Brother Von Doom: error\n",
      "126/210 - Orchid: error\n",
      "126/211 - Addaura: error\n",
      "127/212 - See_You_Next_Tuesday_(band): Bay City, Michigan, United States\n",
      "128/213 - Saints_Never_Surrender: Fort Wayne, Indiana\n",
      "129/214 - Northstar_(band): Huntsville, Alabama, U.S.\n",
      "130/215 - Flake_Music: Albuquerque, New Mexico, U.S.\n",
      "130/216 - Until Your Heart Stops: error\n",
      "131/217 - Sleepercar: El Paso, Texas, USA\n",
      "132/218 - Swamp_Thing_(band): Rotorua, New Zealand\n",
      "133/219 - Tim_Kasher (individual): Omaha, Nebraska, US\n"
     ]
    }
   ],
   "source": [
    "# create the df with the origins scraped from Wikipedia\n",
    "\n",
    "df = pd.read_csv('Datasets/df_us_new_masters_clean.csv')\n",
    "start_index = 0\n",
    "final_index = start_index+220\n",
    "\n",
    "df_artists_origins = get_origins_wikipedia(df, start_index, final_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "86 nulls (39.27 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dark Castle</td>\n",
       "      <td>St. Augustine, Florida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The Pine</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Viral Load</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Turbid North</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Blood Has Been Shed</td>\n",
       "      <td>Granby, Connecticut</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist                  origin\n",
       "0          Dark Castle  St. Augustine, Florida\n",
       "1             The Pine                     NaN\n",
       "2           Viral Load                     NaN\n",
       "3         Turbid North                     NaN\n",
       "4  Blood Has Been Shed     Granby, Connecticut"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a subset of the new artists I just got, and tell me if there are nulls\n",
    "df_new_artists = get_new_artists(df_artists_origins)\n",
    "\n",
    "# show the first new artists, if they were duplicates they have been dropped\n",
    "df_new_artists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there are null or weird values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 2)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a df with where origin is a null value\n",
    "nulls = df_new_artists[df_new_artists['origin'].isna()]\n",
    "nulls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Black Math Horseman\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Broken Water\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Cire\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Arcane Order\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Reptilian\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Riot Before\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Brother Von Doom\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Orchid\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Addaura\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Until Your Heart Stops\", \"England\", df_new_artists[\"origin\"])\n"
     ]
    }
   ],
   "source": [
    "# so I can print the np.where and I save time\n",
    "for artist in nulls['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"England\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking in the internet for the real origins of these artists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>Black Math Horseman</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>Broken Water</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Cire</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>The Arcane Order</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>The Reptilian</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>The Riot Before</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Brother Von Doom</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Orchid</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Addaura</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>Until Your Heart Stops</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     artist origin\n",
       "192     Black Math Horseman    NaN\n",
       "194            Broken Water    NaN\n",
       "197                    Cire    NaN\n",
       "200        The Arcane Order    NaN\n",
       "201           The Reptilian    NaN\n",
       "206         The Riot Before    NaN\n",
       "208        Brother Von Doom    NaN\n",
       "209                  Orchid    NaN\n",
       "210                 Addaura    NaN\n",
       "215  Until Your Heart Stops    NaN"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls.head(10) # so it's faster to copy the names of the artists to look for their origins on the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Black Math Horseman\", \"Los Angeles\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Broken Water\", \"Olympia, Washington\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Cire\", \"New Orleans, LA, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Reptilian\", \"Kalamazoo, Michigan\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Riot Before\", \"Richmond, VA, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Brother Von Doom\", \"Dayton, OH, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Orchid\", \"Amherst, Massachusetts\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Addaura\", \"Seattle, Washington\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Until Your Heart Stops\", \"Oakland, CA, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Only Crime\", \"Fort Collins, CO, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"While Heaven Wept\", \"Dale City, VA, United States\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5619</th>\n",
       "      <td>305973</td>\n",
       "      <td>386259</td>\n",
       "      <td>3227765</td>\n",
       "      <td>US</td>\n",
       "      <td>Only Crime</td>\n",
       "      <td>Virulence</td>\n",
       "      <td>2007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Punk']</td>\n",
       "      <td>Melodic hardcore band formed by [a=Good Riddan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_id  master_id  main_release_id release_country      artist  \\\n",
       "5619     305973     386259          3227765              US  Only Crime   \n",
       "\n",
       "          title  year  album_length  tracks release_type    genres    styles  \\\n",
       "5619  Virulence  2007           0.0      12    ['Album']  ['Rock']  ['Punk']   \n",
       "\n",
       "                                         artist_profile  \n",
       "5619  Melodic hardcore band formed by [a=Good Riddan...  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Only Crime\t\".strip()].sort_values('year').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Melodic hardcore band formed by [a=Good Riddance] singer [a=Russ Rankin] and [a=Bane (2)] guitarist [a=Aaron Dalbec] in\n",
      "2003.\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[5619]['artist_profile']\n",
    "\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the original dataframes in case needed (ex: two bands with the same name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[11090, 'artist'] = 'Embrace (US)'\n",
    "df.loc[6140, 'artist'] = 'Embrace (UK)'\n",
    "df.loc[6141, 'artist'] = 'Embrace (UK)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Datasets/df_masters_blended.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>7197</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>The Good Will Out</td>\n",
       "      <td>3.56</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>7198</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>Out Of Nothing</td>\n",
       "      <td>3.39</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>14575</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>3.99</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      album_id   artist              title  rating  votes\n",
       "4485      7197  Embrace  The Good Will Out    3.56     24\n",
       "4486      7198  Embrace     Out Of Nothing    3.39     27\n",
       "8649     14575  Embrace            Embrace    3.99    309"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df_ratings_20 to check it's the correct artist\n",
    "df_ratings_20[df_ratings_20['artist']==\"Embrace\".strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.loc[8649, 'artist'] = 'Embrace (US)'\n",
    "df_ratings_20.loc[4486, 'artist'] = 'Embrace (UK)'\n",
    "df_ratings_20.loc[4485, 'artist'] = 'Embrace (UK)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.to_csv('Datasets/df_ratings_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists['origin'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Drop artists that are not from the UK or the US** (or supergroups that don't have a clear origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_to_remove = []\n",
    "\n",
    "for artist in artists_to_remove:\n",
    "    try:\n",
    "        artists_usa.remove(artist)\n",
    "        print(f'{artist} removed')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping: 207\n",
      "Rows after dropping: 206\n"
     ]
    }
   ],
   "source": [
    "# I can drop single rows or I can just create a subset with the artists that I want to keep, the ones that are not in the list of artists to remove\n",
    "print(f\"Rows before dropping: {df_new_artists.shape[0]}\")\n",
    "df_new_artists = df_new_artists[~df_new_artists['artist'].isin(artists_to_remove)]\n",
    "print(f\"Rows after dropping: {df_new_artists.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Check short and long origins, probably wrong**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56 Fargo, ND\n",
      "178 Boston\n"
     ]
    }
   ],
   "source": [
    "# print abnormally short origins and visually check if they are correct\n",
    "for index, row in df_new_artists.iterrows():\n",
    "    if len(row['origin']) < 10:\n",
    "        print(index, row['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>While Heaven Wept</td>\n",
       "      <td>Virginia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Brother Von Doom</td>\n",
       "      <td>Dayton, OH, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>Orchid</td>\n",
       "      <td>Amherst, Massachusetts</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Addaura</td>\n",
       "      <td>Seattle, Washington</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>See You Next Tuesday</td>\n",
       "      <td>Bay City, Michigan, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>Saints Never Surrender</td>\n",
       "      <td>Fort Wayne, Indiana</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     artist                             origin\n",
       "207       While Heaven Wept                           Virginia\n",
       "208        Brother Von Doom          Dayton, OH, United States\n",
       "209                  Orchid             Amherst, Massachusetts\n",
       "210                 Addaura                Seattle, Washington\n",
       "211    See You Next Tuesday  Bay City, Michigan, United States\n",
       "212  Saints Never Surrender                Fort Wayne, Indiana"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = 207\n",
    "\n",
    "end_index = start_index+5\n",
    "df_new_artists.loc[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>152830</td>\n",
       "      <td>451305</td>\n",
       "      <td>2572483</td>\n",
       "      <td>US</td>\n",
       "      <td>Big Kids</td>\n",
       "      <td>Hoop Dreams</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['LP']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Rock &amp; Roll', 'Punk']</td>\n",
       "      <td>Punk band from Oakland, CA, USA.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_id  master_id  main_release_id release_country    artist  \\\n",
       "6396     152830     451305          2572483              US  Big Kids   \n",
       "\n",
       "            title  year  album_length  tracks release_type    genres  \\\n",
       "6396  Hoop Dreams  2010           0.0       8       ['LP']  ['Rock']   \n",
       "\n",
       "                       styles                    artist_profile  \n",
       "6396  ['Rock & Roll', 'Punk']  Punk band from Oakland, CA, USA.  "
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Big Kids\t\".strip()].sort_values('year').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "American melodic hardcore punk band from Oakland, CA.\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[5587]['artist_profile']\n",
    "\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 2)"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = df_new_artists[df_new_artists['origin'].str.contains('Genres')]\n",
    "genres.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in genres['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"UK\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Derek Sherinian\", \"Laguna Beach, California, U.S.\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Jeff Loomis\", \"Appleton, Wisconsin, U.S.\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Johnny Hobo and the Freight Trains\", \"Brattleboro, Vermont, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Bumblefoot\", \"Brooklyn, New York, U.S.\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Ill Bill\", \"New York City, U.S.\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Karl Sanders\", \"San Francisco, California, U.S.\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the df so I can copy the origin from the column (before 'Genres')\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Genres')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I create a new column to calculate the lenght of the origin, if it's long it probably didn't scrap correctly Wikipedia\n",
    "df_new_artists[\"origin_length\"] = df_new_artists[\"origin\"].str.len()\n",
    "long_strings = df_new_artists[df_new_artists[\"origin_length\"]>40] # create a df based on these long origins\n",
    "long_strings.shape # to see how many artists I have to take care of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Latterman</td>\n",
       "      <td>Huntington Station, New York, United States</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>Make Do and Mend</td>\n",
       "      <td>West Hartford, Connecticut, United States</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>Baths</td>\n",
       "      <td>Culver City, Los Angeles, California, United S...</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist                                             origin  \\\n",
       "15          Latterman        Huntington Station, New York, United States   \n",
       "147  Make Do and Mend          West Hartford, Connecticut, United States   \n",
       "186             Baths  Culver City, Los Angeles, California, United S...   \n",
       "\n",
       "     origin_length  \n",
       "15              43  \n",
       "147             41  \n",
       "186             51  "
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_strings # display the df so I can copy the parts I am interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in long_strings['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"UK\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Heartsounds\", \"Oakland, CA\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Burn Halo\", \"Costa Mesa\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Gayngs\", \"Minneapolis, MN, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Sound Tribe Sector 9\", \"Snellville, GA, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Big Kids\", \"Oakland, CA\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"SQRM\", \"Springfield, Massachusetts\", df_new_artists[\"origin\"])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I drop the column I just created of 'origin_length'\n",
    "df_new_artists = df_new_artists[['artist', 'origin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from United Kingdom, wrong origin, poor level of detail\n",
    "df_new_artists[df_new_artists['origin']==('United Kingdom')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Changing easy values: individuals that didn't get the right origin in Wikipedia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# individuals that didn't get the right origin in Wikipedia\n",
    "df_new_artists[df_new_artists['origin'].str.contains(' and ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Cumbria, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Cumbria')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace('Cumbria', 'Cumberland'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Middlesex, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Middlesex')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', Middlesex', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Yorkshire, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('West Riding of Yorkshire')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', West Riding of Yorkshire', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Merseyside, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Merseyside')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', Merseyside', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try a single origin in Geopy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kirkland, King County, Washington, United States\n",
      "47.6765382 -122.2070775\n"
     ]
    }
   ],
   "source": [
    "# try to get the right origin of an origin that crashed\n",
    "geolocator = Nominatim(user_agent=\"music_analysis\")\n",
    "\n",
    "origin = \"Kirkland, Washington\"\n",
    "\n",
    "origin_clean = re.sub(r'\\[\\d+\\]', '', origin).replace('.', '')\n",
    "location = geolocator.geocode(origin_clean)\n",
    "print(f\"{location.address}\")\n",
    "print(location.latitude, location.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Artifex Pereo</td>\n",
       "      <td>Louisville, Kentucky, U.S.[1][2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Midsummer</td>\n",
       "      <td>Los Angeles, CA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>Cold World</td>\n",
       "      <td>Wilkes-Barre, PA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>SQRM</td>\n",
       "      <td>Springfield, Massachussets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Infest</td>\n",
       "      <td>Valencia, California, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           artist                            origin\n",
       "76  Artifex Pereo  Louisville, Kentucky, U.S.[1][2]\n",
       "77      Midsummer    Los Angeles, CA, United States\n",
       "78     Cold World                  Wilkes-Barre, PA\n",
       "79           SQRM        Springfield, Massachussets\n",
       "80         Infest        Valencia, California, U.S."
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = 70\n",
    "\n",
    "end_index = start_index+5\n",
    "df_new_artists[start_index:end_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try all origins in Geopy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 - Louisville, Jefferson County, Kentucky, United States\n",
      "71 - Los Angeles, Los Angeles County, California, United States\n",
      "72 - Wilkes-Barre, Luzerne County, Pennsylvania, United States\n",
      "73 - Springfield, Hampden County, Massachusetts, United States\n",
      "74 - Valencia, Santa Clarita, Los Angeles County, California, 91355, United States\n",
      "75 - Noblesville, Hamilton County, Indiana, 46060, United States\n",
      "76 - Dallas/Fort Worth International Airport, 2400, Aviation Drive, Dallas, Tarrant County, Texas, 75261, United States\n",
      "77 - Hemel Hempstead, Dacorum, Hertfordshire, England, HP1 1EW, United Kingdom\n",
      "78 - Memphis, Shelby County, West Tennessee, Tennessee, United States\n",
      "79 - Duluth, Saint Louis County, Minnesota, United States\n",
      "80 - Los Angeles, Los Angeles County, California, United States\n",
      "81 - Maine, United States\n",
      "82 - Philadelphia, Philadelphia County, Pennsylvania, United States\n",
      "83 - Seattle, King County, Washington, United States\n",
      "84 - San Diego, San Diego County, California, United States\n",
      "85 - Boston, Suffolk County, Massachusetts, United States\n",
      "86 - Hollis, Hillsborough County, New Hampshire, United States\n",
      "87 - Philadelphia, Philadelphia County, Pennsylvania, United States\n",
      "88 - Austin, Travis County, Texas, United States\n",
      "89 - Lansing, Ingham County, Michigan, United States\n",
      "90 - Grays, Thurrock, Essex, England, RM17 6NP, United Kingdom\n",
      "91 - Long Island, New York, United States\n",
      "92 - Louisville, Jefferson County, Kentucky, United States\n",
      "93 - Memphis, Shelby County, West Tennessee, Tennessee, United States\n",
      "94 - Tampa, Hillsborough County, Florida, United States\n",
      "95 - Indiana, United States\n",
      "96 - Victoria, Capital Regional District, British Columbia, Canada\n",
      "97 - Tampa, Hillsborough County, Florida, United States\n",
      "98 - Arlington County, Virginia, United States\n",
      "99 - Detroit, Wayne County, Michigan, United States\n",
      "100 - Gteborg, Gteborgs Stad, Vstra Gtalands ln, 411 10, Sverige\n",
      "101 - Philadelphia, Philadelphia County, Pennsylvania, United States\n",
      "102 - Tampa, Hillsborough County, Florida, United States\n",
      "103 - Scotts Valley, Santa Cruz County, California, 95066, United States\n",
      "104 - Novato, Marin County, California, United States\n",
      "105 - Orlando, Orange County, Florida, United States\n",
      "106 - Houston, Harris County, Texas, United States\n",
      "107 - Brooklyn, Kings County, City of New York, New York, United States\n",
      "108 - Joensuu, Joensuun seutukunta, Pohjois-Karjala, Manner-Suomi, Suomi / Finland\n",
      "109 - Burbank, Los Angeles County, California, United States\n",
      "110 - Seattle, King County, Washington, United States\n",
      "111 - Newry, County Down, Northern Ireland / Tuaisceart ireann, United Kingdom\n",
      "112 - Homewood, Jefferson County, Alabama, United States\n",
      "113 - Athens, Clarke County, Georgia, United States\n",
      "114 - Murrieta, Riverside County, California, United States\n",
      "115 - Portland, Multnomah County, Oregon, United States\n",
      "116 - Washington, District of Columbia, United States\n",
      "117 - Harrisburg, Dauphin County, Pennsylvania, United States\n",
      "118 - Houston, Harris County, Texas, United States\n",
      "119 - Yardley, Bucks County, Pennsylvania, United States\n",
      "120 - Brooklyn, Kings County, City of New York, New York, United States\n",
      "121 - Madison, Dane County, Wisconsin, United States\n",
      "122 - Boston, Suffolk County, Massachusetts, United States\n",
      "123 - Boston, Suffolk County, Massachusetts, United States\n",
      "124 - Los Angeles, Los Angeles County, California, United States\n",
      "125 - Seattle, King County, Washington, United States\n",
      "126 - Boston, Suffolk County, Massachusetts, United States\n",
      "127 - Doylestown, Bucks County, Pennsylvania, 18901, United States\n",
      "128 - Salvador, Regio Geogrfica Imediata de Salvador, Regio Metropolitana de Salvador, Regio Geogrfica Intermediria de Salvador, Bahia, Regio Nordeste, Brasil\n",
      "129 - Dayton, Montgomery County, Ohio, United States\n",
      "130 - Cambridge, Middlesex County, Massachusetts, United States\n",
      "131 - Houston, Harris County, Texas, United States\n",
      "132 - San Diego, San Diego County, California, United States\n",
      "133 - Oxford, Lafayette County, Mississippi, United States\n",
      "134 - New Brunswick, Middlesex County, New Jersey, United States\n",
      "135 - Boston, Suffolk County, Massachusetts, United States\n",
      "136 - San Jose, Santa Clara County, California, United States\n",
      "137 - Seattle, King County, Washington, United States\n",
      "138 - Chicago, Cook County, Illinois, United States\n",
      "139 - West Hartford, Capitol Planning Region, Connecticut, United States\n",
      "140 - DeKalb County, Illinois, United States\n",
      "141 - San Diego, San Diego County, California, United States\n",
      "142 - Richmond, Virginia, United States\n",
      "143 - Melbourne, City of Melbourne, Victoria, Australia\n",
      "144 - Brooklyn, Kings County, City of New York, New York, United States\n",
      "145 - Grand Ledge, Eaton County, Michigan, United States\n",
      "146 - Los Angeles, Los Angeles County, California, United States\n",
      "147 - Illinois, United States\n",
      "148 - Louisville, Jefferson County, Kentucky, United States\n",
      "149 - Los Angeles, Los Angeles County, California, United States\n",
      "150 - Murfreesboro, Rutherford County, Middle Tennessee, Tennessee, United States\n",
      "151 - Horsens, Horsens Kommune, Region Midtjylland, 8700, Danmark\n",
      "152 - Winston-Salem, Forsyth County, North Carolina, United States\n",
      "153 - Northridge, Northridge South Neighborhood Council District, Los Angeles, Los Angeles County, California, 91324, United States\n",
      "154 - Charlotte, Mecklenburg County, North Carolina, United States\n",
      "155 - Elmhurst, Queens, Queens County, City of New York, New York, 11373, United States\n",
      "156 - Orange County, California, United States\n",
      "157 - City of New York, New York, United States\n",
      "158 - Coral Springs, Broward County, Florida, United States\n",
      "159 - Los Angeles, Los Angeles County, California, United States\n",
      "160 - Jacksonville, Duval County, Florida, United States\n",
      "161 - Chicago, Cook County, Illinois, United States\n",
      "162 - Chicago, Cook County, Illinois, United States\n",
      "163 - Milwaukee, Lake County, Illinois, 60041, United States\n",
      "164 - Buffalo, Erie County, New York, United States\n",
      "165 - San Francisco, California, United States\n",
      "166 - Boston, Suffolk County, Massachusetts, United States\n",
      "167 - Oakland, Alameda County, California, United States\n",
      "168 - Boston, Suffolk County, Massachusetts, United States\n",
      "169 - Boston, Suffolk County, Massachusetts, United States\n",
      "170 - , \n",
      "171 - Providence, Providence County, Rhode Island, United States\n",
      "172 - Norwalk, Los Angeles County, California, 90650, United States\n",
      "173 - San Diego, San Diego County, California, United States\n",
      "174 - Culver City, Los Angeles County, California, 90232, United States\n",
      "175 - Stockholm, Stockholms kommun, Stockholms ln, 111 29, Sverige\n",
      "176 - Minneapolis, Hennepin County, Minnesota, United States\n",
      "177 - Fort Collins, Larimer County, Colorado, United States\n",
      "178 - Orange County, California, United States\n",
      "179 - Charleston, Kanawha County, West Virginia, United States\n",
      "180 - Los Angeles, Los Angeles County, California, United States\n",
      "181 - Poitiers, Vienne, Nouvelle-Aquitaine, France mtropolitaine, 86000, France\n",
      "182 - Olympia, Thurston County, Washington, United States\n",
      "183 - Buffalo, Erie County, New York, United States\n",
      "184 - Vorarlberg, sterreich\n",
      "185 - New Orleans, Orleans Parish, Louisiana, United States\n",
      "186 - Los Angeles, Los Angeles County, California, United States\n",
      "187 - San Francisco, California, United States\n",
      "188 - Kalamazoo, Kalamazoo County, Michigan, United States\n",
      "189 - Osnabrck, Niedersachsen, Deutschland\n",
      "190 - Cleveland, Cuyahoga County, Ohio, United States\n",
      "191 - Buffalo, Erie County, New York, United States\n",
      "192 - Birmingham, Jefferson County, Alabama, United States\n",
      "193 - Richmond, Virginia, United States\n",
      "194 - Dale City, Prince William County, Virginia, United States\n",
      "195 - Dayton, Montgomery County, Ohio, United States\n",
      "196 - Amherst, Hampshire County, Massachusetts, United States\n",
      "197 - Seattle, King County, Washington, United States\n",
      "198 - Bay City, Bay County, Michigan, 48708, United States\n",
      "199 - Fort Wayne, Allen County, Indiana, United States\n",
      "200 - Huntsville, Madison County, Alabama, United States\n",
      "201 - Albuquerque, Bernalillo County, New Mexico, United States\n",
      "202 - Oakland, Alameda County, California, United States\n",
      "203 - El Paso, El Paso County, Texas, United States\n",
      "204 - Rotorua, Rotorua Lakes District, Bay of Plenty, 3010, New Zealand / Aotearoa\n",
      "205 - Omaha, Douglas County, Nebraska, United States\n"
     ]
    }
   ],
   "source": [
    "# try to get the coordinates of the origins from Geopy and see if it crashes (wrong location that I have to change)\n",
    "geolocator = Nominatim(user_agent=\"music_analysis\", timeout=10)\n",
    "\n",
    "initial_index = 70\n",
    "count = initial_index-1\n",
    "\n",
    "for origin in df_new_artists['origin'].str.replace('.', '').str.replace(r'\\[\\d+\\]', '', regex=True)[initial_index:]:\n",
    "    count+=1\n",
    "    location = geolocator.geocode(origin)\n",
    "    print(f\"{count} - {location.address}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Export to .csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoPy wrong locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case GeoPy fails due to a wrong location, I have to delete the new locations, export again, change the location and run GeoPy again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # import the df with the artists' origins already scraped\n",
    "# df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "# df_artists_origins_scraped = df_artists_origins_scraped[0:-20]\n",
    "# df_artists_origins_scraped.to_csv('Datasets/df_artists_origins.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(206, 2)"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case I created by mistake already 'origin_clean' and I want to drop it\n",
    "# df_new_artists = df_new_artists[['artist', 'origin']]\n",
    "# df_new_artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Export to .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_artists_origins_concat exported to .csv\n",
      "(6737, 2)\n"
     ]
    }
   ],
   "source": [
    "export_artists_origins_concat(df_new_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GeoPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/176 - Saint Augustine, Saint Johns County, Florida, 32084, United States\n",
      "2/176 - Bakersfield, Kern County, California, United States\n",
      "3/176 - Lufkin, Angelina County, Texas, United States\n",
      "4/176 - Fort Worth, Tarrant County, Texas, United States\n",
      "5/176 - Granby, Capitol Planning Region, Connecticut, United States\n",
      "6/176 - Carmi, White County, Illinois, 62821, United States\n",
      "7/176 - Hellissandur, Snfellsbr, Vesturland, 360, sland\n",
      "8/176 - Laguna Beach, Orange County, California, United States\n",
      "9/176 - Los Angeles, Los Angeles County, California, United States\n",
      "10/176 - Providence, Providence County, Rhode Island, United States\n",
      "11/176 - , \n",
      "12/176 - Lancaster, Lancaster County, Pennsylvania, United States\n",
      "13/176 - San Francisco, California, United States\n",
      "14/176 - Chino Hills, San Bernardino County, California, United States\n",
      "15/176 - Huntington Station, Town of Huntington, Suffolk County, New York, United States\n",
      "16/176 - Oakland, Alameda County, California, United States\n",
      "17/176 - Salt Lake City, Salt Lake County, Utah, United States\n",
      "18/176 - Riverside, Riverside County, California, United States\n",
      "19/176 - Baltimore, Maryland, United States\n",
      "20/176 - Pensacola, Escambia County, Florida, United States\n",
      "21/176 - Chattanooga, Hamilton County, East Tennessee, Tennessee, United States\n",
      "22/176 - Kansas City, Jackson County, Missouri, United States\n",
      "23/176 - Fort Collins, Larimer County, Colorado, United States\n",
      "24/176 - Rotterdam, Zuid-Holland, Nederland\n",
      "25/176 - Pfafftown, Forsyth County, North Carolina, 27040, United States\n",
      "26/176 - La Verne, Los Angeles County, California, 91750, United States\n",
      "27/176 - Aledo, Parker County, Texas, United States\n",
      "28/176 - Boston, Suffolk County, Massachusetts, United States\n",
      "29/176 - Portland, Multnomah County, Oregon, United States\n",
      "30/176 - Dallas, Dallas County, Texas, United States\n",
      "31/176 - Haverhill, Essex County, Massachusetts, United States\n",
      "32/176 - Cincinnati, Hamilton County, Ohio, United States\n",
      "33/176 - City of Perth, Western Australia, Australia\n",
      "34/176 - Lule, Lule kommun, Norrbottens ln, 971 28, Sverige\n",
      "35/176 - New Brunswick, Middlesex County, New Jersey, United States\n",
      "36/176 - Toronto, Golden Horseshoe, Ontario, Canada\n",
      "37/176 - Owatonna, Steele County, Minnesota, 55060, United States\n",
      "38/176 - Los Angeles, Los Angeles County, California, United States\n",
      "39/176 - Floral Park Liquors, 259-09, Hillside Avenue, Queens, Queens County, City of New York, New York, 11040, United States\n",
      "40/176 - Costa Mesa, Orange County, California, United States\n",
      "41/176 - Hammonton, Atlantic County, New Jersey, 08037, United States\n",
      "42/176 - Long Island, New York, United States\n",
      "43/176 - Jacksonville, Duval County, Florida, United States\n",
      "44/176 - Fort Wayne, Allen County, Indiana, United States\n",
      "45/176 - Minneapolis, Hennepin County, Minnesota, United States\n",
      "46/176 - Chicago, Cook County, Illinois, United States\n",
      "47/176 - Saginaw, Saginaw County, Michigan, United States\n",
      "48/176 - Jefferson City, Cole County, Missouri, United States\n",
      "49/176 - Baltimore, Maryland, United States\n",
      "50/176 - Auckland, Waitemat, Auckland, 1010, New Zealand / Aotearoa\n",
      "51/176 - Fargo, Cass County, North Dakota, United States\n",
      "52/176 - Mount Pleasant, Isabella County, Michigan, United States\n",
      "53/176 - Westhampton, Hampshire County, Massachusetts, United States\n",
      "54/176 - Washington, District of Columbia, United States\n",
      "55/176 - Whittier, Los Angeles County, California, United States\n",
      "56/176 - Appleton, Outagamie County, Wisconsin, United States\n",
      "57/176 - Sacramento, Sacramento County, California, United States\n",
      "58/176 - Los Angeles, Los Angeles County, California, United States\n",
      "59/176 - Lima, Allen County, Ohio, United States\n",
      "60/176 - Salt Lake City, Salt Lake County, Utah, United States\n",
      "61/176 - Snellville, Gwinnett County, Georgia, United States\n",
      "62/176 - Seal Beach, Orange County, California, United States\n",
      "63/176 - New Orleans, Orleans Parish, Louisiana, United States\n",
      "64/176 - Rancho Cucamonga, San Bernardino County, California, United States\n",
      "65/176 - Walnut Creek, Contra Costa County, California, United States\n",
      "66/176 - Cincinnati, Hamilton County, Ohio, United States\n",
      "67/176 - Boston, Suffolk County, Massachusetts, United States\n",
      "68/176 - Brattleboro, Windham County, Vermont, United States\n",
      "69/176 - Chicago, Cook County, Illinois, United States\n",
      "70/176 - Louisville, Jefferson County, Kentucky, United States\n",
      "71/176 - Los Angeles, Los Angeles County, California, United States\n",
      "72/176 - Wilkes-Barre, Luzerne County, Pennsylvania, United States\n",
      "73/176 - Springfield, Hampden County, Massachusetts, United States\n",
      "74/176 - Valencia, Santa Clarita, Los Angeles County, California, 91355, United States\n",
      "75/176 - Noblesville, Hamilton County, Indiana, 46060, United States\n",
      "76/176 - Dallas/Fort Worth International Airport, 2400, Aviation Drive, Dallas, Tarrant County, Texas, 75261, United States\n",
      "77/176 - Hemel Hempstead, Dacorum, Hertfordshire, England, HP1 1EW, United Kingdom\n",
      "78/176 - Memphis, Shelby County, West Tennessee, Tennessee, United States\n",
      "79/176 - Duluth, Saint Louis County, Minnesota, United States\n",
      "80/176 - Los Angeles, Los Angeles County, California, United States\n",
      "81/176 - Maine, United States\n",
      "82/176 - Philadelphia, Philadelphia County, Pennsylvania, United States\n",
      "83/176 - Seattle, King County, Washington, United States\n",
      "84/176 - San Diego, San Diego County, California, United States\n",
      "85/176 - Hollis, Hillsborough County, New Hampshire, United States\n",
      "86/176 - Philadelphia, Philadelphia County, Pennsylvania, United States\n",
      "87/176 - Austin, Travis County, Texas, United States\n",
      "88/176 - Lansing, Ingham County, Michigan, United States\n",
      "89/176 - Grays, Thurrock, Essex, England, RM17 6NP, United Kingdom\n",
      "90/176 - Louisville, Jefferson County, Kentucky, United States\n",
      "91/176 - Memphis, Shelby County, West Tennessee, Tennessee, United States\n",
      "92/176 - Tampa, Hillsborough County, Florida, United States\n",
      "93/176 - Indiana, United States\n",
      "94/176 - Victoria, Capital Regional District, British Columbia, Canada\n",
      "95/176 - Tampa, Hillsborough County, Florida, United States\n",
      "96/176 - Arlington County, Virginia, United States\n",
      "97/176 - Detroit, Wayne County, Michigan, United States\n",
      "98/176 - Gteborg, Gteborgs Stad, Vstra Gtalands ln, 411 10, Sverige\n",
      "99/176 - Philadelphia, Philadelphia County, Pennsylvania, United States\n",
      "100/176 - Scotts Valley, Santa Cruz County, California, 95066, United States\n",
      "101/176 - Novato, Marin County, California, United States\n",
      "102/176 - Orlando, Orange County, Florida, United States\n",
      "103/176 - Houston, Harris County, Texas, United States\n",
      "104/176 - Brooklyn, Kings County, City of New York, New York, United States\n",
      "105/176 - Joensuu, Joensuun seutukunta, Pohjois-Karjala, Manner-Suomi, Suomi / Finland\n",
      "106/176 - Burbank, Los Angeles County, California, United States\n",
      "107/176 - Seattle, King County, Washington, United States\n",
      "108/176 - Newry, County Down, Northern Ireland / Tuaisceart ireann, United Kingdom\n",
      "109/176 - Homewood, Jefferson County, Alabama, United States\n",
      "110/176 - Athens, Clarke County, Georgia, United States\n",
      "111/176 - Murrieta, Riverside County, California, United States\n",
      "112/176 - Washington, District of Columbia, United States\n",
      "113/176 - Harrisburg, Dauphin County, Pennsylvania, United States\n",
      "114/176 - Houston, Harris County, Texas, United States\n",
      "115/176 - Yardley, Bucks County, Pennsylvania, United States\n",
      "116/176 - Madison, Dane County, Wisconsin, United States\n",
      "117/176 - Boston, Suffolk County, Massachusetts, United States\n",
      "118/176 - Doylestown, Bucks County, Pennsylvania, 18901, United States\n",
      "119/176 - Salvador, Regio Geogrfica Imediata de Salvador, Regio Metropolitana de Salvador, Regio Geogrfica Intermediria de Salvador, Bahia, Regio Nordeste, Brasil\n",
      "120/176 - Dayton, Montgomery County, Ohio, United States\n",
      "121/176 - Cambridge, Middlesex County, Massachusetts, United States\n",
      "122/176 - San Diego, San Diego County, California, United States\n",
      "123/176 - Oxford, Lafayette County, Mississippi, United States\n",
      "124/176 - San Jose, Santa Clara County, California, United States\n",
      "125/176 - Chicago, Cook County, Illinois, United States\n",
      "126/176 - West Hartford, Capitol Planning Region, Connecticut, United States\n",
      "127/176 - DeKalb County, Illinois, United States\n",
      "128/176 - San Diego, San Diego County, California, United States\n",
      "129/176 - Richmond, Virginia, United States\n",
      "130/176 - Melbourne, City of Melbourne, Victoria, Australia\n",
      "131/176 - Grand Ledge, Eaton County, Michigan, United States\n",
      "132/176 - Illinois, United States\n",
      "133/176 - Louisville, Jefferson County, Kentucky, United States\n",
      "134/176 - Murfreesboro, Rutherford County, Middle Tennessee, Tennessee, United States\n",
      "135/176 - Horsens, Horsens Kommune, Region Midtjylland, 8700, Danmark\n",
      "136/176 - Winston-Salem, Forsyth County, North Carolina, United States\n",
      "137/176 - Northridge, Northridge South Neighborhood Council District, Los Angeles, Los Angeles County, California, 91324, United States\n",
      "138/176 - Charlotte, Mecklenburg County, North Carolina, United States\n",
      "139/176 - Elmhurst, Queens, Queens County, City of New York, New York, 11373, United States\n",
      "140/176 - Orange County, California, United States\n",
      "141/176 - City of New York, New York, United States\n",
      "142/176 - Coral Springs, Broward County, Florida, United States\n",
      "143/176 - Jacksonville, Duval County, Florida, United States\n",
      "144/176 - Milwaukee, Lake County, Illinois, 60041, United States\n",
      "145/176 - Buffalo, Erie County, New York, United States\n",
      "146/176 - San Francisco, California, United States\n",
      "147/176 - Boston, Suffolk County, Massachusetts, United States\n",
      "148/176 - Providence, Providence County, Rhode Island, United States\n",
      "149/176 - Norwalk, Los Angeles County, California, 90650, United States\n",
      "150/176 - Culver City, Los Angeles County, California, 90232, United States\n",
      "151/176 - Stockholm, Stockholms kommun, Stockholms ln, 111 29, Sverige\n",
      "152/176 - Minneapolis, Hennepin County, Minnesota, United States\n",
      "153/176 - Fort Collins, Larimer County, Colorado, United States\n",
      "154/176 - Orange County, California, United States\n",
      "155/176 - Charleston, Kanawha County, West Virginia, United States\n",
      "156/176 - Los Angeles, Los Angeles County, California, United States\n",
      "157/176 - Poitiers, Vienne, Nouvelle-Aquitaine, France mtropolitaine, 86000, France\n",
      "158/176 - Olympia, Thurston County, Washington, United States\n",
      "159/176 - Buffalo, Erie County, New York, United States\n",
      "160/176 - Vorarlberg, sterreich\n",
      "161/176 - Kalamazoo, Kalamazoo County, Michigan, United States\n",
      "162/176 - Osnabrck, Niedersachsen, Deutschland\n",
      "163/176 - Cleveland, Cuyahoga County, Ohio, United States\n",
      "164/176 - Birmingham, Jefferson County, Alabama, United States\n",
      "165/176 - Richmond, Virginia, United States\n",
      "166/176 - Dale City, Prince William County, Virginia, United States\n",
      "167/176 - Amherst, Hampshire County, Massachusetts, United States\n",
      "168/176 - Seattle, King County, Washington, United States\n",
      "169/176 - Bay City, Bay County, Michigan, 48708, United States\n",
      "170/176 - Fort Wayne, Allen County, Indiana, United States\n",
      "171/176 - Huntsville, Madison County, Alabama, United States\n",
      "172/176 - Albuquerque, Bernalillo County, New Mexico, United States\n",
      "173/176 - Oakland, Alameda County, California, United States\n",
      "174/176 - El Paso, El Paso County, Texas, United States\n",
      "175/176 - Rotorua, Rotorua Lakes District, Bay of Plenty, 3010, New Zealand / Aotearoa\n",
      "176/176 - Omaha, Douglas County, Nebraska, United States\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Melbourne</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>Melbourne, Victoria, Australia</td>\n",
       "      <td>-37.814245</td>\n",
       "      <td>144.963173</td>\n",
       "      <td>Melbourne, City of Melbourne, Victoria, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Perth</td>\n",
       "      <td>Perth, Western Australia</td>\n",
       "      <td>Perth, Western Australia</td>\n",
       "      <td>-31.955893</td>\n",
       "      <td>115.860585</td>\n",
       "      <td>City of Perth, Western Australia, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Brasil</td>\n",
       "      <td>Salvador</td>\n",
       "      <td>Salvador, Bahia, Brazil</td>\n",
       "      <td>Salvador, Bahia, Brazil</td>\n",
       "      <td>-12.982250</td>\n",
       "      <td>-38.481277</td>\n",
       "      <td>Salvador, Regio Geogrfica Imediata de Salvad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Toronto</td>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "      <td>43.653482</td>\n",
       "      <td>-79.383935</td>\n",
       "      <td>Toronto, Golden Horseshoe, Ontario, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Victoria</td>\n",
       "      <td>Victoria, British Columbia, Canada</td>\n",
       "      <td>Victoria, British Columbia, Canada</td>\n",
       "      <td>48.428318</td>\n",
       "      <td>-123.364953</td>\n",
       "      <td>Victoria, Capital Regional District, British C...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>United States</td>\n",
       "      <td>Yardley</td>\n",
       "      <td>Yardley, Pennsylvania, U.S.</td>\n",
       "      <td>Yardley, Pennsylvania, US</td>\n",
       "      <td>40.245664</td>\n",
       "      <td>-74.845997</td>\n",
       "      <td>Yardley, Bucks County, Pennsylvania, United St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>United States</td>\n",
       "      <td>chattanooga</td>\n",
       "      <td>chattanooga, tennessee</td>\n",
       "      <td>chattanooga, tennessee</td>\n",
       "      <td>35.045722</td>\n",
       "      <td>-85.309488</td>\n",
       "      <td>Chattanooga, Hamilton County, East Tennessee, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>sland</td>\n",
       "      <td>Hellissandur</td>\n",
       "      <td>Hellissandur, Iceland</td>\n",
       "      <td>Hellissandur, Iceland</td>\n",
       "      <td>64.917158</td>\n",
       "      <td>-23.882463</td>\n",
       "      <td>Hellissandur, Snfellsbr, Vesturland, 360, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>sterreich</td>\n",
       "      <td>Vorarlberg</td>\n",
       "      <td>Vorarlberg, Austria</td>\n",
       "      <td>Vorarlberg, Austria</td>\n",
       "      <td>47.250000</td>\n",
       "      <td>9.916667</td>\n",
       "      <td>Vorarlberg, sterreich</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td></td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>Tokyo, Japan</td>\n",
       "      <td>Tokyo, Japan</td>\n",
       "      <td>35.676860</td>\n",
       "      <td>139.763895</td>\n",
       "      <td>, </td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>176 rows  7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           country          city                              origin  \\\n",
       "0        Australia     Melbourne      Melbourne, Victoria, Australia   \n",
       "1        Australia         Perth            Perth, Western Australia   \n",
       "2           Brasil      Salvador             Salvador, Bahia, Brazil   \n",
       "3           Canada       Toronto            Toronto, Ontario, Canada   \n",
       "4           Canada      Victoria  Victoria, British Columbia, Canada   \n",
       "..             ...           ...                                 ...   \n",
       "171  United States       Yardley         Yardley, Pennsylvania, U.S.   \n",
       "172  United States   chattanooga              chattanooga, tennessee   \n",
       "173         sland  Hellissandur               Hellissandur, Iceland   \n",
       "174     sterreich    Vorarlberg                 Vorarlberg, Austria   \n",
       "175                      Tokyo                        Tokyo, Japan   \n",
       "\n",
       "                           origin_clean   latitude   longitude  \\\n",
       "0        Melbourne, Victoria, Australia -37.814245  144.963173   \n",
       "1              Perth, Western Australia -31.955893  115.860585   \n",
       "2               Salvador, Bahia, Brazil -12.982250  -38.481277   \n",
       "3              Toronto, Ontario, Canada  43.653482  -79.383935   \n",
       "4    Victoria, British Columbia, Canada  48.428318 -123.364953   \n",
       "..                                  ...        ...         ...   \n",
       "171           Yardley, Pennsylvania, US  40.245664  -74.845997   \n",
       "172              chattanooga, tennessee  35.045722  -85.309488   \n",
       "173               Hellissandur, Iceland  64.917158  -23.882463   \n",
       "174                 Vorarlberg, Austria  47.250000    9.916667   \n",
       "175                        Tokyo, Japan  35.676860  139.763895   \n",
       "\n",
       "                                               address  \n",
       "0    Melbourne, City of Melbourne, Victoria, Australia  \n",
       "1          City of Perth, Western Australia, Australia  \n",
       "2    Salvador, Regio Geogrfica Imediata de Salvad...  \n",
       "3           Toronto, Golden Horseshoe, Ontario, Canada  \n",
       "4    Victoria, Capital Regional District, British C...  \n",
       "..                                                 ...  \n",
       "171  Yardley, Bucks County, Pennsylvania, United St...  \n",
       "172  Chattanooga, Hamilton County, East Tennessee, ...  \n",
       "173  Hellissandur, Snfellsbr, Vesturland, 360, s...  \n",
       "174                             Vorarlberg, sterreich  \n",
       "175                                            ,   \n",
       "\n",
       "[176 rows x 7 columns]"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates = get_coordinates_geopy(df_new_artists)\n",
    "df_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_coordinates_scraped: (2680, 7)\n",
      "\n",
      "Found 84 duplicates:\n",
      "               city        country\n",
      "26        Melbourne      Australia\n",
      "32            Perth      Australia\n",
      "123         Toronto         Canada\n",
      "127        Victoria         Canada\n",
      "141         Horsens        Danmark\n",
      "...             ...            ...\n",
      "2627          Tampa  United States\n",
      "2725     Washington  United States\n",
      "2732  Washington DC  United States\n",
      "2760       Whittier  United States\n",
      "2853          Tokyo             \n",
      "\n",
      "[84 rows x 2 columns]\n",
      "\n",
      "Resulting dataset: (2772, 7)\n",
      "Merged artists with coordinates! Found 92 new locations\n",
      "df_coordinates_concat exported to .csv\n"
     ]
    }
   ],
   "source": [
    "export_coordinates_concat(df_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to a .csv file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6699</th>\n",
       "      <td>Flake Music</td>\n",
       "      <td>United States</td>\n",
       "      <td>Albuquerque</td>\n",
       "      <td>35.084103</td>\n",
       "      <td>-106.650985</td>\n",
       "      <td>Albuquerque, Bernalillo County, New Mexico, Un...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6700</th>\n",
       "      <td>Until Your Heart Stops</td>\n",
       "      <td>United States</td>\n",
       "      <td>Oakland</td>\n",
       "      <td>37.804456</td>\n",
       "      <td>-122.271356</td>\n",
       "      <td>Oakland, Alameda County, California, United St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6701</th>\n",
       "      <td>Sleepercar</td>\n",
       "      <td>United States</td>\n",
       "      <td>El Paso</td>\n",
       "      <td>31.760116</td>\n",
       "      <td>-106.487040</td>\n",
       "      <td>El Paso, El Paso County, Texas, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6702</th>\n",
       "      <td>Swamp Thing</td>\n",
       "      <td>New Zealand / Aotearoa</td>\n",
       "      <td>Rotorua</td>\n",
       "      <td>-38.138149</td>\n",
       "      <td>176.252922</td>\n",
       "      <td>Rotorua, Rotorua Lakes District, Bay of Plenty...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6703</th>\n",
       "      <td>Tim Kasher</td>\n",
       "      <td>United States</td>\n",
       "      <td>Omaha</td>\n",
       "      <td>41.258746</td>\n",
       "      <td>-95.938376</td>\n",
       "      <td>Omaha, Douglas County, Nebraska, United States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      artist                 country         city   latitude  \\\n",
       "6699             Flake Music           United States  Albuquerque  35.084103   \n",
       "6700  Until Your Heart Stops           United States      Oakland  37.804456   \n",
       "6701              Sleepercar           United States      El Paso  31.760116   \n",
       "6702             Swamp Thing  New Zealand / Aotearoa      Rotorua -38.138149   \n",
       "6703              Tim Kasher           United States        Omaha  41.258746   \n",
       "\n",
       "       longitude                                            address  \n",
       "6699 -106.650985  Albuquerque, Bernalillo County, New Mexico, Un...  \n",
       "6700 -122.271356  Oakland, Alameda County, California, United St...  \n",
       "6701 -106.487040      El Paso, El Paso County, Texas, United States  \n",
       "6702  176.252922  Rotorua, Rotorua Lakes District, Bay of Plenty...  \n",
       "6703  -95.938376     Omaha, Douglas County, Nebraska, United States  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with the dataframe containing all the artists and their origins\n",
    "df_artists_origins_coordinates_concat = merge_origins_coordinates(df_new_artists)\n",
    "df_artists_origins_coordinates_concat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6704, 6)"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins_coordinates_concat = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')\n",
    "df_artists_origins_coordinates_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "brittish_cities = df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United Kingdom']\n",
    "american_cities = df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "United States     3952\n",
      "United Kingdom    1493\n",
      "Canada             213\n",
      "Sverige            153\n",
      "Australia          131\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "order = df_artists_origins_coordinates_concat['country'].value_counts().index\n",
    "print(df_artists_origins_coordinates_concat['country'].value_counts().head())\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.countplot(df_artists_origins_coordinates_concat['country'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1490 Brittish artists\n",
      "428 Brittish cities\n",
      "\n",
      "city\n",
      "London         402\n",
      "Birmingham      40\n",
      "Glasgow         40\n",
      "Manchester      39\n",
      "Brighton        38\n",
      "Leeds           36\n",
      "Liverpool       30\n",
      "Bristol         25\n",
      "Nottingham      22\n",
      "Sheffield       19\n",
      "Edinburgh       16\n",
      "Cardiff         16\n",
      "Cambridge       15\n",
      "Reading         13\n",
      "Southampton     13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{brittish_cities.shape[0]} Brittish artists\")\n",
    "order = brittish_cities['city'].value_counts().index\n",
    "print(f\"{brittish_cities['city'].nunique()} Brittish cities\\n\")\n",
    "print(brittish_cities['city'].value_counts().head(15))\n",
    "\n",
    "# plt.figure(figsize=(9,45))\n",
    "# sns.countplot(brittish_cities['city'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3703 American artists\n",
      "868 American cities\n",
      "\n",
      "city\n",
      "Los Angeles      341\n",
      "New York City    182\n",
      "Chicago          138\n",
      "San Francisco    112\n",
      "Seattle           89\n",
      "Boston            84\n",
      "Brooklyn          74\n",
      "Portland          63\n",
      "Philadelphia      61\n",
      "San Diego         56\n",
      "Atlanta           43\n",
      "Washington        41\n",
      "Austin            41\n",
      "Nashville         38\n",
      "New York          38\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{american_cities.shape[0]} American artists\")\n",
    "order = american_cities['city'].value_counts().index\n",
    "print(f\"{american_cities['city'].nunique()} American cities\\n\")\n",
    "print(american_cities['city'].value_counts().head(15))\n",
    "\n",
    "# plt.figure(figsize=(5,55))\n",
    "# sns.countplot(df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United States']['city'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
