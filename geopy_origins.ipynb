{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import json_normalize\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests \n",
    "import time\n",
    "import re\n",
    "\n",
    "# pip install geopy\n",
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from geopy_functions import *\n",
    "from my_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(56660, 13): df_uk_masters\n",
      "(48690, 13): df_us_masters\n",
      "(74652, 13): df_us_new_masters\n",
      "(6708, 13): df_us_new_masters_clean\n",
      "(51222, 5): df_ratings_20\n",
      "(9667, 13): df_masters_blended\n"
     ]
    }
   ],
   "source": [
    "# import the dataframes\n",
    "df_uk_masters = pd.read_csv('Datasets/df_uk_masters.csv')                         # all the albums from the UK\n",
    "df_us_masters = pd.read_csv('Datasets/df_us_masters.csv')                         # albums from the US until 1996, 1998 and 2000\n",
    "df_us_new_masters = pd.read_csv('Datasets/df_us_new_masters.csv')                         # albums from the US from 1997, 1999 and 2001\n",
    "df_us_new_masters_clean = pd.read_csv('Datasets/df_us_new_masters_clean.csv')             # albums from the US from 1997, 1999 and 2001, cleaned, merged with df_ratings_20\n",
    "df_ratings_20 = pd.read_csv('Datasets/df_ratings_20.csv', keep_default_na=False)  # albums with >= 20 votes, mostly from rock, worldwide\n",
    "df_masters_blended = pd.read_csv('Datasets/df_masters_blended.csv')               # albums from the UK and US (and others) with >= 20 votes until 2000 aprox\n",
    "df_artists_origins_coordinates = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')               # merge of df_masters_blended with their locations\n",
    "\n",
    "# print information\n",
    "print(f'{df_uk_masters.shape}: df_uk_masters')\n",
    "print(f'{df_us_masters.shape}: df_us_masters')\n",
    "print(f'{df_us_new_masters.shape}: df_us_new_masters')\n",
    "print(f'{df_us_new_masters_clean.shape}: df_us_new_masters_clean')\n",
    "print(f'{df_ratings_20.shape}: df_ratings_20')\n",
    "print(f'{df_masters_blended.shape}: df_masters_blended')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15152368</td>\n",
       "      <td>3747909</td>\n",
       "      <td>31909420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>As Living Arrows</td>\n",
       "      <td>Hope and Ruin</td>\n",
       "      <td>2024</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Post-Hardcore']</td>\n",
       "      <td>Post-screamo band from Brighton, UK\\r\\n</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id  master_id  main_release_id release_country            artist  \\\n",
       "0   15152368    3747909         31909420             NaN  As Living Arrows   \n",
       "\n",
       "           title  year  album_length  tracks     release_type    genres  \\\n",
       "0  Hope and Ruin  2024           0.0       8  ['LP', 'Album']  ['Rock']   \n",
       "\n",
       "              styles                            artist_profile  \n",
       "0  ['Post-Hardcore']  Post-screamo band from Brighton, UK\\r\\n   "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1441645</td>\n",
       "      <td>396963</td>\n",
       "      <td>3314361</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Devin Townsend Project</td>\n",
       "      <td>Contain Us</td>\n",
       "      <td>2011</td>\n",
       "      <td>1177.03</td>\n",
       "      <td>219</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Electronic', 'Rock', 'Pop']</td>\n",
       "      <td>['Alternative Rock', 'Industrial', 'Prog Rock'...</td>\n",
       "      <td>Rock/metal project of [a251249]. It was founde...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   artist_id  master_id  main_release_id release_country  \\\n",
       "0    1441645     396963          3314361          Europe   \n",
       "\n",
       "                   artist       title  year  album_length  tracks  \\\n",
       "0  Devin Townsend Project  Contain Us  2011       1177.03     219   \n",
       "\n",
       "  release_type                         genres  \\\n",
       "0    ['Album']  ['Electronic', 'Rock', 'Pop']   \n",
       "\n",
       "                                              styles  \\\n",
       "0  ['Alternative Rock', 'Industrial', 'Prog Rock'...   \n",
       "\n",
       "                                      artist_profile  \n",
       "0  Rock/metal project of [a251249]. It was founde...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_new_masters_clean.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Locations Wikipedia scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'Datasets/df_rock_ratings.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDatasets/df_rock_ratings.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, keep_default_na\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124martist\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mnunique()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m artists\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdf\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m albums\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[0;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m get_handle(\n\u001b[0;32m   1881\u001b[0m     f,\n\u001b[0;32m   1882\u001b[0m     mode,\n\u001b[0;32m   1883\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1884\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcompression\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1885\u001b[0m     memory_map\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmemory_map\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m),\n\u001b[0;32m   1886\u001b[0m     is_text\u001b[38;5;241m=\u001b[39mis_text,\n\u001b[0;32m   1887\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoding_errors\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstrict\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1888\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m),\n\u001b[0;32m   1889\u001b[0m )\n\u001b[0;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[1;32mc:\\Users\\Arnaldur\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'Datasets/df_rock_ratings.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/df_rock_ratings.csv', keep_default_na=False)\n",
    "\n",
    "print(f\"{df['artist'].nunique()} artists\")\n",
    "print(f\"{df.shape[0]} albums\")\n",
    "print(f\"Average of {round(df.shape[0] / df['artist'].nunique(), 2)} albums per artist in the subset with the (mostly UK) albums with more than 10 votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3823 artists\n",
      "9380 albums\n",
      "Average of 2.45 albums per artist in the subset with the (mostly UK) albums with more than 20 votes\n"
     ]
    }
   ],
   "source": [
    "df_20 = pd.read_csv('Datasets/df_rock_ratings_20.csv', keep_default_na=False)\n",
    "\n",
    "print(f\"{df_20['artist'].nunique()} artists\")\n",
    "print(f\"{df_20.shape[0]} albums\")\n",
    "print(f\"Average of {round(df_20.shape[0] / df_20['artist'].nunique(), 2)} albums per artist in the subset with the (mostly UK) albums with more than 20 votes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(51252, 5)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_ratings_20 = pd.read_csv('Datasets/df_ratings_20.csv')\n",
    "df_ratings_20.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10580</th>\n",
       "      <td>The 1975</td>\n",
       "      <td>A Brief Inquiry into Online Relationships</td>\n",
       "      <td>2018</td>\n",
       "      <td>58.43</td>\n",
       "      <td>15</td>\n",
       "      <td>['Rock', 'Pop']</td>\n",
       "      <td>['Indie Rock', 'Alternative Rock', 'Indie Pop']</td>\n",
       "      <td>UK &amp; Europe</td>\n",
       "      <td>British indie rock band. \\r\\n\\r\\nPop-rock band...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9889</th>\n",
       "      <td>Le Butcherettes</td>\n",
       "      <td>A Raw Youth</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.00</td>\n",
       "      <td>12</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>[]</td>\n",
       "      <td>US</td>\n",
       "      <td>Formed by Teri Gender Bender and Auryn Jolene ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>John Fogerty</td>\n",
       "      <td>Centerfield</td>\n",
       "      <td>1985</td>\n",
       "      <td>35.33</td>\n",
       "      <td>9</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Pop Rock', 'Folk Rock', 'Country Rock']</td>\n",
       "      <td>US</td>\n",
       "      <td>American musician, songwriter, and guitarist (...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4498</th>\n",
       "      <td>L7</td>\n",
       "      <td>The Beauty Process: Triple Platinum</td>\n",
       "      <td>1997</td>\n",
       "      <td>41.57</td>\n",
       "      <td>12</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Punk', 'Grunge']</td>\n",
       "      <td>US</td>\n",
       "      <td>American grunge punk/alternative rock band fro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5742</th>\n",
       "      <td>The Fall</td>\n",
       "      <td>Are You Are Missing Winner</td>\n",
       "      <td>2001</td>\n",
       "      <td>47.68</td>\n",
       "      <td>10</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Garage Rock', 'Punk', 'Rockabilly']</td>\n",
       "      <td>UK</td>\n",
       "      <td>Post-punk band from Greater Manchester, UK. 19...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                artist                                      title  year  \\\n",
       "10580         The 1975  A Brief Inquiry into Online Relationships  2018   \n",
       "9889   Le Butcherettes                                A Raw Youth  2015   \n",
       "6394      John Fogerty                                Centerfield  1985   \n",
       "4498                L7        The Beauty Process: Triple Platinum  1997   \n",
       "5742          The Fall                 Are You Are Missing Winner  2001   \n",
       "\n",
       "       album_length  tracks           genres  \\\n",
       "10580         58.43      15  ['Rock', 'Pop']   \n",
       "9889           0.00      12         ['Rock']   \n",
       "6394          35.33       9         ['Rock']   \n",
       "4498          41.57      12         ['Rock']   \n",
       "5742          47.68      10         ['Rock']   \n",
       "\n",
       "                                                styles release_country  \\\n",
       "10580  ['Indie Rock', 'Alternative Rock', 'Indie Pop']     UK & Europe   \n",
       "9889                                                []              US   \n",
       "6394         ['Pop Rock', 'Folk Rock', 'Country Rock']              US   \n",
       "4498                                ['Punk', 'Grunge']              US   \n",
       "5742             ['Garage Rock', 'Punk', 'Rockabilly']              UK   \n",
       "\n",
       "                                          artist_profile  \n",
       "10580  British indie rock band. \\r\\n\\r\\nPop-rock band...  \n",
       "9889   Formed by Teri Gender Bender and Auryn Jolene ...  \n",
       "6394   American musician, songwriter, and guitarist (...  \n",
       "4498   American grunge punk/alternative rock band fro...  \n",
       "5742   Post-punk band from Greater Manchester, UK. 19...  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9616"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists = df['artist'].unique()\n",
    "len(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Life at These Speeds'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[4155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aabsinthe'"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artist = \"AABSINTHE\"\n",
    "name_changed = artist.title().replace(' ', '_')\n",
    "name_changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Genres\n"
     ]
    }
   ],
   "source": [
    "artist = \"John Grant\"\n",
    "name_changed = artist.replace(' ', '_')\n",
    "name_changed_band = artist.replace(' ', '_') + ('_(band)')\n",
    "name_changed_musician = name_changed + ('_(musician)')\n",
    "\n",
    "url = f\"https://en.wikipedia.org/wiki/{name_changed_musician}\"\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "try:\n",
    "    text = table[0].text\n",
    "\n",
    "    # Step 1: Extract the part after 'Born'\n",
    "    after_born = text.split(\"Born\", 1)[1]\n",
    "\n",
    "    text_age = re.search(\"aged\", after_born)\n",
    "\n",
    "    if text_age:\n",
    "        # This means the musician is dead\n",
    "        location = re.split(r'(19\\d{2})', after_born)[4].split('Died')[0].strip()\n",
    "    else:\n",
    "        try:\n",
    "            text = re.split(r'(19\\d{2})', after_born)[4].split(')')[1]\n",
    "\n",
    "            if \"Other\\xa0names\" in text:\n",
    "                location = text.split('Other\\xa0names')[0]\n",
    "            else:\n",
    "                if \"Citizenship\" in text:\n",
    "                    location = text.split('Citizenship')[0]\n",
    "                else:\n",
    "                    if \"Genres\" in text:\n",
    "                        location = text.split('Genres')[0]\n",
    "                        print('Genres')\n",
    "                    else:\n",
    "                        if \"Occupations\" in text:\n",
    "                            location = text.split('Occupations')[0]\n",
    "                            print('Occupations')\n",
    "                        else:\n",
    "                            location = np.nan\n",
    "        except:  \n",
    "            location = np.nan\n",
    "except:\n",
    "    print('fuck')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Buchanan, Michigan, U.S.'"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'John_Grant_(musician)'"
      ]
     },
     "execution_count": 652,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name_changed_musician"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "artist = \"Stone Gossard\"\n",
    "name_changed = artist.replace(' ', '_')\n",
    "name_changed_band = artist.replace(' ', '_') + ('_(band)')\n",
    "\n",
    "url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "response = requests.get(url).content\n",
    "soup = BeautifulSoup(response, \"html.parser\")\n",
    "table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "try:\n",
    "    location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "\n",
    "# save info in lists\n",
    "    print('origin')\n",
    "\n",
    "except:\n",
    "    text = table[0].text\n",
    "\n",
    "    # Step 1: Extract the part after 'Born'\n",
    "    after_born = text.split(\"Born\", 1)[1]\n",
    "\n",
    "    text_age = re.search(\"aged\", after_born)\n",
    "\n",
    "    if text_age:\n",
    "        # This means the artist is dead\n",
    "        print('dead')\n",
    "        location = re.split(r'(19\\d{2})', after_born)[4].split('Died')[0].strip()\n",
    "    else:\n",
    "        try:\n",
    "            text = re.split(r'(19\\d{2})', after_born)[4].split(')')[1]\n",
    "\n",
    "            if \"Other\\xa0names\" in text:\n",
    "                location = text.split('Other\\xa0names')[0]\n",
    "            else:\n",
    "                if \"Citizenship\" in text:\n",
    "                    location = text.split('Citizenship')[0]\n",
    "                else:\n",
    "                    if \"Occupations\" in text:\n",
    "                        location = text.split('Occupations')[0]\n",
    "                    else:\n",
    "                        if \"Genres\" in text:\n",
    "                            location = text.split('Genres')[0]\n",
    "                            print(repr(location))\n",
    "                        else:\n",
    "                            location = np.nan\n",
    "        except:  \n",
    "            location = np.nan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seattle, Washington, U.S.GenresAlternative rockgrungeglam punkpunk rockhard rockheavy metalglam metalOccupationsMusiciansongwriterInstrumentsGuitarvocalsYears active'"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 536,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Seattle, Washington, U.S.GenresAlternative rockgrungeglam punkpunk rockhard rockheavy metalglam metal'"
      ]
     },
     "execution_count": 536,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>37</td>\n",
       "      <td>Less Than Jake</td>\n",
       "      <td>Losing Streak</td>\n",
       "      <td>3.90</td>\n",
       "      <td>414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>40</td>\n",
       "      <td>Sparta</td>\n",
       "      <td>Wiretap Scars</td>\n",
       "      <td>3.79</td>\n",
       "      <td>431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>Muse</td>\n",
       "      <td>Absolution</td>\n",
       "      <td>3.99</td>\n",
       "      <td>4411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>Muse</td>\n",
       "      <td>Showbiz</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2181</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>45</td>\n",
       "      <td>Finch</td>\n",
       "      <td>What It Is to Burn</td>\n",
       "      <td>3.69</td>\n",
       "      <td>864</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   album_id          artist               album  rating  votes\n",
       "0        37  Less Than Jake       Losing Streak    3.90    414\n",
       "1        40          Sparta       Wiretap Scars    3.79    431\n",
       "2        41            Muse          Absolution    3.99   4411\n",
       "3        42            Muse             Showbiz    3.50   2181\n",
       "4        45           Finch  What It Is to Burn    3.69    864"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_artists_origins``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3251, 2)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "df_artists_origins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sparta</td>\n",
       "      <td>El Paso, Texas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Muse</td>\n",
       "      <td>Teignmouth, Devon, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Finch</td>\n",
       "      <td>Temecula, California, Estados Unidos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Transplants</td>\n",
       "      <td>Los Angeles, California, United States[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rooney</td>\n",
       "      <td>Los Angeles, California, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        artist                                     origin\n",
       "0       Sparta                             El Paso, Texas\n",
       "1         Muse                 Teignmouth, Devon, England\n",
       "2        Finch       Temecula, California, Estados Unidos\n",
       "3  Transplants  Los Angeles, California, United States[1]\n",
       "4       Rooney              Los Angeles, California, U.S."
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins[df_artists_origins['origin']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists = df_artists_origins[df_artists_origins['origin']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>Son of Dork</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1192</th>\n",
       "      <td>Mojave 3</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>Crippled Black Phoenix</td>\n",
       "      <td>Bristol, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>This Mortal Coil</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2191</th>\n",
       "      <td>Arcadia</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2300</th>\n",
       "      <td>Jade Warrior</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2348</th>\n",
       "      <td>The Waterboys</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2469</th>\n",
       "      <td>Blackmore's Night</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2556</th>\n",
       "      <td>Atomic Rooster</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>The Nefilim</td>\n",
       "      <td>Lambeth, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2715</th>\n",
       "      <td>Black Spiders</td>\n",
       "      <td>Sheffield, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2822</th>\n",
       "      <td>Brontide</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2878</th>\n",
       "      <td>Gilgamesh</td>\n",
       "      <td>Hampstead, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2914</th>\n",
       "      <td>Young Legionnaire</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2924</th>\n",
       "      <td>The Deviants</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2956</th>\n",
       "      <td>Head of David</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3157</th>\n",
       "      <td>Quintessence</td>\n",
       "      <td>London, England</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      artist                                 origin\n",
       "1059             Son of Dork                        London, England\n",
       "1192                Mojave 3                        London, England\n",
       "1326  Crippled Black Phoenix                       Bristol, England\n",
       "1597        This Mortal Coil                    Wandsworth, England\n",
       "2191                 Arcadia                        London, England\n",
       "2300            Jade Warrior                        London, England\n",
       "2348           The Waterboys                        London, England\n",
       "2469       Blackmore's Night         Mount Sinai, NY, United States\n",
       "2556          Atomic Rooster                        London, England\n",
       "2609             The Nefilim                       Lambeth, England\n",
       "2715           Black Spiders                     Sheffield, England\n",
       "2822                Brontide                        London, England\n",
       "2878               Gilgamesh                     Hampstead, England\n",
       "2914       Young Legionnaire                        London, England\n",
       "2924            The Deviants        Ladbroke Grove, London, England\n",
       "2956           Head of David  Dudley, West Midlands, United Kingdom\n",
       "3157            Quintessence                        London, England"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Son of Dork\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Mojave 3\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Crippled Black Phoenix\", \"Bristol, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"This Mortal Coil\", \"Wandsworth, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Arcadia\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Jade Warrior\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Waterboys\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Blackmore's Night\", \"Mount Sinai, NY, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Atomic Rooster\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Nefilim\", \"Lambeth, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Black Spiders\", \"Sheffield, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Brontide\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Gilgamesh\", \"Hampstead, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Young Legionnaire\", \"London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Deviants\", \"Ladbroke Grove, London, England\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Head of David\", \"Dudley, West Midlands, United Kingdom\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Quintessence\", \"London, England\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formed in 1969, they played a blend of jazz, progressive rock, Indian Music, and new age rock.   Members included:\n",
      "Sambhu Babaji : Bass  Dave Codling : Guitar  Shiva Shankar Jones : Keyboards, Vocals  Jake Milton : Drums  Alan Mostert\n",
      ": Guitar  Raja Ram : Flute, Piano, Vocals\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[8016]['artist_profile']\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>styles</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8016</th>\n",
       "      <td>1969</td>\n",
       "      <td>Quintessence</td>\n",
       "      <td>In Blissful Company</td>\n",
       "      <td>3.88</td>\n",
       "      <td>16</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "      <td>['Psychedelic Rock']</td>\n",
       "      <td>UK</td>\n",
       "      <td>Formed in 1969, they played a blend of jazz, p...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      year        artist                title  rating  votes  album_length  \\\n",
       "8016  1969  Quintessence  In Blissful Company    3.88     16           0.0   \n",
       "\n",
       "      tracks                styles release_country  \\\n",
       "8016       8  ['Psychedelic Rock']              UK   \n",
       "\n",
       "                                         artist_profile  \n",
       "8016  Formed in 1969, they played a blend of jazz, p...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Quintessence\".strip()].sort_values('votes', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3234, 2)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = df_artists_origins[df_artists_origins['origin']!='United Kingdom']\n",
    "df_artists_origins.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_artists_origins.to_csv('Datasets/df_artists_origins.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_artists_origins_concat exported to .csv\n",
      "(3251, 2)\n"
     ]
    }
   ],
   "source": [
    "export_artists_origins_concat(df_new_artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/9 - London, Greater London, England, United Kingdom\n",
      "2/9 - Bristol, City of Bristol, West of England, England, United Kingdom\n",
      "3/9 - Wandsworth, London Borough of Wandsworth, London, Greater London, England, SW18 1UJ, United Kingdom\n",
      "4/9 - Mount Sinai, Miller Place, Town of Brookhaven, Suffolk County, New York, 11766, United States\n",
      "5/9 - Lambeth, London Borough of Lambeth, London, Greater London, England, SE1 7JW, United Kingdom\n",
      "6/9 - Sheffield, South Yorkshire, England, United Kingdom\n",
      "7/9 - Hampstead, Greater London, England, NW3 1QG, United Kingdom\n",
      "8/9 - Ladbroke Grove, Westway, Lancaster West Estate, North Kensington, Royal Borough of Kensington and Chelsea, London, Greater London, England, W10 5YG, United Kingdom\n",
      "9/9 - Dudley, West Midlands, England, United Kingdom\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Bristol</td>\n",
       "      <td>Bristol, England</td>\n",
       "      <td>Bristol, England</td>\n",
       "      <td>51.453802</td>\n",
       "      <td>-2.597298</td>\n",
       "      <td>Bristol, City of Bristol, West of England, Eng...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Dudley</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "      <td>Dudley, West Midlands, United Kingdom</td>\n",
       "      <td>52.511083</td>\n",
       "      <td>-2.081681</td>\n",
       "      <td>Dudley, West Midlands, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Hampstead</td>\n",
       "      <td>Hampstead, England</td>\n",
       "      <td>Hampstead, England</td>\n",
       "      <td>51.556530</td>\n",
       "      <td>-0.178301</td>\n",
       "      <td>Hampstead, Greater London, England, NW3 1QG, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Ladbroke Grove</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "      <td>Ladbroke Grove, London, England</td>\n",
       "      <td>51.517264</td>\n",
       "      <td>-0.211102</td>\n",
       "      <td>Ladbroke Grove, Westway, Lancaster West Estate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Lambeth</td>\n",
       "      <td>Lambeth, England</td>\n",
       "      <td>Lambeth, England</td>\n",
       "      <td>51.495211</td>\n",
       "      <td>-0.116335</td>\n",
       "      <td>Lambeth, London Borough of Lambeth, London, Gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>London, England</td>\n",
       "      <td>London, England</td>\n",
       "      <td>51.507446</td>\n",
       "      <td>-0.127765</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Sheffield</td>\n",
       "      <td>Sheffield, England</td>\n",
       "      <td>Sheffield, England</td>\n",
       "      <td>53.380663</td>\n",
       "      <td>-1.470228</td>\n",
       "      <td>Sheffield, South Yorkshire, England, United Ki...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Wandsworth</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "      <td>Wandsworth, England</td>\n",
       "      <td>51.457027</td>\n",
       "      <td>-0.193261</td>\n",
       "      <td>Wandsworth, London Borough of Wandsworth, Lond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>United States</td>\n",
       "      <td>Mount Sinai</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "      <td>Mount Sinai, NY, United States</td>\n",
       "      <td>40.941066</td>\n",
       "      <td>-73.019455</td>\n",
       "      <td>Mount Sinai, Miller Place, Town of Brookhaven,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          country            city                                 origin  \\\n",
       "0  United Kingdom         Bristol                       Bristol, England   \n",
       "1  United Kingdom          Dudley  Dudley, West Midlands, United Kingdom   \n",
       "2  United Kingdom       Hampstead                     Hampstead, England   \n",
       "3  United Kingdom  Ladbroke Grove        Ladbroke Grove, London, England   \n",
       "4  United Kingdom         Lambeth                       Lambeth, England   \n",
       "5  United Kingdom          London                        London, England   \n",
       "6  United Kingdom       Sheffield                     Sheffield, England   \n",
       "7  United Kingdom      Wandsworth                    Wandsworth, England   \n",
       "8   United States     Mount Sinai         Mount Sinai, NY, United States   \n",
       "\n",
       "                            origin_clean   latitude  longitude  \\\n",
       "0                       Bristol, England  51.453802  -2.597298   \n",
       "1  Dudley, West Midlands, United Kingdom  52.511083  -2.081681   \n",
       "2                     Hampstead, England  51.556530  -0.178301   \n",
       "3        Ladbroke Grove, London, England  51.517264  -0.211102   \n",
       "4                       Lambeth, England  51.495211  -0.116335   \n",
       "5                        London, England  51.507446  -0.127765   \n",
       "6                     Sheffield, England  53.380663  -1.470228   \n",
       "7                    Wandsworth, England  51.457027  -0.193261   \n",
       "8         Mount Sinai, NY, United States  40.941066 -73.019455   \n",
       "\n",
       "                                             address  \n",
       "0  Bristol, City of Bristol, West of England, Eng...  \n",
       "1     Dudley, West Midlands, England, United Kingdom  \n",
       "2  Hampstead, Greater London, England, NW3 1QG, U...  \n",
       "3  Ladbroke Grove, Westway, Lancaster West Estate...  \n",
       "4  Lambeth, London Borough of Lambeth, London, Gr...  \n",
       "5    London, Greater London, England, United Kingdom  \n",
       "6  Sheffield, South Yorkshire, England, United Ki...  \n",
       "7  Wandsworth, London Borough of Wandsworth, Lond...  \n",
       "8  Mount Sinai, Miller Place, Town of Brookhaven,...  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates = get_coordinates_geopy(df_new_artists)\n",
    "df_coordinates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_coordinates``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1527, 7)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "df_coordinates_scraped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Adelaide, South Australia, Australia</td>\n",
       "      <td>Adelaide, South Australia, Australia</td>\n",
       "      <td>-34.928181</td>\n",
       "      <td>138.599931</td>\n",
       "      <td>Adelaide, Adelaide City Council, South Austral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Adelaide</td>\n",
       "      <td>Adelaide, South Australia</td>\n",
       "      <td>Adelaide, South Australia</td>\n",
       "      <td>-34.928181</td>\n",
       "      <td>138.599931</td>\n",
       "      <td>Adelaide, Adelaide City Council, South Austral...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Blue Mountains</td>\n",
       "      <td>Blue Mountains, NSW, Australia</td>\n",
       "      <td>Blue Mountains, NSW, Australia</td>\n",
       "      <td>-33.609741</td>\n",
       "      <td>150.405224</td>\n",
       "      <td>Blue Mountains, New South Wales, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Brisbane</td>\n",
       "      <td>Brisbane, Queensland, Australia</td>\n",
       "      <td>Brisbane, Queensland, Australia</td>\n",
       "      <td>-27.468968</td>\n",
       "      <td>153.023499</td>\n",
       "      <td>City of Brisbane, Queensland, Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Australia</td>\n",
       "      <td>Byron Bay</td>\n",
       "      <td>Byron Bay, New South Wales, Australia</td>\n",
       "      <td>Byron Bay, New South Wales, Australia</td>\n",
       "      <td>-28.648333</td>\n",
       "      <td>153.617778</td>\n",
       "      <td>Byron Bay, Byron Shire Council, New South Wale...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country            city                                 origin  \\\n",
       "0  Australia        Adelaide   Adelaide, South Australia, Australia   \n",
       "1  Australia        Adelaide              Adelaide, South Australia   \n",
       "2  Australia  Blue Mountains         Blue Mountains, NSW, Australia   \n",
       "3  Australia        Brisbane        Brisbane, Queensland, Australia   \n",
       "4  Australia       Byron Bay  Byron Bay, New South Wales, Australia   \n",
       "\n",
       "                            origin_clean   latitude   longitude  \\\n",
       "0   Adelaide, South Australia, Australia -34.928181  138.599931   \n",
       "1              Adelaide, South Australia -34.928181  138.599931   \n",
       "2         Blue Mountains, NSW, Australia -33.609741  150.405224   \n",
       "3        Brisbane, Queensland, Australia -27.468968  153.023499   \n",
       "4  Byron Bay, New South Wales, Australia -28.648333  153.617778   \n",
       "\n",
       "                                             address  \n",
       "0  Adelaide, Adelaide City Council, South Austral...  \n",
       "1  Adelaide, Adelaide City Council, South Austral...  \n",
       "2         Blue Mountains, New South Wales, Australia  \n",
       "3            City of Brisbane, Queensland, Australia  \n",
       "4  Byron Bay, Byron Shire Council, New South Wale...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>54.702354</td>\n",
       "      <td>-3.276575</td>\n",
       "      <td>United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            country            city          origin    origin_clean  \\\n",
       "702  United Kingdom  United Kingdom  United Kingdom  United Kingdom   \n",
       "\n",
       "      latitude  longitude         address  \n",
       "702  54.702354  -3.276575  United Kingdom  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped[df_coordinates_scraped['city']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_clean</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [country, city, origin, origin_clean, latitude, longitude, address]\n",
       "Index: []"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates_scraped.drop(702, axis=0, inplace=True)\n",
    "df_coordinates_scraped[df_coordinates_scraped['city']=='United Kingdom']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coordinates_scraped.to_csv('Datasets/df_coordinates.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9, 7)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_coordinates.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_coordinates_scraped: (1526, 7)\n",
      "\n",
      "Found 4 duplicates:\n",
      "               city         country\n",
      "324         Bristol  United Kingdom\n",
      "515  Ladbroke Grove  United Kingdom\n",
      "542          London  United Kingdom\n",
      "650       Sheffield  United Kingdom\n",
      "\n",
      "Resulting dataset: (1531, 7)\n",
      "Merged artists with coordinates! Found 5 new locations\n",
      "df_coordinates_concat exported to .csv\n"
     ]
    }
   ],
   "source": [
    "export_coordinates_concat(df_coordinates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``df_artists_origins_coordinates_concat``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to a .csv file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3246</th>\n",
       "      <td>Gilgamesh</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Hampstead</td>\n",
       "      <td>51.556530</td>\n",
       "      <td>-0.178301</td>\n",
       "      <td>Hampstead, Greater London, England, NW3 1QG, U...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>Young Legionnaire</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>51.489334</td>\n",
       "      <td>-0.144055</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3248</th>\n",
       "      <td>The Deviants</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Ladbroke Grove</td>\n",
       "      <td>51.517264</td>\n",
       "      <td>-0.211102</td>\n",
       "      <td>Ladbroke Grove, Westway, Lancaster West Estate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>Head of David</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>Dudley</td>\n",
       "      <td>52.511083</td>\n",
       "      <td>-2.081681</td>\n",
       "      <td>Dudley, West Midlands, England, United Kingdom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Quintessence</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>London</td>\n",
       "      <td>51.489334</td>\n",
       "      <td>-0.144055</td>\n",
       "      <td>London, Greater London, England, United Kingdom</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 artist         country            city   latitude  longitude  \\\n",
       "3246          Gilgamesh  United Kingdom       Hampstead  51.556530  -0.178301   \n",
       "3247  Young Legionnaire  United Kingdom          London  51.489334  -0.144055   \n",
       "3248       The Deviants  United Kingdom  Ladbroke Grove  51.517264  -0.211102   \n",
       "3249      Head of David  United Kingdom          Dudley  52.511083  -2.081681   \n",
       "3250       Quintessence  United Kingdom          London  51.489334  -0.144055   \n",
       "\n",
       "                                                address  \n",
       "3246  Hampstead, Greater London, England, NW3 1QG, U...  \n",
       "3247    London, Greater London, England, United Kingdom  \n",
       "3248  Ladbroke Grove, Westway, Lancaster West Estate...  \n",
       "3249     Dudley, West Midlands, England, United Kingdom  \n",
       "3250    London, Greater London, England, United Kingdom  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins_coordinates_concat = merge_origins_coordinates(df_new_artists)\n",
    "df_artists_origins_coordinates_concat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>3821235</td>\n",
       "      <td>1537522</td>\n",
       "      <td>13529787</td>\n",
       "      <td>US</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Entity</td>\n",
       "      <td>2019</td>\n",
       "      <td>38.42</td>\n",
       "      <td>8</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Death Metal']</td>\n",
       "      <td>Death Metal band from Chicago, Illinois, USA. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1592</th>\n",
       "      <td>3821235</td>\n",
       "      <td>1094310</td>\n",
       "      <td>8362817</td>\n",
       "      <td>US</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Sentient</td>\n",
       "      <td>2016</td>\n",
       "      <td>37.92</td>\n",
       "      <td>9</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Death Metal']</td>\n",
       "      <td>Death Metal band from Chicago, Illinois, USA. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5257</th>\n",
       "      <td>184256</td>\n",
       "      <td>175620</td>\n",
       "      <td>279855</td>\n",
       "      <td>UK</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>We'll Talk About It Later</td>\n",
       "      <td>1971</td>\n",
       "      <td>0.00</td>\n",
       "      <td>7</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Jazz', 'Rock']</td>\n",
       "      <td>['Fusion', 'Jazz-Funk', 'Jazz-Rock', 'Prog Rock']</td>\n",
       "      <td>Pioneering jazz-rock, progressive, psychedelic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10195</th>\n",
       "      <td>184256</td>\n",
       "      <td>23574</td>\n",
       "      <td>465143</td>\n",
       "      <td>UK</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Elastic Rock</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Jazz', 'Rock']</td>\n",
       "      <td>['Jazz-Rock', 'Fusion', 'Prog Rock']</td>\n",
       "      <td>Pioneering jazz-rock, progressive, psychedelic...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       artist_id  master_id  main_release_id release_country        artist  \\\n",
       "1004     3821235    1537522         13529787              US  Nucleus (US)   \n",
       "1592     3821235    1094310          8362817              US  Nucleus (US)   \n",
       "5257      184256     175620           279855              UK  Nucleus (UK)   \n",
       "10195     184256      23574           465143              UK  Nucleus (UK)   \n",
       "\n",
       "                           title  year  album_length  tracks     release_type  \\\n",
       "1004                      Entity  2019         38.42       8        ['Album']   \n",
       "1592                    Sentient  2016         37.92       9        ['Album']   \n",
       "5257   We'll Talk About It Later  1971          0.00       7  ['LP', 'Album']   \n",
       "10195               Elastic Rock  1970          0.00      13  ['LP', 'Album']   \n",
       "\n",
       "                 genres                                             styles  \\\n",
       "1004           ['Rock']                                    ['Death Metal']   \n",
       "1592           ['Rock']                                    ['Death Metal']   \n",
       "5257   ['Jazz', 'Rock']  ['Fusion', 'Jazz-Funk', 'Jazz-Rock', 'Prog Rock']   \n",
       "10195  ['Jazz', 'Rock']               ['Jazz-Rock', 'Fusion', 'Prog Rock']   \n",
       "\n",
       "                                          artist_profile  \n",
       "1004   Death Metal band from Chicago, Illinois, USA. ...  \n",
       "1592   Death Metal band from Chicago, Illinois, USA. ...  \n",
       "5257   Pioneering jazz-rock, progressive, psychedelic...  \n",
       "10195  Pioneering jazz-rock, progressive, psychedelic...  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended[df_masters_blended['artist'].str.contains('Nucleus')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist_id, master_id, main_release_id, release_country, artist, title, year, album_length, tracks, release_type, genres, styles, artist_profile]\n",
       "Index: []"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_masters_blended[df_masters_blended['title'].str.contains('Alleycat')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>29004</th>\n",
       "      <td>86398</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Elastic Rock</td>\n",
       "      <td>3.55</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29120</th>\n",
       "      <td>87140</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>We'll Talk About It Later</td>\n",
       "      <td>3.79</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39636</th>\n",
       "      <td>216509</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Sentient</td>\n",
       "      <td>3.29</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45524</th>\n",
       "      <td>333839</td>\n",
       "      <td>Nucleus (US)</td>\n",
       "      <td>Entity</td>\n",
       "      <td>3.68</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46380</th>\n",
       "      <td>352917</td>\n",
       "      <td>Nucleus (UK)</td>\n",
       "      <td>Alleycat</td>\n",
       "      <td>3.52</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       album_id        artist                      title  rating  votes\n",
       "29004     86398  Nucleus (UK)               Elastic Rock    3.55     20\n",
       "29120     87140  Nucleus (UK)  We'll Talk About It Later    3.79     21\n",
       "39636    216509  Nucleus (US)                   Sentient    3.29     29\n",
       "45524    333839  Nucleus (US)                     Entity    3.68     40\n",
       "46380    352917  Nucleus (UK)                   Alleycat    3.52     20"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ratings_20[df_ratings_20['artist'].str.contains('Nucleus')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.loc[46380, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[29004, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[29120, 'artist'] = 'Nucleus (UK)'\n",
    "df_ratings_20.loc[39636, 'artist'] = 'Nucleus (US)'\n",
    "df_ratings_20.loc[45524, 'artist'] = 'Nucleus (US)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12059, 10)"
      ]
     },
     "execution_count": 869,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.drop([7660, 8037], axis=0, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>album</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [album_id, artist, album, rating, votes]\n",
       "Index: []"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['artist'] = np.where(df['artist']=='pg.99 / Majority Rule', 'Majority Rule', df['artist'])\n",
    "df[df['artist']=='pg.99 / Majority Rule']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.to_csv('Datasets/df_ratings_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12059, 10)"
      ]
     },
     "execution_count": 581,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Testing code for strange cases**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 - Funeral_for_a_Friend_(band): Bridgend, Wales\n",
      "1 - Millencolin_(band): multiple issues - rebro, Sweden\n",
      "2 - The_Flaming_Lips_(band): Oklahoma City, Oklahoma, U.S.\n",
      "3 - Feeder_(band): Feeder in 2008\n",
      "4 - Descendents_(band): Manhattan Beach, California, U.S.\n",
      "5 - PJ Harvey: no location found\n",
      "6 - Godsmack_(band): Lawrence, Massachusetts U.S.\n",
      "7 - Blind_Faith_(band): Ripley, Surrey, England\n",
      "8 - Van_Halen_(band): Pasadena, California, U.S.\n",
      "9 - Damageplan_(band): Dallas, Texas, U.S.\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('Datasets/df_ratings.csv')\n",
    "artists = df['artist'].unique()\n",
    "\n",
    "artists_list = []\n",
    "origin_list = []\n",
    "count=0\n",
    "\n",
    "for index in artists[140:150]:\n",
    "\n",
    "    artists_list.append(index)\n",
    "    name_changed = index.replace(' ', '_')\n",
    "    name_changed_band = name_changed + ('_(band)')\n",
    "\n",
    "    try:\n",
    "        url = f\"https://en.wikipedia.org/wiki/{name_changed_band}\"\n",
    "        response = requests.get(url).content\n",
    "        soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "        origin = soup.select('table tr th', class_='infobox-label')\n",
    "\n",
    "        if len(origin) > 0:\n",
    "            try:\n",
    "                if origin[2].text == 'Origin':\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[1].text\n",
    "                elif origin[3].text == 'Origin':\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[2].text\n",
    "                # else:\n",
    "                    \n",
    "                if 'multiple issues' in location:\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[7].text        \n",
    "                    print(f'{count} - {name_changed_band}: multiple issues - {location}')\n",
    "                    origin_list.append(location)\n",
    "                elif 'additional citations' in location:\n",
    "                    location = soup.select('table tr td', class_='infobox-data')[3].text        \n",
    "                    print(f'{count} - {name_changed_band}: additional citations - {location}')\n",
    "                    origin_list.append(location)\n",
    "\n",
    "                else:\n",
    "                    print(f'{count} - {name_changed_band}: {location}')\n",
    "                    origin_list.append(location)\n",
    "            except:\n",
    "                print(f'{count} - {name_changed_band}: {location}')\n",
    "                origin_list.append(location)      \n",
    "        else:\n",
    "            try:\n",
    "                url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "                response = requests.get(url).content\n",
    "                soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "                origin = soup.select('table tr th', class_='infobox-label')\n",
    "\n",
    "                if len(origin) > 0:\n",
    "                    if origin[2].text == 'Origin':\n",
    "                        location = soup.select('table tr td', class_='infobox-data')[1].text\n",
    "\n",
    "                        if 'multiple issues' in location:\n",
    "                            location = soup.select('table tr td', class_='infobox-data')[7].text        \n",
    "                            print(f'{count} - {name_changed_band}: multiple issues - {location}')\n",
    "                            origin_list.append(location)\n",
    "                        elif 'additional citations' in location:\n",
    "                            location = soup.select('table tr td', class_='infobox-data')[3].text        \n",
    "                            print(f'{count} - {name_changed_band}: additional citations - {location}')\n",
    "                            origin_list.append(location)\n",
    "                        else:\n",
    "                            print(f'{count} - {name_changed_band}: {location}')\n",
    "                            origin_list.append(location)\n",
    "\n",
    "                    elif origin[3].text == 'Origin':\n",
    "                        location = soup.select('table tr td', class_='infobox-data')[2].text\n",
    "                        print(f'{count} - {name_changed_band}: {location}')\n",
    "                        origin_list.append(location) \n",
    "\n",
    "                    else:\n",
    "                        print(f'{count} - {index}: no location found')\n",
    "                        origin_list.append(np.nan)  \n",
    "                else:\n",
    "                    print(f'{count} - {index}: short length')\n",
    "                    origin_list.append(np.nan)\n",
    "            except:\n",
    "                print(f'{count} - {index}: error')\n",
    "                origin_list.append(np.nan)\n",
    "    except:\n",
    "        print(f'{count} - {index}: error')\n",
    "        origin_list.append(np.nan)\n",
    "\n",
    "    if len(artists_list) != len(origin_list):\n",
    "        print('different lengths')\n",
    "        break\n",
    "\n",
    "    count+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_origins_wikipedia(df, start_index, final_index):\n",
    "    df = pd.read_csv('Datasets/df_rock_ratings_20.csv')\n",
    "    artists = df['artist'].unique()\n",
    "\n",
    "    try:\n",
    "    # import the DataFrame with the locations whose coordinates I already have\n",
    "        df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "        print('Bingo! df_coordinates.csv found \\n')\n",
    "    except: \n",
    "        print('df_coordinates.csv not found \\n')\n",
    "\n",
    "    artists_list = []\n",
    "    origin_list = []\n",
    "    count=0\n",
    "    scraped=0\n",
    "\n",
    "    for index in artists_us_to_do[start_index:final_index]:\n",
    "\n",
    "        name_changed = index.replace(' ', '_')\n",
    "        name_changed_band = name_changed + ('_(band)')\n",
    "\n",
    "        try:\n",
    "            url = f\"https://en.wikipedia.org/wiki/{name_changed_band}\"\n",
    "            response = requests.get(url).content\n",
    "            soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "            table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "            location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "            city = location.split(', ')[0]\n",
    "            count+=1\n",
    "            \n",
    "        # save info in lists\n",
    "            artists_list.append(index)  \n",
    "            origin_list.append(location)\n",
    "            scraped+=1\n",
    "            print(f'{scraped}/{count} - {name_changed_band}: {location}')\n",
    "\n",
    "        except:\n",
    "            try:\n",
    "                url = f\"https://en.wikipedia.org/wiki/{name_changed}\"\n",
    "                response = requests.get(url).content\n",
    "                soup = BeautifulSoup(response, \"html.parser\")\n",
    "                table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "\n",
    "                try:\n",
    "                    location = table[0].text.split('Origin')[1].split('Genres')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1 \n",
    "    \n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed}: {location}')\n",
    "\n",
    "                except:\n",
    "                    location = table[0].text.split(')')[2].split('Genres')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1\n",
    "\n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed} (individual): {location}')\n",
    "\n",
    "            except:\n",
    "                try:\n",
    "                    url = f\"https://es.wikipedia.org/wiki/{name_changed}\"\n",
    "                    response = requests.get(url).content\n",
    "                    soup = BeautifulSoup(response, \"html.parser\")\n",
    "\n",
    "                    table = soup.select('#mw-content-text > div.mw-content-ltr.mw-parser-output > table.infobox')\n",
    "                    location = table[0].text.split('Origen\\n')[1].split(' Informacin')[0]\n",
    "                    city = location.split(', ')[0]\n",
    "                    count+=1    \n",
    "    \n",
    "                # save info in lists\n",
    "                    artists_list.append(index)  \n",
    "                    origin_list.append(location)\n",
    "                    scraped+=1\n",
    "                    print(f'{scraped}/{count} - {name_changed} (espaol): {location}')\n",
    "\n",
    "                except:\n",
    "                    count+=1\n",
    "                    print(f'{scraped}/{count} - {index}: error')\n",
    "                    artists_list.append(index) \n",
    "                    origin_list.append(np.nan)\n",
    "\n",
    "        if len(artists_list) != len(origin_list):\n",
    "            print('different lengths')\n",
    "            break\n",
    "\n",
    "    df_artists_origins = pd.DataFrame({'artist': artists_list\n",
    "                             , 'origin': origin_list})\n",
    "    \n",
    "    return df_artists_origins"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_new_artists(df_artists_origins):\n",
    "\n",
    "# import the df with the artists' origins already scraped\n",
    "    df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "\n",
    "    if df_artists_origins['origin'].isna().sum() == 0:        \n",
    "        print(\"No null values, but let's take a look just in case there are weird locations\")\n",
    "\n",
    "    else: \n",
    "    # take a look at the df with the new artists and make sure there are non null values in origin (when it couldn't find it in Wikipedia)\n",
    "        print(f'{round(df_artists_origins['origin'].isna().sum() / df_artists_origins.shape[0]*100, 2)} % of nulls')\n",
    "    \n",
    "# subset of the new artists I just got, wether there are null values or not\n",
    "    df_new_artists = df_artists_origins[~df_artists_origins['artist'].isin(df_artists_origins_scraped['artist'].values)]\n",
    "\n",
    "    print(\"Here is the dataframe with the new artists, without duplicates\")\n",
    "    return df_new_artists   # so I can take a look at it and then continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_artists_origins_concat(df_new_artists):\n",
    "\n",
    "# import the df with the artists' origins already scraped\n",
    "    df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "\n",
    "# concat with the df I just got\n",
    "    df_artists_origins_concat = pd.concat([df_artists_origins_scraped, df_new_artists])\n",
    "    df_artists_origins_concat.drop_duplicates(inplace=True)     # just in case\n",
    "    df_artists_origins_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# export all the artists and their origins to a .csv file (the ones I got plus the new artists)\n",
    "    df_artists_origins_concat.to_csv('Datasets/df_artists_origins.csv', index=False)\n",
    "    print('df_artists_origins_concat exported to .csv')\n",
    "    print(df_artists_origins_concat.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coordinates_geopy(df_new_artists):\n",
    "    \n",
    "# replace special characters for spaces\n",
    "    df_new_artists['origin_clean'] = df_new_artists['origin'].str.replace('.', '')\n",
    "    df_new_artists['origin_clean'] = df_new_artists['origin_clean'].str.replace(r'\\[\\d+\\]', '', regex=True)\n",
    "\n",
    "# run the function that gets the coordinates from the origins from Geopy\n",
    "    geolocator = Nominatim(user_agent=\"music_analysis\", timeout=10)\n",
    "\n",
    "# if they are 'dirty' origins that after the cleaning, they result in the same 'origin_clean'\n",
    "    df_unique = df_new_artists[['origin', 'origin_clean']].drop_duplicates() \n",
    "    unique_origins = df_unique['origin'].values\n",
    "    unique_origins_clean = df_unique['origin_clean'].values\n",
    "\n",
    "    country_list = []\n",
    "    city_list = []\n",
    "    latitude_list = []\n",
    "    longitude_list = []\n",
    "    address_list = []\n",
    "    lists = [country_list, city_list, latitude_list, longitude_list, address_list]\n",
    "    count = 0\n",
    "\n",
    "    for origin in unique_origins_clean:\n",
    "        count+=1\n",
    "        time.sleep(1)\n",
    "        location = geolocator.geocode(origin)\n",
    "\n",
    "        print(f'{count}/{len(unique_origins_clean)} - {location.address}')  \n",
    "\n",
    "    # save the info in lists\n",
    "        country_list.append(location.address.split(', ')[-1])\n",
    "        city_list.append(origin.split(', ')[0])\n",
    "        latitude_list.append(location.latitude)\n",
    "        longitude_list.append(location.longitude)\n",
    "        address_list.append(location.address)\n",
    "\n",
    "        # # Check lengths\n",
    "        # print(f\"{count}/{len(unique_origins_clean)} - {origin}\")\n",
    "        # print(f\"Current list lengths -> country: {len(country_list)}, city: {len(city_list)}, \"\n",
    "        #     f\"lat: {len(latitude_list)}, lon: {len(longitude_list)}, address: {len(address_list)}\")\n",
    "\n",
    "    df_coordinates = pd.DataFrame({'country': country_list\n",
    "                                , 'city': city_list\n",
    "                                , 'origin': unique_origins\n",
    "                                , 'origin_clean': unique_origins_clean\n",
    "                                , 'latitude': latitude_list\n",
    "                                , 'longitude': longitude_list\n",
    "                                , 'address': address_list})\n",
    "    df_coordinates.sort_values(['country', 'city'], inplace=True) # sort by country and city\n",
    "    df_coordinates.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def export_coordinates_concat(df_coordinates):\n",
    "\n",
    "# import the last df that contains the coordinates of the unique origins\n",
    "    df_coordinates_scraped = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "    print(f\"df_coordinates_scraped: {df_coordinates_scraped.shape}\\n\")\n",
    "\n",
    "# concat with the df of the coordinates I just got\n",
    "    df_coordinates_concat = pd.concat([df_coordinates_scraped, df_coordinates])\n",
    "    df_coordinates_concat.sort_values(['country', 'city'], inplace=True) # sort by country and city\n",
    "    df_coordinates_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# look for duplicates in the origin, between the locations I had already gotten and the new ones\n",
    "    check_duplicates_origins(df_coordinates_concat)\n",
    "    new_origins = df_coordinates_concat.shape[0] - df_coordinates_scraped.shape[0]\n",
    "    print(f\"Merged artists with coordinates! Found {new_origins} new locations\")\n",
    "\n",
    "# save it in a csv file (the coordinates I had plus the ones from the new artists I just got)\n",
    "    df_coordinates_concat.to_csv('Datasets/df_coordinates.csv', index=False)\n",
    "    print('df_coordinates_concat exported to .csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_origins_coordinates(df_new_artists):\n",
    "\n",
    "# import the last df that contains the coordinates of the unique origins\n",
    "    df_coordinates_concat = pd.read_csv('Datasets/df_coordinates.csv')\n",
    "\n",
    "# merge with the previous df with the artists\n",
    "    df_artists_origins_coordinates = pd.merge(df_new_artists, df_coordinates_concat, on=['origin'])\n",
    "    df_artists_origins_coordinates.drop(columns=['origin', 'origin_clean_x', 'origin_clean_y'], inplace=True)\n",
    "\n",
    "# import the df that contains info of the artists and the coordinates of their origins\n",
    "    df_artists_origins_coordinates_scraped = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')\n",
    "\n",
    "# concat to get the df with all the artists, origins and their coordinates\n",
    "    df_artists_origins_coordinates_concat = pd.concat([df_artists_origins_coordinates_scraped, df_artists_origins_coordinates])\n",
    "    df_artists_origins_coordinates_concat.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# save it in a csv file\n",
    "    df_artists_origins_coordinates_concat.to_csv('Datasets/df_artists_origins_coordinates.csv', index=False)\n",
    "    print(\"Exported to a .csv file\")\n",
    "\n",
    "    return df_artists_origins_coordinates_concat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge dataframes and look for the ``new_artists``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4527"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_blend = df_masters_blended['artist'].unique()\n",
    "len(artists_blend)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1555"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "artists = df_artists_origins['artist'].unique()\n",
    "artists_usa = []\n",
    "\n",
    "for artist in artists_blend:\n",
    "    if artist not in df_artists_origins['artist'].values:\n",
    "        artists_usa.append(artist)\n",
    "\n",
    "len(artists_usa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['As Living Arrows',\n",
       " 'Hidden Mothers',\n",
       " 'Tiny Moving Parts',\n",
       " 'Poppy',\n",
       " 'State Champs',\n",
       " 'Oso Oso',\n",
       " 'Better Lovers',\n",
       " 'Lowen',\n",
       " 'Halsey',\n",
       " 'Amyl and the Sniffers',\n",
       " 'Delta Sleep',\n",
       " 'High Vis',\n",
       " 'Cemetery Skyline',\n",
       " 'Goat',\n",
       " 'Chat Pile',\n",
       " 'Drug Church',\n",
       " 'Origami Angel',\n",
       " 'Heriot',\n",
       " 'Nightwish',\n",
       " 'Foxing',\n",
       " 'Alora Crucible',\n",
       " 'Wage War',\n",
       " 'TURQUOISEDEATH',\n",
       " 'Dawn Treader',\n",
       " 'Boston Manor',\n",
       " 'MJ Lenderman',\n",
       " 'Fat Dog',\n",
       " 'Kingcrow',\n",
       " 'Leprous',\n",
       " 'Wunderhorse',\n",
       " 'thrown',\n",
       " 'Horse Jumper of Love',\n",
       " 'Within the Ruins',\n",
       " 'Magdalena Bay',\n",
       " 'Fontaines D.C.',\n",
       " 'beabadoobee',\n",
       " 'State Faults',\n",
       " 'Graphic Nature',\n",
       " 'The Home Team',\n",
       " 'Speed',\n",
       " 'Remi Wolf',\n",
       " 'Clairo',\n",
       " 'Crippling Alcoholism',\n",
       " 'Cigarettes After Sex',\n",
       " 'Abriction',\n",
       " 'Pijn',\n",
       " 'Outlander',\n",
       " 'Imagine Dragons',\n",
       " 'The Dangerous Summer',\n",
       " 'Pond',\n",
       " 'Hyperdontia',\n",
       " 'Vredehammer',\n",
       " 'Pedro the Lion',\n",
       " 'Weston Super Maim',\n",
       " 'Stand Still',\n",
       " 'Mortal Wound',\n",
       " 'Eye of Solitude',\n",
       " 'Beth Gibbons',\n",
       " 'Contention',\n",
       " 'Knocked Loose',\n",
       " 'Mdou Moctar',\n",
       " 'The Lemon Twigs',\n",
       " 'Mk.Gee',\n",
       " 'Vennart',\n",
       " 'Microwave',\n",
       " 'Mastiff',\n",
       " 'Skycamefalling',\n",
       " 'SeeYouSpaceCowboy',\n",
       " 'Jamie Lenman',\n",
       " 'AVRALIZE',\n",
       " 'Imminence',\n",
       " 'Aaron West and The Roaring Twenties',\n",
       " 'Lo Moon',\n",
       " 'English Teacher',\n",
       " 'Engulfed',\n",
       " 'Khruangbin',\n",
       " 'Coffin Storm',\n",
       " 'Blanket',\n",
       " 'Boundaries',\n",
       " 'Adrianne Lenker',\n",
       " 'samlrc',\n",
       " 'Sticky Fingers',\n",
       " 'Bleachers',\n",
       " 'Stay Inside',\n",
       " 'Mannequin Pussy',\n",
       " 'Yard Act',\n",
       " 'Faye Webster',\n",
       " 'Little Kid',\n",
       " 'Job For A Cowboy',\n",
       " 'IDLES',\n",
       " 'Ihsahn',\n",
       " 'Laura Jane Grace',\n",
       " 'The Chisel',\n",
       " 'The Last Dinner Party',\n",
       " 'NewDad',\n",
       " 'Frank Carter and the Rattlesnakes',\n",
       " 'Tapir!',\n",
       " 'Neck Deep',\n",
       " 'Casey',\n",
       " 'Marika Hackman',\n",
       " 'Slift',\n",
       " 'Sprints',\n",
       " 'Killing Me Softly',\n",
       " 'Rannoch',\n",
       " 'Termina',\n",
       " 'Harp',\n",
       " 'Empty Country',\n",
       " 'Free Throw',\n",
       " 'Psychedelic Porn Crumpets',\n",
       " 'Dying Wish',\n",
       " 'END',\n",
       " 'Wargasm',\n",
       " 'Maria BC',\n",
       " 'Myrkur',\n",
       " 'Knuckle Puck',\n",
       " 'Creeper',\n",
       " 'Beartooth',\n",
       " 'Blood Command',\n",
       " 'Rorcal',\n",
       " 'Yeule',\n",
       " 'Slow Pulp',\n",
       " 'Dead and Dripping',\n",
       " 'Koyo',\n",
       " 'Shade Empire',\n",
       " 'TesseracT',\n",
       " 'Explosions in the Sky',\n",
       " 'Cursetheknife',\n",
       " 'Olivia Rodrigo',\n",
       " 'Uada',\n",
       " 'Pain of Truth',\n",
       " 'Reverence To Paroxysm',\n",
       " 'Royal Blood',\n",
       " 'Celestial Sanctuary',\n",
       " 'Empire State Bastard',\n",
       " 'Jeff Rosenstock',\n",
       " 'Spanish Love Songs',\n",
       " 'Urne',\n",
       " 'Movements',\n",
       " 'Caskets',\n",
       " 'Fiddlehead',\n",
       " 'Sunami',\n",
       " 'Teenage Wrist',\n",
       " 'Deitus',\n",
       " 'Mutoid Man',\n",
       " 'Voyager',\n",
       " 'Dawnwalker',\n",
       " 'PVRIS',\n",
       " 'Julie Byrne',\n",
       " 'Blindfolded and Led to the Woods',\n",
       " 'Nothing But Thieves',\n",
       " 'Grian Chatten',\n",
       " 'Model/Actriz',\n",
       " 'Burner',\n",
       " 'Death Goals',\n",
       " 'King Krule',\n",
       " 'feeble little horse',\n",
       " 'Noah Kahan',\n",
       " 'Squid',\n",
       " 'Tigercub',\n",
       " 'Pupil Slicer',\n",
       " 'Protomartyr',\n",
       " 'Phoxjaw',\n",
       " 'Bully',\n",
       " 'Wytch Hazel',\n",
       " 'Water From Your Eyes',\n",
       " 'Incendiary',\n",
       " 'bar italia',\n",
       " 'Sleep Token',\n",
       " 'Mandy, Indiana',\n",
       " 'Covet',\n",
       " 'The Amity Affliction',\n",
       " 'Veil of Maya',\n",
       " 'Currents',\n",
       " 'Crown the Empire',\n",
       " 'There Will Be Fireworks',\n",
       " 'Waterparks',\n",
       " 'Blondshell',\n",
       " 'HMLTD',\n",
       " 'deathcrash',\n",
       " 'Wednesday',\n",
       " 'Gel',\n",
       " 'Allfather',\n",
       " 'Bury Tomorrow',\n",
       " 'City and Colour',\n",
       " 'Boygenius',\n",
       " \"Dawn Ray'd\",\n",
       " 'BABYMETAL',\n",
       " 'Mork',\n",
       " 'Green Druid',\n",
       " 'M83',\n",
       " '100 Gecs',\n",
       " 'Periphery',\n",
       " 'Sleaford Mods',\n",
       " 'Acres',\n",
       " \"Can't Swim\",\n",
       " 'Pest Control',\n",
       " 'Host',\n",
       " 'U.S. Girls',\n",
       " 'Shame',\n",
       " 'Avatar',\n",
       " 'Hellripper',\n",
       " 'Avey Tare',\n",
       " 'A Wake in Providence',\n",
       " 'Pigs Pigs Pigs Pigs Pigs Pigs Pigs',\n",
       " 'Ihlo',\n",
       " 'Narrow Head',\n",
       " 'Emarosa',\n",
       " 'Molly',\n",
       " 'The Murder Capital',\n",
       " 'Margo Price',\n",
       " 'Weyes Blood',\n",
       " 'Turnover',\n",
       " 'Demon Hunter',\n",
       " \"Arm's Length\",\n",
       " 'Fit for a King',\n",
       " 'Dead Cross',\n",
       " 'Abduction',\n",
       " 'Brutus',\n",
       " 'Dry Cleaning',\n",
       " 'The 1975',\n",
       " 'Lacuna Coil',\n",
       " 'Gilla Band',\n",
       " 'Alvvays',\n",
       " 'Counterparts',\n",
       " 'Vacuous',\n",
       " 'Faceless Burial',\n",
       " 'Drowning Pool',\n",
       " 'Within Destruction',\n",
       " 'Miss May I',\n",
       " 'Escuela Grind',\n",
       " 'No Devotion',\n",
       " 'Holy Fawn',\n",
       " 'Courting',\n",
       " 'Tamino',\n",
       " 'Horsey',\n",
       " 'Inclination',\n",
       " 'Rina Sawayama',\n",
       " 'Electric Callboy',\n",
       " 'Camping In Alaska',\n",
       " 'Slaughterhouse',\n",
       " 'YUNGBLUD',\n",
       " 'Stella Donnelly',\n",
       " 'Julia Jacklin',\n",
       " 'Pale Waves',\n",
       " 'The Halo Effect',\n",
       " 'Sedimentum',\n",
       " 'Pool Kids',\n",
       " 'Ithaca',\n",
       " 'Dance Gavin Dance',\n",
       " 'Molder',\n",
       " 'Black Midi',\n",
       " 'Say Sue Me',\n",
       " 'Viagra Boys',\n",
       " 'Wormrot',\n",
       " 'Momma',\n",
       " 'Petrol Girls',\n",
       " 'Saor',\n",
       " 'Soccer Mommy',\n",
       " 'Sunrise Patriot Motion',\n",
       " 'Nova Twins',\n",
       " 'Ataraxy',\n",
       " 'Otoboke Beaver',\n",
       " 'Motionless In White',\n",
       " 'Corpsessed',\n",
       " 'Blood Youth',\n",
       " 'Horsegirl',\n",
       " 'Just Mustard',\n",
       " 'Malevolence',\n",
       " 'Harry Styles',\n",
       " 'Porridge Radio',\n",
       " 'Toad',\n",
       " 'Rolling Blackouts Coastal Fever',\n",
       " 'Bodysnatcher',\n",
       " 'Static Dress',\n",
       " 'Halestorm',\n",
       " 'Stand Atlantic',\n",
       " 'Proper.',\n",
       " 'Black Sheep Wall',\n",
       " 'Hatchie',\n",
       " 'Prince Daddy and The Hyena',\n",
       " 'Undeath',\n",
       " 'Epitaphe',\n",
       " 'Envy of None',\n",
       " 'Helpless',\n",
       " 'Wet Leg',\n",
       " 'PUP',\n",
       " 'Camp Cope',\n",
       " 'Ditz',\n",
       " 'Aldous Harding',\n",
       " 'Indian Summer',\n",
       " 'Machine Gun Kelly',\n",
       " 'Animals As Leaders',\n",
       " 'Yumi Zouma',\n",
       " 'Twelve Foot Ninja',\n",
       " 'Belmont',\n",
       " 'Messa',\n",
       " 'Chalk Hands',\n",
       " 'Ghost',\n",
       " 'Cryptworm',\n",
       " 'Mountaineer',\n",
       " 'Ecchymosis',\n",
       " 'Bloodywood',\n",
       " 'Sasami',\n",
       " 'Avril Lavigne',\n",
       " 'Mom Jeans.',\n",
       " 'Caroline',\n",
       " 'Scorpions',\n",
       " 'Evergreen',\n",
       " 'Sea Power',\n",
       " 'Big Thief',\n",
       " 'As It Is',\n",
       " 'Grivo',\n",
       " 'Mitski',\n",
       " 'Pinegrove',\n",
       " 'Black Country, New Road',\n",
       " 'Bad Omens',\n",
       " 'Voices',\n",
       " 'Comeback Kid',\n",
       " 'Shadow Of Intent',\n",
       " 'Vertebra Atlantis',\n",
       " 'Slow Crush',\n",
       " 'Unfurl',\n",
       " 'Geese',\n",
       " 'Papangu',\n",
       " 'Damon Albarn',\n",
       " 'Sermon of Flames',\n",
       " 'Springtime',\n",
       " 'Snail Mail',\n",
       " 'Emma Ruth Rundle',\n",
       " 'Courtney Barnett',\n",
       " 'Black Veil Brides',\n",
       " 'Frontierer',\n",
       " 'Monolord',\n",
       " 'Sulphurous',\n",
       " 'Black Marble',\n",
       " 'Ice Nine Kills',\n",
       " 'I Feel Fine',\n",
       " 'Sugar Horse',\n",
       " 'Dean Blunt',\n",
       " 'Sam Fender',\n",
       " \"KK's Priest\",\n",
       " 'Full of Hell',\n",
       " 'Tremonti',\n",
       " 'LLNN',\n",
       " 'Spiritbox',\n",
       " 'Aborted',\n",
       " 'Kacey Musgraves',\n",
       " 'Trna',\n",
       " 'Slaughter To Prevail',\n",
       " 'sonhos tomam conta',\n",
       " 'Bossk',\n",
       " 'Indigo De Souza',\n",
       " 'Deafheaven',\n",
       " 'Wolves in the Throne Room',\n",
       " 'Qrixkuor',\n",
       " 'Trash Boat',\n",
       " 'Galvanizer',\n",
       " 'Yola',\n",
       " 'Torres',\n",
       " 'LUMP',\n",
       " 'The Maine',\n",
       " 'Ophidian I',\n",
       " 'Diabolizer',\n",
       " 'Descendents',\n",
       " 'Lightning Bug',\n",
       " 'Atvm',\n",
       " 'Project 86',\n",
       " 'Lovesliescrushing',\n",
       " 'Hacktivist',\n",
       " 'Lucy Dacus',\n",
       " 'Portal',\n",
       " 'Ceremonium',\n",
       " 'Nexilva',\n",
       " 'Fear Factory',\n",
       " 'Morbific',\n",
       " 'Marina',\n",
       " 'Our Hollow, Our Home',\n",
       " 'Wolf Alice',\n",
       " 'Tilian',\n",
       " 'Bachelor',\n",
       " 'Noctule',\n",
       " 'Japanese Breakfast',\n",
       " 'Home Is Where',\n",
       " 'Manchester Orchestra',\n",
       " 'The Raging Nathans',\n",
       " 'Holding Absence',\n",
       " 'Flock of Dimes',\n",
       " \"'68\",\n",
       " 'Genghis Tron',\n",
       " 'Ominous Ruin',\n",
       " 'Cassandra Jenkins',\n",
       " 'Julien Baker',\n",
       " 'Love and Death',\n",
       " 'Defacement',\n",
       " 'Divide And Dissolve',\n",
       " 'TV Priest',\n",
       " 'Lamp of Murmuur',\n",
       " 'Goat Girl',\n",
       " 'Soen',\n",
       " 'Accept',\n",
       " 'Pom Poko',\n",
       " 'The Casket Lottery',\n",
       " 'Parquet Courts',\n",
       " 'Pearl Charles',\n",
       " 'Respire',\n",
       " 'Teenage Mutant Ninja Turtles',\n",
       " 'Dominic Fike',\n",
       " 'Undergang',\n",
       " 'Edenic Past',\n",
       " 'Red City Radio',\n",
       " 'Palm Reader',\n",
       " 'Bearings',\n",
       " 'Seahaven',\n",
       " 'Black Foxxes',\n",
       " 'Scalp',\n",
       " 'The Menzingers',\n",
       " 'Kingdom of Giants',\n",
       " 'Guitar Fight from Fooly Cooly',\n",
       " 'Miasmatic Necrosis',\n",
       " 'Black Stone Cherry',\n",
       " 'Nothing',\n",
       " 'The Fall of Troy',\n",
       " 'Matt Berninger',\n",
       " 'Gorephilia',\n",
       " 'Joji',\n",
       " 'Corey Taylor',\n",
       " 'Fires in the Distance',\n",
       " 'Obsidian Kingdom',\n",
       " 'Svalbard',\n",
       " 'The Ocean',\n",
       " 'Into It. Over It.',\n",
       " 'Fawn Limbs',\n",
       " 'Vous Autres',\n",
       " 'Carnation',\n",
       " 'Special Interest',\n",
       " 'Declan McKenna',\n",
       " 'Xazraug',\n",
       " 'Necrot',\n",
       " 'Angel Olsen',\n",
       " \"Luna's Call\",\n",
       " 'No Joy',\n",
       " 'Pharmacist',\n",
       " 'Duma',\n",
       " 'Misery Signals',\n",
       " 'Slightly Stoopid',\n",
       " 'Aseitas',\n",
       " 'Paara',\n",
       " 'Greg Puciato',\n",
       " 'The Beths',\n",
       " 'Nation of Language',\n",
       " 'Grey Daze',\n",
       " 'Carach Angren',\n",
       " 'Melt Yourself Down',\n",
       " 'Pottery',\n",
       " 'Sault',\n",
       " 'Calligram',\n",
       " 'Phoebe Bridgers',\n",
       " 'Owen',\n",
       " 'Justice For The Damned',\n",
       " 'Make Them Suffer',\n",
       " 'Westerman',\n",
       " 'Sports Team',\n",
       " 'Muzz',\n",
       " 'Palaye Royale',\n",
       " \"Caligula's Horse\",\n",
       " 'Infant Island',\n",
       " 'VVilderness',\n",
       " 'Car Seat Headrest',\n",
       " 'Elephant Tree',\n",
       " 'Molested Divinity',\n",
       " 'Ellis',\n",
       " 'Kontinuum',\n",
       " 'Yves Tumor',\n",
       " 'Telepathy',\n",
       " '5 Seconds of Summer',\n",
       " 'Brian Fallon',\n",
       " 'Sorry',\n",
       " 'The Chats',\n",
       " 'Malokarpatan',\n",
       " 'Afterbirth',\n",
       " 'Temple of Void',\n",
       " 'Hot Mulligan',\n",
       " 'Horse Lords',\n",
       " 'The Districts',\n",
       " 'Monsters',\n",
       " 'Greg Dulli',\n",
       " 'Panchiko',\n",
       " 'Bambara',\n",
       " 'Giver',\n",
       " 'Loathe',\n",
       " 'Shopping',\n",
       " 'Leeched',\n",
       " 'Lowrider',\n",
       " 'Lovebites',\n",
       " 'Vengeful Spectre',\n",
       " 'Higher Power',\n",
       " 'Slick Shoes',\n",
       " 'Wolf Parade',\n",
       " 'Mura Masa',\n",
       " 'Garganjua',\n",
       " 'Algiers',\n",
       " 'Vomit the Soul',\n",
       " 'The Last Ten Seconds Of Life',\n",
       " 'Blood Incantation',\n",
       " 'Dream State',\n",
       " 'Stray from the Path',\n",
       " 'Rex Orange County',\n",
       " 'Sadisme',\n",
       " 'Patrick Watson',\n",
       " 'Common Holly',\n",
       " 'Car Bomb',\n",
       " 'We Lost the Sea',\n",
       " 'Surf Curse',\n",
       " 'Issues',\n",
       " 'Kim Gordon',\n",
       " 'Alarmist',\n",
       " 'Dayseeker',\n",
       " 'Renounced',\n",
       " 'Post Malone',\n",
       " 'Klone',\n",
       " 'Void of Vision',\n",
       " 'The Agonist',\n",
       " 'Liam Gallagher',\n",
       " 'The Hu',\n",
       " 'Grayscale',\n",
       " 'Chris Farren',\n",
       " 'The Odious',\n",
       " 'Sleeping With Sirens',\n",
       " 'Nocturnal Departure',\n",
       " 'Whitney',\n",
       " 'Jay Som',\n",
       " 'Tropical Fuck Storm',\n",
       " 'King Gizzard and The Lizard Wizard',\n",
       " 'Blanck Mass',\n",
       " 'Richard Henshall',\n",
       " 'Rosalie Cunningham',\n",
       " 'Slaughter Beach, Dog',\n",
       " 'iamthemorning',\n",
       " 'Iniquitous Deeds',\n",
       " 'Throes',\n",
       " 'Abbath',\n",
       " 'Ossuary',\n",
       " 'Shirokuma',\n",
       " 'Puppy',\n",
       " 'Bill Callahan',\n",
       " 'CHON',\n",
       " 'Vanishing Twin',\n",
       " 'Frank Iero and The Future Violents',\n",
       " 'Novo Amor',\n",
       " 'Death Angel',\n",
       " 'Cate Le Bon',\n",
       " 'Plastic Mermaids',\n",
       " 'Black Mountain',\n",
       " 'Alex Lahey',\n",
       " 'Lewis Capaldi',\n",
       " 'Holding Patterns',\n",
       " 'Forests',\n",
       " 'We Never Learned To Live',\n",
       " 'Shin Guard',\n",
       " 'Town Portal',\n",
       " 'Trade Wind',\n",
       " 'Kevin Morby',\n",
       " 'Nucleus',\n",
       " 'Wand',\n",
       " 'Clowns',\n",
       " 'The Raven Age',\n",
       " 'Ceremony Of Silence',\n",
       " 'The Dismemberment Plan',\n",
       " 'CHAI',\n",
       " 'Orville Peck',\n",
       " 'Akasha',\n",
       " 'Venom Prison',\n",
       " 'Oozing Wound',\n",
       " 'Baalsebub',\n",
       " 'Tim Bowness',\n",
       " 'Mammoth Weed Wizard Bastard',\n",
       " 'Hozier',\n",
       " 'Teeth Of The Sea',\n",
       " 'Badflower',\n",
       " 'Drenge',\n",
       " 'Astronauts',\n",
       " 'Homeshake',\n",
       " 'Green Lung',\n",
       " 'Set It Off',\n",
       " 'Minors',\n",
       " 'King 810',\n",
       " 'Mystifier',\n",
       " 'Jade Bird',\n",
       " 'Press Club',\n",
       " 'Mono',\n",
       " 'Palisades',\n",
       " 'Tallies',\n",
       " 'Deuce',\n",
       " 'Napoleon',\n",
       " 'Normandie',\n",
       " 'XXXTENTACION',\n",
       " 'Ex:Re',\n",
       " 'Bliss Signal',\n",
       " 'Portrayal of Guilt',\n",
       " 'The Good, The Bad and The Queen',\n",
       " 'Toska',\n",
       " 'Tenacious D',\n",
       " 'Hippo Campus',\n",
       " 'Mass of the Fermenting Dregs',\n",
       " 'The Struts',\n",
       " 'Frog',\n",
       " 'The Dirty Nil',\n",
       " 'Polyphia',\n",
       " 'Hands Like Houses',\n",
       " 'Tom Morello',\n",
       " 'Pagan',\n",
       " 'Black Peaks',\n",
       " 'Kero Kero Bonito',\n",
       " 'Monuments',\n",
       " 'Exit North',\n",
       " 'Against The Current',\n",
       " 'Windhand',\n",
       " 'All Them Witches',\n",
       " 'Head with Wings',\n",
       " 'Wstr',\n",
       " 'Imperial Triumphant',\n",
       " 'The Skull',\n",
       " 'Gia Margaret',\n",
       " 'Trophy Eyes',\n",
       " 'Regal Worm',\n",
       " 'Talons',\n",
       " 'Like Pacific',\n",
       " 'The Antichrist Imperium',\n",
       " 'Mouse On The Keys',\n",
       " 'Burial Invocation',\n",
       " 'Morrow',\n",
       " 'The Interrupters',\n",
       " 'Panic! at the Disco',\n",
       " 'Mark Kozelek',\n",
       " 'Church of the Cosmic Skull',\n",
       " 'Zeal and Ardor',\n",
       " 'Jonathan Davis',\n",
       " 'Tancred',\n",
       " 'Lunatic Soul',\n",
       " 'Flasher',\n",
       " 'Graveyard',\n",
       " 'Keiji Haino',\n",
       " 'Body Void',\n",
       " 'Middle Kids',\n",
       " 'Pinkshinyultrablast',\n",
       " 'Forth Wanderers',\n",
       " 'Sectioned',\n",
       " 'Speedy Ortiz',\n",
       " 'Cassus',\n",
       " 'Boss Keloid',\n",
       " 'Tangled Hair',\n",
       " 'Ruins',\n",
       " 'Mastersystem',\n",
       " 'Rainbow Kitten Surprise',\n",
       " 'Autokrator',\n",
       " 'Night Flowers',\n",
       " 'Hinds',\n",
       " 'Sunflower Bean',\n",
       " 'Nervus',\n",
       " 'George Ezra',\n",
       " 'King Goat',\n",
       " 'Dead!',\n",
       " 'Moose Blood',\n",
       " \"Ed Schrader's Music Beat\",\n",
       " 'Gleb Kolyadin',\n",
       " 'Slugdge',\n",
       " 'Conjurer',\n",
       " 'Vundabar',\n",
       " 'Dvne',\n",
       " 'S. Carey',\n",
       " 'Pianos Become the Teeth',\n",
       " 'Band-Maid',\n",
       " 'Legend of the Seagullmen',\n",
       " 'Crywank',\n",
       " 'The Plot In You',\n",
       " 'Loma',\n",
       " 'Ezra Furman',\n",
       " 'Son Lux',\n",
       " 'Alpha Male Tea Party',\n",
       " 'Palm',\n",
       " 'Philip H. Anselmo and The Illegals',\n",
       " 'Marmozets',\n",
       " 'Somali Yacht Club',\n",
       " 'Anna Burch',\n",
       " 'Dream Wife',\n",
       " 'Thousand Below',\n",
       " 'Of Mice and Men',\n",
       " \"Leaves' Eyes\",\n",
       " 'Embodyment',\n",
       " 'Five Iron Frenzy',\n",
       " 'Yellow Days',\n",
       " 'Death Toll 80k',\n",
       " 'Sacred Son',\n",
       " 'Peach Pit',\n",
       " 'Beast In Black',\n",
       " 'ROAM',\n",
       " 'Turnpike Troubadours',\n",
       " 'Ibeyi',\n",
       " 'Grave Pleasures',\n",
       " 'IDYLLS',\n",
       " 'With the Dead',\n",
       " 'Nothing More',\n",
       " 'Prawn',\n",
       " 'Seaway',\n",
       " 'Ariel Pink',\n",
       " 'Rostam',\n",
       " 'The Contortionist',\n",
       " 'Prophets of Rage',\n",
       " 'White Moth Black Butterfly',\n",
       " 'Hammock',\n",
       " 'Hungry Ghosts',\n",
       " 'Thy Art Is Murder',\n",
       " 'ostraca',\n",
       " 'Kesha',\n",
       " 'Horrified',\n",
       " 'Agents of Oblivion',\n",
       " 'Sheer Mag',\n",
       " 'Silverstein',\n",
       " 'HAIM',\n",
       " 'Public Service Broadcasting',\n",
       " 'Spaceslug',\n",
       " 'Floating Points',\n",
       " 'Ex Eye',\n",
       " 'Hey Violet',\n",
       " 'Single Mothers',\n",
       " 'Wode',\n",
       " 'Flogging Molly',\n",
       " 'Tricot',\n",
       " 'Pumarosa',\n",
       " 'Employed To Serve',\n",
       " 'Gnarwolves',\n",
       " 'Woods',\n",
       " 'PWR BTTM',\n",
       " 'i hate sex',\n",
       " 'Spotlights',\n",
       " 'Sundara Karma',\n",
       " 'Hoops',\n",
       " 'The Physics House Band',\n",
       " 'Artificial Brain',\n",
       " 'Falling in Reverse',\n",
       " 'Jeromes Dream',\n",
       " 'Richard Cheese',\n",
       " 'Michelle Branch',\n",
       " 'Timber Timbre',\n",
       " 'I Declare War',\n",
       " 'Chinese Football',\n",
       " 'The Smith Street Band',\n",
       " 'Phrenelith',\n",
       " 'Hurray For The Riff Raff',\n",
       " 'Circa Waves',\n",
       " 'Temples',\n",
       " 'Raspberry Bulbs',\n",
       " 'Crystal Fairy',\n",
       " 'Vagabon',\n",
       " 'Peter Silberman',\n",
       " 'Meat Wave',\n",
       " 'The Orwells',\n",
       " 'Andrew McMahon in the Wilderness',\n",
       " 'Starset',\n",
       " 'Mark Eitzel',\n",
       " 'Foxygen',\n",
       " 'The Mayfield Four',\n",
       " 'Tycho',\n",
       " 'Youth Funeral',\n",
       " '40 Watt Sun',\n",
       " 'Attila',\n",
       " 'You Blew It!',\n",
       " 'Voices from the Fuselage',\n",
       " 'Earth Moves',\n",
       " 'D.D Dumbo',\n",
       " 'Lewis Del Mar',\n",
       " 'From Ashes To New',\n",
       " 'Shawn Mendes',\n",
       " 'Airbourne',\n",
       " 'Merchandise',\n",
       " 'Beach Slang',\n",
       " 'Newsboys',\n",
       " 'Preoccupations',\n",
       " 'Okkervil River',\n",
       " 'Dope Lemon',\n",
       " 'Mild High Club',\n",
       " 'David Brent',\n",
       " 'Abhorrent Decimation',\n",
       " 'Bayside',\n",
       " 'SWMRS',\n",
       " 'Gouge Away',\n",
       " 'Young the Giant',\n",
       " 'Monarch',\n",
       " 'Coldrain',\n",
       " \"Bear's Den\",\n",
       " 'Despised Icon',\n",
       " 'Omni',\n",
       " 'McCafferty',\n",
       " 'Dikembe',\n",
       " 'Nonpoint',\n",
       " 'The Avalanches',\n",
       " 'Big Business',\n",
       " 'Martha',\n",
       " 'Fates Warning',\n",
       " 'Lonely the Brave',\n",
       " 'British Theatre',\n",
       " 'Thousand Foot Krutch',\n",
       " 'Art Of Dying',\n",
       " 'With Confidence',\n",
       " 'Jake Bugg',\n",
       " 'The Hotelier',\n",
       " 'Rival Sons',\n",
       " 'The Claypool Lennon Delirium',\n",
       " 'Wicked Innocence',\n",
       " 'Minor Victories',\n",
       " 'Fear of Men',\n",
       " 'Real Friends',\n",
       " 'Catfish and the Bottlemen',\n",
       " 'Pantha Du Prince',\n",
       " 'Crystal Lake',\n",
       " 'Kikagaku Moyo',\n",
       " 'Schammasch',\n",
       " 'Twin Peaks',\n",
       " 'Destruction',\n",
       " 'Eagulls',\n",
       " 'RY X',\n",
       " 'LUH',\n",
       " 'ANOHNI',\n",
       " 'Messenger',\n",
       " 'Annisokay',\n",
       " 'Dowsing',\n",
       " 'Crooks',\n",
       " 'Dehumanized',\n",
       " 'Moonlit Sailor',\n",
       " 'The Comet Is Coming',\n",
       " 'Radical Face',\n",
       " 'King Buffalo',\n",
       " 'The Drones',\n",
       " 'Plague Vendor',\n",
       " 'Richmond Fontaine',\n",
       " 'Sarah Neufeld',\n",
       " 'Heck',\n",
       " 'Wormed',\n",
       " 'ee',\n",
       " 'Guerilla Toss',\n",
       " 'Big Ups',\n",
       " 'Mothers',\n",
       " 'Cindy Lee',\n",
       " 'The Neighbourhood',\n",
       " 'Porches',\n",
       " 'Money',\n",
       " 'Nevermen',\n",
       " 'Savages',\n",
       " 'Intervals',\n",
       " 'Fit for an Autopsy',\n",
       " 'Violet Cold',\n",
       " 'Sam Hunt',\n",
       " 'Nokturnel',\n",
       " 'Good Tiger',\n",
       " 'Sexwitch',\n",
       " 'EL VY',\n",
       " 'Love Lost But Not Forgotten',\n",
       " 'Half Moon Run',\n",
       " 'Shining',\n",
       " 'Marietta',\n",
       " 'Dilly Dally',\n",
       " 'One Ok Rock',\n",
       " 'Cruciamentum',\n",
       " 'Kylesa',\n",
       " 'Caspian',\n",
       " 'Agent Fresco',\n",
       " 'P.O.D.',\n",
       " 'X Ambassadors',\n",
       " 'Hills',\n",
       " 'Soilwork',\n",
       " 'Heartist',\n",
       " 'The Sword',\n",
       " 'Royal Headache',\n",
       " 'Highly Suspect',\n",
       " 'Kings Kaleidoscope',\n",
       " 'Archivist',\n",
       " 'Jason Isbell',\n",
       " 'Dan Andriano in the Emergency Room',\n",
       " 'Years and Years',\n",
       " 'Ethereal Shroud',\n",
       " 'God Damn',\n",
       " 'August Burns Red',\n",
       " 'Human Hands',\n",
       " 'Iwrestledabearonce',\n",
       " 'Mutiny On The Bounty',\n",
       " 'Mylets',\n",
       " 'Lucifer',\n",
       " 'Zella Day',\n",
       " 'FFS',\n",
       " 'Jaga Jazzist',\n",
       " 'Girlpool',\n",
       " 'Pet Symmetry',\n",
       " 'Charlie Simpson',\n",
       " 'Johnny Rebel',\n",
       " 'Surfer Blood',\n",
       " 'Murmur',\n",
       " 'We Are Harlot',\n",
       " 'Nai Harvest',\n",
       " 'Ghost Bath',\n",
       " 'Alabama Shakes',\n",
       " 'Bio-Cancer',\n",
       " 'Neon Trees',\n",
       " 'Say Lou Lou',\n",
       " 'Until The Ribbon Breaks',\n",
       " 'Shizune',\n",
       " 'Lower Dens',\n",
       " 'Ryley Walker',\n",
       " 'James Bay',\n",
       " 'AWOLNATION',\n",
       " 'Ranger',\n",
       " 'Trepalium',\n",
       " 'Houndmouth',\n",
       " 'The Sidekicks',\n",
       " 'Pile',\n",
       " 'Ghostpoet',\n",
       " 'A Textbook Tragedy',\n",
       " 'Colleen Green',\n",
       " 'Butch Walker',\n",
       " 'xRepentancex',\n",
       " 'Peace',\n",
       " 'The Arrogant Sons of Bitches',\n",
       " 'Jessica Pratt',\n",
       " 'This Is A Standoff',\n",
       " 'Planet X',\n",
       " 'Kodaline',\n",
       " 'FACT',\n",
       " 'Abstracter',\n",
       " 'California X',\n",
       " 'Cloakroom',\n",
       " 'Swallowed',\n",
       " 'Charli XCX',\n",
       " 'Clouds',\n",
       " 'TrenchRot',\n",
       " 'Forever Came Calling',\n",
       " 'The Ghost Inside',\n",
       " 'Youngblood Hawke',\n",
       " 'No Bragging Rights',\n",
       " 'Disembarked',\n",
       " 'The Jazz June',\n",
       " 'Wildbirds and Peacedrums',\n",
       " 'Crobot',\n",
       " 'Miroist',\n",
       " 'Climates',\n",
       " 'Tweedy',\n",
       " 'Adult Jazz',\n",
       " 'Benjamin Booker',\n",
       " 'My Brightest Diamond',\n",
       " 'The Hell',\n",
       " 'The Wytches',\n",
       " 'Lay Down Rotten',\n",
       " 'Owl John',\n",
       " 'The Algorithm',\n",
       " 'The Flex',\n",
       " 'Bear Hands',\n",
       " 'Totem Skin',\n",
       " 'Breathe Carolina',\n",
       " 'Braid',\n",
       " 'Total Control',\n",
       " 'Glass Animals',\n",
       " 'White Lung',\n",
       " 'Dreamshade',\n",
       " 'Tombs',\n",
       " 'Harry Pussy',\n",
       " 'Vales',\n",
       " 'Archspire',\n",
       " 'Sickening Gore',\n",
       " 'Mars Red Sky',\n",
       " 'Lewis',\n",
       " 'Sorority Noise',\n",
       " 'Echosmith',\n",
       " 'Brody Dalle',\n",
       " 'Circles',\n",
       " 'Ian Anderson',\n",
       " 'The Mire',\n",
       " \"Avey Tare's Slasher Flicks\",\n",
       " 'Chuck Ragan',\n",
       " 'Scar the Martyr',\n",
       " 'Owls',\n",
       " 'Collide',\n",
       " 'Laibach',\n",
       " 'Tony Molina',\n",
       " 'Adrenaline Mob',\n",
       " 'I See Stars',\n",
       " 'Pan.Thy.Monium',\n",
       " 'Above and Beyond',\n",
       " 'Cheatahs',\n",
       " 'Sahg',\n",
       " 'Harvey Danger',\n",
       " 'Mutual Benefit',\n",
       " 'Marvelous 3',\n",
       " 'Pestilence',\n",
       " 'Beastmilk',\n",
       " 'Hell',\n",
       " 'Steve Von Till',\n",
       " 'Laughing Hyenas',\n",
       " 'Yamantaka // Sonic Titan',\n",
       " 'Sky Ferreira',\n",
       " 'Kind of Like Spitting',\n",
       " 'the GazettE',\n",
       " 'San Fermin',\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists_usa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4249"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I have to import this df for the function to properly work\n",
    "df = pd.read_csv('Datasets/df_blend_ratings.csv')\n",
    "artists = df['artist'].unique()\n",
    "len(artists)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'As Living Arrows'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3423"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.index[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3419</th>\n",
       "      <td>Cinderella</td>\n",
       "      <td>Philadelphia, Pennsylvania, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3420</th>\n",
       "      <td>Death From Above 1979</td>\n",
       "      <td>Toronto, Ontario, Canada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3421</th>\n",
       "      <td>Chicago</td>\n",
       "      <td>Chicago, Illinois, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3422</th>\n",
       "      <td>The Nation of Ulysses</td>\n",
       "      <td>Washington, D.C.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3423</th>\n",
       "      <td>Strung Out</td>\n",
       "      <td>Simi Valley, California, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     artist                            origin\n",
       "3419             Cinderella  Philadelphia, Pennsylvania, U.S.\n",
       "3420  Death From Above 1979          Toronto, Ontario, Canada\n",
       "3421                Chicago  Chicago, Illinois, United States\n",
       "3422  The Nation of Ulysses                  Washington, D.C.\n",
       "3423             Strung Out     Simi Valley, California, U.S."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([2772], dtype=int64),)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(artists=='July Talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'July Talk'"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artists[2772]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Code to execute the functions from ``geopy_functions.py``**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_to_remove = ['Cemetery Skyline', 'Goat', 'Kingcrow', 'Speed', 'Hyperdontia', 'Vredehammer', 'Weston Super Maim',\n",
    "                'Mdou Moctar', 'AVRALIZE', 'Engulfed', 'Coffin Storm', 'samlrc', 'Little Kid', 'Termina', 'Rorcal',\n",
    "                'Reverence To Paroxysm', 'Voyager', 'Blindfolded and Led to the Woods', 'Mork', 'Yeule', 'Pond',\n",
    "                'Empire State Bastard', 'Blood Command', 'Avatar', 'Brutus', 'Faceless Burial', 'Within Destruction',\n",
    "                'Sedimentum', 'Ataraxy', 'Corpsessed', 'Epitaphe', 'Aldous Harding', 'Messa', 'Ghost', 'Ecchymosis',\n",
    "                'Wormrot', 'Vertebra Atlantis', 'Papangu', 'Sermon of Flames', 'Springtime', 'Monolord', 'Sulphurous',\n",
    "                'LLNN', 'Trna', 'Slaughter To Prevail', 'sonhos tomam conta', 'Galvanizer', 'Ophidian I', 'Diabolizer',\n",
    "                'Morbific', 'Defacement', 'Divide And Dissolve', 'Soen', 'Scorpions', 'Accept', 'Respire', 'Undergang',\n",
    "                'Bearings', 'Scalp', 'Miasmatic Necrosis', 'Teenage Mutant Ninja Turtles', 'Gorephilia', 'Vous Autres',\n",
    "                'Carnation', 'Pharmacist', 'Paara', \"Justice For The Damned\", 'VVilderness', 'Molested Divinity', 'Ellis',\n",
    "                'Kontinuum', 'Monsters', 'Giver', 'Lowrider', 'Vengeful Spectre', 'Vomit the Soul', 'Sadisme', 'Alarmist',\n",
    "                'Klone', 'Nocturnal Departure', 'King Gizzard and The Lizard Wizard', 'Make Them Suffer', 'The Chats',\n",
    "                'Patrick Watson', 'Shirokuma', 'Forests', 'Town Portal', 'Ceremony Of Silence', 'CHAI', 'Baalsebub',\n",
    "                'Minors', 'Mono', 'Tallies', 'Normandie', 'Mouse On The Keys', 'Burial Invocation', 'Orville Peck',\n",
    "                'Lunatic Soul', 'Alex Lahey', 'Hozier', 'Mystifier', 'Hands Like Houses', 'Ruins', 'Autokrator',\n",
    "                'Legend of the Seagullmen', 'Death Toll 80k', 'IDYLLS', 'Spaceslug', 'i hate sex', 'Band-Maid',\n",
    "                'With the Dead', 'Hungry Ghosts', 'Middle Kids', 'Gleb Kolyadin', \"Leaves' Eyes\", \"Phrenelith\",\n",
    "                \"David Brent\", \"Art Of Dying\", \"Minor Victories\", \"Pantha Du Prince\", \"Schammasch\", 'LUH',\n",
    "                'Violet Cold', 'EL VY', 'Shining', 'Hills', \"Mutiny On The Bounty\", 'Lucifer', 'FFS', 'Ranger',\n",
    "                'Trepalium', 'A Textbook Tragedy', 'This Is A Standoff', 'FACT', 'Swallowed', 'Disembarked',\n",
    "                'Wildbirds and Peacedrums', 'Archivist', 'Timber Timbre', 'Newsboys', 'Dope Lemon', 'Vagabon',\n",
    "                'RY X', 'Moonlit Sailor', 'The Drones', 'Sarah Neufeld', 'Say Lou Lou', 'Cruciamentum', 'Lay Down Rotten',\n",
    "                'Dreamshade', 'Sickening Gore', 'Circles', \"Avey Tare's Slasher Flicks\", 'Forest Silence',\n",
    "                \"One Eyed God Prophecy\", 'Coffins', 'Osamu Kitajima', 'Living With Lions', 'Ansur', 'Parades',\n",
    "                \"Intestine Baalism\", 'Comity', 'No Omega', 'Wolverine', 'Disavowed', 'Angel Dust', \"!T.O.O.H.!\",\n",
    "                'Hypnosia', 'Hexenhaus', 'Paradox', 'Deathrow', 'Excruciate', 'FareWell Poetry', 'Sights and Sounds',\n",
    "                'Supersister', \"Birds Of Tokyo\", 'Ark', \"The Flower Kings\", 'Beardfish', 'Graveworm', 'Acid',\n",
    "                'Ladyhawke', 'Geddy Lee', 'Yngwie Malmsteen', \"World's End Girlfriend\", 'Totem Skin', 'Lewis',\n",
    "                'I Hate Sally', \"The Band\", 'Lisa Hannigan', 'Lethal', 'Bubu', 'Van She', 'Mooncake', 'The Haunted',\n",
    "                \"Orphaned Land\", 'Madder Mortem', 'Kataxu', 'Gilberto Gil', 'Vendetta', 'Kvist', 'Acrostichon', 'Pain',\n",
    "                'Obliteration', 'Flames of Hell', 'Wombbath', 'Stone', 'Disgrace', 'Fionn Regan', 'Disastrous Murmur',\n",
    "                'Urfaust', 'Sleepingdog', 'Island', 'Bethlehem', 'Subterranean Masquerade', 'After Dinner', \n",
    "                'Black Boned Angel', 'FM', 'Embrace', 'Solefald', 'Maneige', 'Amberian Dawn', 'OOIOO', 'Anekdoten',\n",
    "                \"Aphrodite's Child\", 'Hollenthon', 'Lykke Li', 'Lenka', 'Sarah McLachlan', 'Owen Pallett',\n",
    "                'Devin Townsend Project', 'Missy Higgins', 'The Devin Townsend Band', 'Selda', 'Massacra', \"Rory Gallagher\",\n",
    "                'Taste', 'Celestial Season', 'Ida Maria', 'Dark Tranquillity', 'Cadaver', 'Pele', 'Exuma',\n",
    "                'Great Lake Swimmers', 'Dawn', 'The Bats', 'Yoko Ono', 'Illogicist', 'The Saints', 'Final Fantasy',\n",
    "                'Pendulum', 'Lunar Aurora', 'Bee Gees', 'Stars', \"David Sylvian and Robert Fripp\", 'Afflicted', 'Lengsel',\n",
    "                'Extol', 'MDFMK', 'Univers Zero', 'Mortuary Drape', 'Zyklon', 'Winds', 'Zyklon-B', 'The Sins of Thy Beloved',\n",
    "                'Lords of Acid', 'Devin Townsend', 'Diablo Swing Orchestra', 'Arcturus', 'Cornelius', 'Manu Chao',\n",
    "                'Bryan Adams', 'Peaches', 'Doro', 'Kingdom Come', 'Pekka Pohjola', 'Shakira', 'Massacre', 'Subhumans',\n",
    "                'Set Fire to Flames', 'Gorgoroth', 'Gandalf', 'Klaus Schulze', 'The Ecstasy of Saint Theresa',\n",
    "                \"Lou Reed and John Cale\", 'Brian Eno and David Byrne', 'Bob Dylan and The Band', 'Era', 'Devil Doll',\n",
    "                'Cauterize', 'Roadrunner United', 'Circus Maximus', 'Crowpath', 'Raunchy', 'Tad Morose', 'Kenna',\n",
    "                'Head Control System', 'Torchbearer', 'Rosesdead', 'Angtoria', 'Nightrage', 'Necros Christos', 'Hypnos 69',\n",
    "                'Wold', 'Andromeda', 'Chad VanGaalen', 'Melechesh', 'Spheric Universe Experience', 'Anubis Gate',\n",
    "                'The Project Hate MCMXCIX', 'Myrath', 'Savage Circus', 'Hartfield', 'Evereve', 'Daturah', 'Ad Infinitum',\n",
    "                'Tash Sultana', 'Tarja Turunen', 'Ram-Zet', 'Sweven', 'Arcane', 'Sons of Apollo', 'Celesty', 'Brainstorm',\n",
    "                'Unleash The Archers', 'Prostitute Disfigurement', 'The Psyke Project', 'Dornenreich', 'Watain', 'Funeral',\n",
    "                'Cultes Des Ghoules', 'Revolting', 'Igorrr', 'Symfonia', 'Darkestrah', 'Sarah Blasko', 'Fractal Universe',\n",
    "                'The End', 'Apotheosis', 'Drautran', 'Monolithe', 'CrazyEightyEight', 'Black Hole', 'Polaris', 'Nug',\n",
    "                'Klabautamann', 'James LaBrie', 'Vance Joy', 'Helena Deland', 'Authorize', 'Blazon Stone', 'Rapture',\n",
    "                'Worship', 'Conqueror', 'Swan Lake', 'Yyrkoon', 'Inquisition', 'Kerli', 'Keldian', 'Wake', 'Megiddo',\n",
    "                'Juanes', 'William Hung', 'Votum', 'Atramentus', 'Abysmal Torment', 'Paul Dempsey']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1328"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_us_new_masters_clean = pd.read_csv('Datasets/df_us_new_masters_clean.csv')\n",
    "unique_artists = df_us_new_masters_clean['artist'].unique()\n",
    "\n",
    "df_artists_origins = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "artists = df_artists_origins['artist'].unique()\n",
    "artists_to_do = []\n",
    "\n",
    "for artist in unique_artists:\n",
    "    if artist not in df_artists_origins['artist'].values and artist not in artists_to_remove:\n",
    "        artists_to_do.append(artist)\n",
    "\n",
    "len(artists_to_do)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Withered', 'Twisted Method', 'Tides of Man', \"O'Brother\", 'Suuns']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# show the first next 5 artists I'm going to scrape\n",
    "artists_to_do[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bingo! df_coordinates.csv found \n",
      "\n",
      "1/1 - Withered: Atlanta, Georgia, United States[1][2][3]\n",
      "2/2 - Twisted_Method: Cape Coral, Florida, U.S.\n",
      "3/3 - Tides_of_Man: Tampa, Florida, U.S.\n",
      "4/4 - O'Brother: Atlanta, Georgia, U.S.\n",
      "5/5 - Suuns: Montreal, Quebec, Canada\n",
      "6/6 - Doomriders: Boston, Massachusetts, U.S.\n",
      "6/7 - Mortal Decay: error\n",
      "7/8 - Deas_Vail: Russellville, Arkansas\n",
      "8/9 - Halou: San Francisco, California\n",
      "9/10 - Norah_Jones (individual): New York City, U.S.\n",
      "10/11 - ASG_(band): Wilmington, North Carolina, U.S.\n",
      "11/12 - Warrel_Dane (individual): Seattle, Washington, U.S.\n",
      "12/13 - Jimmie's_Chicken_Shack: Annapolis, Maryland, U.S.\n",
      "12/14 - A Hill To Die Upon: error\n",
      "13/15 - Alchemist_(band): Canberra, Australia\n",
      "14/16 - Chromatics_(band): Portland, Oregon, U.S.\n",
      "14/17 - Battle Of Mice: error\n",
      "14/18 - Wake: error\n",
      "15/19 - Dew-Scented_(band): Braunschweig, Germany\n",
      "15/20 - Spirit Adrift: error\n",
      "16/21 - The_Scene_Aesthetic: Everett, Washington, U.S.\n",
      "17/22 - Lorna_Shore: New Jersey, U.S.\n",
      "17/23 - Gigan: error\n",
      "18/24 - Hanzel_Und_Gretyl: New York City, United States\n",
      "18/25 - Scars of Life: error\n",
      "19/26 - Scale_the_Summit: Houston, Texas, U.S.\n",
      "20/27 - Colour_Haze: Munich, Germany\n",
      "21/28 - Thulcandra_(band): Munich, Germany\n",
      "22/29 - Apoptygma_Berzerk: Sarpsborg, Norway\n",
      "23/30 - Sick_Puppies: Sydney, Australia\n",
      "24/31 - Cynthesis: Pleasanton, California, USA\n",
      "25/32 - Dear_and_the_Headlights: Phoenix, Arizona, U.S.\n",
      "26/33 - Paul_Dempsey (individual): Melbourne, Victoria, AustraliaGenresAlternative rockAustralian rockfolk\n",
      "27/34 - Page_France: Cumberland/Hagerstown, Maryland, United States\n",
      "28/35 - Parliament_(band): Plainfield, New Jersey, U.S.\n",
      "28/36 - Akhlys: error\n",
      "29/37 - Men_As_Trees: Auburn Hills, Michigan\n",
      "30/38 - The_Bicycle_Thief_(band): Los Angeles, California, U.S.\n",
      "31/39 - Lich_King_(band): Amherst, Massachusetts, U.S.\n",
      "32/40 - Soul_Embraced: Little Rock, Arkansas, U.S.\n",
      "32/41 - The Jim Yoshii Pile-Up: error\n",
      "32/42 - Anchor and Braille: error\n",
      "33/43 - Maggie_Rogers (individual): nan\n",
      "34/44 - Lake_of_Tears: Bors, Sweden\n",
      "34/45 - Megiddo: error\n",
      "35/46 - Immortal_Souls_(band): Kokkola, Finland\n",
      "36/47 - Pyramaze: Hjordkr, Denmark\n",
      "37/48 - Sanctity_(band): Asheville, North Carolina, U.S.\n",
      "38/49 - Crematory_(band): Westhofen, Germany\n",
      "39/50 - Christina_Perri (individual): Bensalem, Pennsylvania, U.S.\n",
      "40/51 - Secret_And_Whisper: Kelowna, British Columbia, Canada[1]\n",
      "41/52 - Ken_Andrews (individual): Seattle, Washington, U.S.Genres\n",
      "Alternative rock\n",
      "alternative metal\n",
      "post-grunge\n",
      "indie rock\n",
      "space rock\n",
      "electronic\n",
      "\n",
      "41/53 - Jacobi Wichita: error\n",
      "42/54 - Hockey_(band): Portland, Oregon, United States\n",
      "43/55 - Witch_Mountain_(band): Portland, Oregon, U.S.\n",
      "43/56 - Juanes: error\n",
      "44/57 - Lowercase_(band): Palm Desert, California\n",
      "44/58 - Falls of Rauros: error\n",
      "45/59 - Abysmal_Torment: Malta\n",
      "45/60 - William Hung: error\n",
      "46/61 - Kiss_Kiss_(band): Milton, New York, US\n",
      "47/62 - Zonaria: Ume, Sweden\n",
      "48/63 - Between_the_Trees: Orlando, Florida, United States\n",
      "49/64 - Om_(band): San Francisco, California, U.S.\n",
      "50/65 - From_Indian_Lakes: Indian Lakes Estates, California, U.S.\n",
      "51/66 - Capital_Lights: Tulsa, Oklahoma, U.S.[1]\n",
      "52/67 - Burning_Airlines: Washington, D.C., U.S.\n",
      "53/68 - Advent_(band): Kernersville, North Carolina, U.S.\n",
      "54/69 - Lacrimas_Profundere: Waging am See, Germany\n",
      "54/70 - The Demonstration: error\n",
      "55/71 - Brother_Dege (individual): Lafayette, Louisiana\n",
      "56/72 - Fallujah_(band): San Francisco, California, United States\n",
      "56/73 - Funeral Leech: error\n",
      "57/74 - If_These_Trees_Could_Talk: Akron, Ohio, US\n",
      "57/75 - Irepress: error\n",
      "57/76 - Jack Rose: error\n",
      "58/77 - Zoroaster_(band): Atlanta, Georgia, U.S.\n",
      "59/78 - Stereomud: New York City/Georgia, U.S.[1]\n",
      "59/79 - The Bird And The Bee: error\n",
      "60/80 - The_Atlas_Moth: Chicago, Illinois, United States\n",
      "61/81 - Fair_(band): Seattle, Washington, U.S.\n",
      "62/82 - Rascal_Flatts_(band): Nashville, Tennessee, U.S.\n",
      "62/83 - Those Who Lie Beneath: error\n",
      "63/84 - I_the_Mighty: San Francisco, California, U.S.\n",
      "64/85 - Grand_Belial's_Key: Oakton, Virginia\n",
      "65/86 - 5ive: London, England\n",
      "66/87 - Closure_in_Moscow: Melbourne, Victoria, Australia\n",
      "67/88 - Eyes_Set_to_Kill: Tempe, Arizona, U.S.\n",
      "68/89 - Star_Fucking_Hipsters: New York City\n",
      "69/90 - A_Rocket_to_the_Moon: Braintree, Massachusetts, United States\n",
      "69/91 - Votum: error\n",
      "69/92 - Atramentus: error\n",
      "70/93 - Wye_Oak_(band): Baltimore, Maryland\n",
      "71/94 - Marnie_Stern: New York City\n",
      "72/95 - Ashes_Divide_(band): New Jersey, United States\n",
      "73/96 - The_Six_Parts_Seven: Kent, Ohio, U.S.\n",
      "73/97 - Six Organs Of Admittance: error\n",
      "74/98 - Emigrate_(band): New York City, U.S.\n",
      "75/99 - Faunts: Edmonton, Alberta, Canada\n",
      "76/100 - Madina_Lake: Chicago, Illinois, United States\n"
     ]
    }
   ],
   "source": [
    "# create the df with the origins scraped from Wikipedia\n",
    "\n",
    "df = pd.read_csv('Datasets/df_us_new_masters_clean.csv')\n",
    "start_index = 0\n",
    "final_index = start_index+100\n",
    "\n",
    "df_artists_origins = get_origins_wikipedia(df, start_index, final_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25 nulls (25.0 %)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Withered</td>\n",
       "      <td>Atlanta, Georgia, United States[1][2][3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twisted Method</td>\n",
       "      <td>Cape Coral, Florida, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Tides of Man</td>\n",
       "      <td>Tampa, Florida, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>O'Brother</td>\n",
       "      <td>Atlanta, Georgia, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Suuns</td>\n",
       "      <td>Montreal, Quebec, Canada</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           artist                                    origin\n",
       "0        Withered  Atlanta, Georgia, United States[1][2][3]\n",
       "1  Twisted Method                 Cape Coral, Florida, U.S.\n",
       "2    Tides of Man                      Tampa, Florida, U.S.\n",
       "3       O'Brother                    Atlanta, Georgia, U.S.\n",
       "4           Suuns                  Montreal, Quebec, Canada"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a subset of the new artists I just got, and tell me if there are nulls\n",
    "df_new_artists = get_new_artists(df_artists_origins)\n",
    "\n",
    "# show the first new artists, if they were duplicates they have been dropped\n",
    "df_new_artists.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If there are null or weird values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a df with where origin is a null value\n",
    "nulls = df_new_artists[df_new_artists['origin'].isna()]\n",
    "nulls.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Irepress\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Jack Rose\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Bird And The Bee\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Those Who Lie Beneath\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Votum\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Atramentus\", \"England\", df_new_artists[\"origin\"])\n",
      "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Six Organs Of Admittance\", \"England\", df_new_artists[\"origin\"])\n"
     ]
    }
   ],
   "source": [
    "# so I can print the np.where and I save time\n",
    "for artist in nulls['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"England\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Looking in the internet for the real origins of these artists**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>Irepress</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>Jack Rose</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>The Bird And The Bee</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Those Who Lie Beneath</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>Votum</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Atramentus</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Six Organs Of Admittance</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      artist origin\n",
       "74                  Irepress    NaN\n",
       "75                 Jack Rose    NaN\n",
       "78      The Bird And The Bee    NaN\n",
       "82     Those Who Lie Beneath    NaN\n",
       "90                     Votum    NaN\n",
       "91                Atramentus    NaN\n",
       "96  Six Organs Of Admittance    NaN"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nulls.head(10) # so it's faster to copy the names of the artists to look for their origins on the internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Irepress\", \"Sharon, MA, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Jack Rose\", \"Fredericksburg, VA, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"The Bird And The Bee\", \"Los Angeles, CA, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Those Who Lie Beneath\", \"Portland, OR, United States\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Six Organs Of Admittance\", \"Arcata, CA, United States\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3176</th>\n",
       "      <td>274469</td>\n",
       "      <td>81580</td>\n",
       "      <td>601943</td>\n",
       "      <td>US</td>\n",
       "      <td>Six Organs Of Admittance</td>\n",
       "      <td>Dark Noontide</td>\n",
       "      <td>2002</td>\n",
       "      <td>41.88</td>\n",
       "      <td>8</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Folk Rock', 'Acoustic', 'Lo-Fi', 'Psychedeli...</td>\n",
       "      <td>Musical project of guitarist Ben Chasny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3642</th>\n",
       "      <td>274469</td>\n",
       "      <td>67602</td>\n",
       "      <td>399762</td>\n",
       "      <td>US</td>\n",
       "      <td>Six Organs Of Admittance</td>\n",
       "      <td>School of the Flower</td>\n",
       "      <td>2005</td>\n",
       "      <td>39.70</td>\n",
       "      <td>8</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>['Folk Rock', 'Acoustic', 'Psychedelic Rock']</td>\n",
       "      <td>Musical project of guitarist Ben Chasny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>274469</td>\n",
       "      <td>81589</td>\n",
       "      <td>713761</td>\n",
       "      <td>US</td>\n",
       "      <td>Six Organs Of Admittance</td>\n",
       "      <td>The Sun Awakens</td>\n",
       "      <td>2006</td>\n",
       "      <td>44.63</td>\n",
       "      <td>7</td>\n",
       "      <td>['LP', 'Album']</td>\n",
       "      <td>['Electronic', 'Rock']</td>\n",
       "      <td>['Folk Rock', 'Avantgarde', 'Experimental']</td>\n",
       "      <td>Musical project of guitarist Ben Chasny.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3083</th>\n",
       "      <td>274469</td>\n",
       "      <td>171537</td>\n",
       "      <td>1830979</td>\n",
       "      <td>US</td>\n",
       "      <td>Six Organs Of Admittance</td>\n",
       "      <td>Luminous Night</td>\n",
       "      <td>2009</td>\n",
       "      <td>42.30</td>\n",
       "      <td>8</td>\n",
       "      <td>['Album', 'Promo']</td>\n",
       "      <td>['Rock']</td>\n",
       "      <td>[]</td>\n",
       "      <td>Musical project of guitarist Ben Chasny.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      artist_id  master_id  main_release_id release_country  \\\n",
       "3176     274469      81580           601943              US   \n",
       "3642     274469      67602           399762              US   \n",
       "2593     274469      81589           713761              US   \n",
       "3083     274469     171537          1830979              US   \n",
       "\n",
       "                        artist                 title  year  album_length  \\\n",
       "3176  Six Organs Of Admittance         Dark Noontide  2002         41.88   \n",
       "3642  Six Organs Of Admittance  School of the Flower  2005         39.70   \n",
       "2593  Six Organs Of Admittance       The Sun Awakens  2006         44.63   \n",
       "3083  Six Organs Of Admittance        Luminous Night  2009         42.30   \n",
       "\n",
       "      tracks        release_type                  genres  \\\n",
       "3176       8           ['Album']                ['Rock']   \n",
       "3642       8           ['Album']                ['Rock']   \n",
       "2593       7     ['LP', 'Album']  ['Electronic', 'Rock']   \n",
       "3083       8  ['Album', 'Promo']                ['Rock']   \n",
       "\n",
       "                                                 styles  \\\n",
       "3176  ['Folk Rock', 'Acoustic', 'Lo-Fi', 'Psychedeli...   \n",
       "3642      ['Folk Rock', 'Acoustic', 'Psychedelic Rock']   \n",
       "2593        ['Folk Rock', 'Avantgarde', 'Experimental']   \n",
       "3083                                                 []   \n",
       "\n",
       "                                artist_profile  \n",
       "3176  Musical project of guitarist Ben Chasny.  \n",
       "3642  Musical project of guitarist Ben Chasny.  \n",
       "2593  Musical project of guitarist Ben Chasny.  \n",
       "3083  Musical project of guitarist Ben Chasny.  "
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Six Organs Of Admittance\t\".strip()].sort_values('year').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indie/Synthpop/Alternative musician duo from Los Angeles (USA), composed of vocalist [a=Inara George] \"The Bird\" and\n",
      "multi-instrumentalist [a=Greg Kurstin] \"The Bee\".\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[2528]['artist_profile']\n",
    "\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing the original dataframes in case needed (ex: two bands with the same name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[11090, 'artist'] = 'Embrace (US)'\n",
    "df.loc[6140, 'artist'] = 'Embrace (UK)'\n",
    "df.loc[6141, 'artist'] = 'Embrace (UK)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('Datasets/df_masters_blended.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album_id</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>rating</th>\n",
       "      <th>votes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4485</th>\n",
       "      <td>7197</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>The Good Will Out</td>\n",
       "      <td>3.56</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4486</th>\n",
       "      <td>7198</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>Out Of Nothing</td>\n",
       "      <td>3.39</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8649</th>\n",
       "      <td>14575</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>Embrace</td>\n",
       "      <td>3.99</td>\n",
       "      <td>309</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      album_id   artist              title  rating  votes\n",
       "4485      7197  Embrace  The Good Will Out    3.56     24\n",
       "4486      7198  Embrace     Out Of Nothing    3.39     27\n",
       "8649     14575  Embrace            Embrace    3.99    309"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df_ratings_20 to check it's the correct artist\n",
    "df_ratings_20[df_ratings_20['artist']==\"Embrace\".strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.loc[8649, 'artist'] = 'Embrace (US)'\n",
    "df_ratings_20.loc[4486, 'artist'] = 'Embrace (UK)'\n",
    "df_ratings_20.loc[4485, 'artist'] = 'Embrace (UK)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ratings_20.to_csv('Datasets/df_ratings_20.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists['origin'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Drop artists that are not from the UK or the US** (or supergroups that don't have a clear origin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "artists_to_remove = []\n",
    "\n",
    "for artist in artists_to_remove:\n",
    "    try:\n",
    "        artists_usa.remove(artist)\n",
    "        print(f'{artist} removed')\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows before dropping: 93\n",
      "Rows after dropping: 92\n"
     ]
    }
   ],
   "source": [
    "# I can drop single rows or I can just create a subset with the artists that I want to keep, the ones that are not in the list of artists to remove\n",
    "print(f\"Rows before dropping: {df_new_artists.shape[0]}\")\n",
    "df_new_artists = df_new_artists[~df_new_artists['artist'].isin(artists_to_remove)]\n",
    "print(f\"Rows after dropping: {df_new_artists.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Check short and long origins, probably wrong**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print abnormally short origins and visually check if they are correct\n",
    "for index, row in df_new_artists.iterrows():\n",
    "    if len(row['origin']) < 10:\n",
    "        print(index, row['origin'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Abysmal Torment</td>\n",
       "      <td>Malta</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Kiss Kiss</td>\n",
       "      <td>Milton, New York, US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Zonaria</td>\n",
       "      <td>Ume, Sweden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>Between the Trees</td>\n",
       "      <td>Orlando, Florida, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>Om</td>\n",
       "      <td>San Francisco, California, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               artist                           origin\n",
       "58    Abysmal Torment                            Malta\n",
       "60          Kiss Kiss             Milton, New York, US\n",
       "61            Zonaria                     Ume, Sweden\n",
       "62  Between the Trees  Orlando, Florida, United States\n",
       "63                 Om  San Francisco, California, U.S."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = 58\n",
    "\n",
    "end_index = start_index+5\n",
    "df_new_artists.loc[start_index:end_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist_id</th>\n",
       "      <th>master_id</th>\n",
       "      <th>main_release_id</th>\n",
       "      <th>release_country</th>\n",
       "      <th>artist</th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>album_length</th>\n",
       "      <th>tracks</th>\n",
       "      <th>release_type</th>\n",
       "      <th>genres</th>\n",
       "      <th>styles</th>\n",
       "      <th>artist_profile</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>1363881</td>\n",
       "      <td>0</td>\n",
       "      <td>1648728</td>\n",
       "      <td>US</td>\n",
       "      <td>Thanatopsis</td>\n",
       "      <td>Anatomize</td>\n",
       "      <td>2007</td>\n",
       "      <td>55.8</td>\n",
       "      <td>10</td>\n",
       "      <td>['Album']</td>\n",
       "      <td>['Jazz', 'Rock', 'Funk / Soul']</td>\n",
       "      <td>['Alternative Rock', 'Funk Metal', 'Prog Rock'...</td>\n",
       "      <td>Instrumental Jazz Fusion Project from the 2000...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     artist_id  master_id  main_release_id release_country       artist  \\\n",
       "999    1363881          0          1648728              US  Thanatopsis   \n",
       "\n",
       "         title  year  album_length  tracks release_type  \\\n",
       "999  Anatomize  2007          55.8      10    ['Album']   \n",
       "\n",
       "                              genres  \\\n",
       "999  ['Jazz', 'Rock', 'Funk / Soul']   \n",
       "\n",
       "                                                styles  \\\n",
       "999  ['Alternative Rock', 'Funk Metal', 'Prog Rock'...   \n",
       "\n",
       "                                        artist_profile  \n",
       "999  Instrumental Jazz Fusion Project from the 2000...  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look for the albums of the artist in the original df to check it's the correct artist\n",
    "df[df['artist']==\"Thanatopsis\".strip()].sort_values('year').head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Instrumental Jazz Fusion Project from the 2000s. The band's status is currently unknown.\n"
     ]
    }
   ],
   "source": [
    "# check if there's info of the artist origin in the column 'artist_profile'\n",
    "import textwrap\n",
    "artist_profile = df.loc[999]['artist_profile']\n",
    "\n",
    "splitted_string = textwrap.fill(artist_profile, width=120)\n",
    "print(splitted_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Genres**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 2)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "genres = df_new_artists[df_new_artists['origin'].str.contains('Genres')]\n",
    "genres.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in genres['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"UK\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Ken Andrews\", \"Seattle, Washington, U.S.\", df_new_artists[\"origin\"])\n",
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Page France\", \"Cumberland, MD, U.S.\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the df so I can copy the origin from the column (before 'Genres')\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Genres')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 3)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# I create a new column to calculate the lenght of the origin, if it's long it probably didn't scrap correctly Wikipedia\n",
    "df_new_artists[\"origin_length\"] = df_new_artists[\"origin\"].str.len()\n",
    "long_strings = df_new_artists[df_new_artists[\"origin_length\"]>40] # create a df based on these long origins\n",
    "long_strings.shape # to see how many artists I have to take care of"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "      <th>origin_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin, origin_length]\n",
       "Index: []"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "long_strings # display the df so I can copy the parts I am interested in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "for artist in long_strings['artist'].values:\n",
    "    print(f'df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"{artist}\", \"UK\", df_new_artists[\"origin\"])')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists[\"origin\"] = np.where(df_new_artists[\"artist\"]==\"Stereomud\", \"Atlanta, GA, United States\", df_new_artists[\"origin\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I drop the column I just created of 'origin_length'\n",
    "df_new_artists = df_new_artists[['artist', 'origin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from United Kingdom, wrong origin, poor level of detail\n",
    "df_new_artists[df_new_artists['origin']==('United Kingdom')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Changing easy values: individuals that didn't get the right origin in Wikipedia**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# individuals that didn't get the right origin in Wikipedia\n",
    "df_new_artists[df_new_artists['origin'].str.contains(' and ')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Cumbria, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Cumbria')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace('Cumbria', 'Cumberland'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Middlesex, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Middlesex')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', Middlesex', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Yorkshire, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('West Riding of Yorkshire')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', West Riding of Yorkshire', ''))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [artist, origin]\n",
       "Index: []"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# bands from Merseyside, Geopy doesn't detect it\n",
    "df_new_artists[df_new_artists['origin'].str.contains('Merseyside')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new_artists['origin'] = df_new_artists['origin'].apply(lambda x: x.replace(', Merseyside', ''))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **``np.where`` to replace the values for the real origins**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try a single origin in Geopy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kirkland, King County, Washington, United States\n",
      "47.6765382 -122.2070775\n"
     ]
    }
   ],
   "source": [
    "# try to get the right origin of an origin that crashed\n",
    "geolocator = Nominatim(user_agent=\"music_analysis\")\n",
    "\n",
    "origin = \"Kirkland, Washington\"\n",
    "\n",
    "origin_clean = re.sub(r'\\[\\d+\\]', '', origin).replace('.', '')\n",
    "location = geolocator.geocode(origin_clean)\n",
    "print(f\"{location.address}\")\n",
    "print(location.latitude, location.longitude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>origin</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>Zoroaster</td>\n",
       "      <td>Atlanta, Georgia, U.S.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Stereomud</td>\n",
       "      <td>New York City/Georgia, U.S.[1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>The Bird And The Bee</td>\n",
       "      <td>Los Angeles, CA, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>The Atlas Moth</td>\n",
       "      <td>Chicago, Illinois, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>Fair</td>\n",
       "      <td>Seattle, Washington, U.S.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  artist                            origin\n",
       "76             Zoroaster            Atlanta, Georgia, U.S.\n",
       "77             Stereomud    New York City/Georgia, U.S.[1]\n",
       "78  The Bird And The Bee    Los Angeles, CA, United States\n",
       "79        The Atlas Moth  Chicago, Illinois, United States\n",
       "80                  Fair         Seattle, Washington, U.S."
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start_index = 70\n",
    "\n",
    "end_index = start_index+5\n",
    "df_new_artists[start_index:end_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Try all origins in Geopy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70 - Atlanta, Fulton County, Georgia, United States\n",
      "71 - Atlanta, Fulton County, Georgia, United States\n",
      "72 - Los Angeles, Los Angeles County, California, United States\n",
      "73 - Chicago, Cook County, Illinois, United States\n",
      "74 - Seattle, King County, Washington, United States\n",
      "75 - Nashville, Davidson County, Middle Tennessee, Tennessee, United States\n",
      "76 - Portland, Multnomah County, Oregon, United States\n",
      "77 - San Francisco, California, United States\n",
      "78 - Oakton, Fairfax County, Virginia, United States\n",
      "79 - London, Greater London, England, United Kingdom\n",
      "80 - Melbourne, City of Melbourne, Victoria, Australia\n",
      "81 - Tempe, Maricopa County, Arizona, United States\n",
      "82 - City of New York, New York, United States\n",
      "83 - Braintree, Norfolk County, Massachusetts, 02184, United States\n",
      "84 - Baltimore, Maryland, United States\n",
      "85 - City of New York, New York, United States\n",
      "86 - New Jersey, United States\n",
      "87 - Kent, Portage County, Ohio, United States\n",
      "88 - Arcata, Humboldt County, California, 95521, United States\n",
      "89 - City of New York, New York, United States\n",
      "90 - Edmonton, Alberta, Canada\n",
      "91 - Chicago, Cook County, Illinois, United States\n"
     ]
    }
   ],
   "source": [
    "# try to get the coordinates of the origins from Geopy and see if it crashes (wrong location that I have to change)\n",
    "geolocator = Nominatim(user_agent=\"music_analysis\", timeout=10)\n",
    "\n",
    "initial_index = 70\n",
    "count = initial_index-1\n",
    "\n",
    "for origin in df_new_artists['origin'].str.replace('.', '').str.replace(r'\\[\\d+\\]', '', regex=True)[initial_index:]:\n",
    "    count+=1\n",
    "    location = geolocator.geocode(origin)\n",
    "    print(f\"{count} - {location.address}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Export to .csv**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GeoPy wrong locations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In case GeoPy fails due to a wrong location, I have to delete the new locations, export again, change the location and run GeoPy again**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#     # import the df with the artists' origins already scraped\n",
    "# df_artists_origins_scraped = pd.read_csv('Datasets/df_artists_origins.csv')\n",
    "# df_artists_origins_scraped = df_artists_origins_scraped[0:-20]\n",
    "# df_artists_origins_scraped.to_csv('Datasets/df_artists_origins.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(92, 2)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new_artists.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in case I created by mistake already 'origin_clean' and I want to drop it\n",
    "# df_new_artists = df_new_artists[['artist', 'origin']]\n",
    "# df_new_artists"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Export to .csv**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_artists_origins_concat exported to .csv\n",
      "(5850, 2)\n"
     ]
    }
   ],
   "source": [
    "export_artists_origins_concat(df_new_artists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **GeoPy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/83 - Atlanta, Fulton County, Georgia, United States\n",
      "2/83 - Cape Coral, Lee County, Florida, United States\n",
      "3/83 - Tampa, Hillsborough County, Florida, United States\n",
      "4/83 - Atlanta, Fulton County, Georgia, United States\n",
      "5/83 - Montral, Agglomration de Montral, Montral (rgion administrative), Qubec, Canada\n",
      "6/83 - Boston, Suffolk County, Massachusetts, United States\n",
      "7/83 - Audubon, Camden County, New Jersey, 08106, United States\n",
      "8/83 - Russellville, Pope County, Arkansas, United States\n",
      "9/83 - San Francisco, California, United States\n",
      "10/83 - City of New York, New York, United States\n",
      "11/83 - Wilmington, New Hanover County, North Carolina, United States\n",
      "12/83 - Seattle, King County, Washington, United States\n",
      "13/83 - Annapolis, Anne Arundel County, Maryland, United States\n",
      "14/83 - Monmouth, Warren County, Illinois, 61462, United States\n",
      "15/83 - Canberra, District of Canberra Central, Australian Capital Territory, 2601, Australia\n",
      "16/83 - Portland, Multnomah County, Oregon, United States\n",
      "17/83 - Brooklyn, Kings County, City of New York, New York, United States\n",
      "18/83 - Braunschweig, Niedersachsen, Deutschland\n",
      "19/83 - Mesa, Maricopa County, Arizona, United States\n",
      "20/83 - Everett, Snohomish County, Washington, United States\n",
      "21/83 - New Jersey, United States\n",
      "22/83 - Tampa, Hillsborough County, Florida, United States\n",
      "23/83 - City of New York, New York, United States\n",
      "24/83 - Pompano Beach, Broward County, Florida, United States\n",
      "25/83 - Houston, Harris County, Texas, United States\n",
      "26/83 - Mnchen, Bayern, Deutschland\n",
      "27/83 - Sarpsborg, stfold, Norge\n",
      "28/83 - Sydney, Council of the City of Sydney, New South Wales, Australia\n",
      "29/83 - Pleasanton, Alameda County, California, United States\n",
      "30/83 - Phoenix, Maricopa County, Arizona, United States\n"
     ]
    }
   ],
   "source": [
    "df_coordinates = get_coordinates_geopy(df_new_artists)\n",
    "df_coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df_coordinates_scraped: (2349, 7)\n",
      "\n",
      "Found 50 duplicates:\n",
      "               city          country\n",
      "24        Melbourne        Australia\n",
      "34           Sydney        Australia\n",
      "115        Victoria           Canada\n",
      "122        Winnipeg           Canada\n",
      "143      Dsseldorf      Deutschland\n",
      "207           Paris           France\n",
      "250     Netherlands        Nederland\n",
      "254             Oss        Nederland\n",
      "279          Bergen            Norge\n",
      "292            Oslo            Norge\n",
      "329        Helsinki  Suomi / Finland\n",
      "348         Tampere  Suomi / Finland\n",
      "365      Gothenburg          Sverige\n",
      "369     Helsingborg          Sverige\n",
      "393       Stockholm          Sverige\n",
      "766          London   United Kingdom\n",
      "1091         Athens    United States\n",
      "1176         Boston    United States\n",
      "1177         Boston    United States\n",
      "1220     California    United States\n",
      "1263        Chicago    United States\n",
      "1264        Chicago    United States\n",
      "1283      Cleveland    United States\n",
      "1337         Denton    United States\n",
      "1345          Derry    United States\n",
      "1378        El Paso    United States\n",
      "1410        Florida    United States\n",
      "1445        Gilbert    United States\n",
      "1530     Huntsville    United States\n",
      "1536   Indianapolis    United States\n",
      "1630    Little Rock    United States\n",
      "1668    Los Angeles    United States\n",
      "1669    Los Angeles    United States\n",
      "1670    Los Angeles    United States\n",
      "1730        Memphis    United States\n",
      "1738          Miami    United States\n",
      "1759    Minneapolis    United States\n",
      "1807      Nashville    United States\n",
      "1854  New York City    United States\n",
      "1914  Orange County    United States\n",
      "1915  Orange County    United States\n",
      "1998       Portland    United States\n",
      "1999       Portland    United States\n",
      "2016     Providence    United States\n",
      "2097     Sacramento    United States\n",
      "2115      San Diego    United States\n",
      "2128  San Francisco    United States\n",
      "2170        Seattle    United States\n",
      "2341        Wheaton    United States\n",
      "2402         Athens            \n",
      "\n",
      "Resulting dataset: (2378, 7)\n",
      "Merged artists with coordinates! Found 29 new locations\n",
      "df_coordinates_concat exported to .csv\n"
     ]
    }
   ],
   "source": [
    "export_coordinates_concat(df_coordinates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exported to a .csv file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>artist</th>\n",
       "      <th>country</th>\n",
       "      <th>city</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>address</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5720</th>\n",
       "      <td>Holy Grail</td>\n",
       "      <td>United States</td>\n",
       "      <td>Pasadena</td>\n",
       "      <td>34.147651</td>\n",
       "      <td>-118.144155</td>\n",
       "      <td>Pasadena, Los Angeles County, California, Unit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5721</th>\n",
       "      <td>Drawn and Quartered</td>\n",
       "      <td>United States</td>\n",
       "      <td>Seattle</td>\n",
       "      <td>47.603832</td>\n",
       "      <td>-122.330062</td>\n",
       "      <td>Seattle, King County, Washington, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5722</th>\n",
       "      <td>Electric President</td>\n",
       "      <td>United States</td>\n",
       "      <td>Jacksonville</td>\n",
       "      <td>30.332184</td>\n",
       "      <td>-81.655651</td>\n",
       "      <td>Jacksonville, Duval County, Florida, United St...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5723</th>\n",
       "      <td>Young Jesus</td>\n",
       "      <td>United States</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>41.875562</td>\n",
       "      <td>-87.624421</td>\n",
       "      <td>Chicago, Cook County, Illinois, United States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5724</th>\n",
       "      <td>Crossbreed</td>\n",
       "      <td>United States</td>\n",
       "      <td>Clearwater</td>\n",
       "      <td>27.965853</td>\n",
       "      <td>-82.800103</td>\n",
       "      <td>Clearwater, Pinellas County, Florida, United S...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   artist        country          city   latitude   longitude  \\\n",
       "5720           Holy Grail  United States      Pasadena  34.147651 -118.144155   \n",
       "5721  Drawn and Quartered  United States       Seattle  47.603832 -122.330062   \n",
       "5722   Electric President  United States  Jacksonville  30.332184  -81.655651   \n",
       "5723          Young Jesus  United States       Chicago  41.875562  -87.624421   \n",
       "5724           Crossbreed  United States    Clearwater  27.965853  -82.800103   \n",
       "\n",
       "                                                address  \n",
       "5720  Pasadena, Los Angeles County, California, Unit...  \n",
       "5721    Seattle, King County, Washington, United States  \n",
       "5722  Jacksonville, Duval County, Florida, United St...  \n",
       "5723      Chicago, Cook County, Illinois, United States  \n",
       "5724  Clearwater, Pinellas County, Florida, United S...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# merge with the dataframe containing all the artists and their origins\n",
    "df_artists_origins_coordinates_concat = merge_origins_coordinates(df_new_artists)\n",
    "df_artists_origins_coordinates_concat.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **Statistics**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5725, 6)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_artists_origins_coordinates_concat = pd.read_csv('Datasets/df_artists_origins_coordinates.csv')\n",
    "df_artists_origins_coordinates_concat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "brittish_cities = df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United Kingdom']\n",
    "american_cities = df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United States']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "country\n",
      "United States     3099\n",
      "United Kingdom    1479\n",
      "Canada             184\n",
      "Sverige            127\n",
      "Australia          116\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "order = df_artists_origins_coordinates_concat['country'].value_counts().index\n",
    "print(df_artists_origins_coordinates_concat['country'].value_counts().head())\n",
    "\n",
    "# plt.figure(figsize=(8,6))\n",
    "# sns.countplot(df_artists_origins_coordinates_concat['country'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1479 Brittish artists\n",
      "427 Brittish cities\n",
      "\n",
      "city\n",
      "London         400\n",
      "Glasgow         40\n",
      "Birmingham      39\n",
      "Manchester      39\n",
      "Brighton        38\n",
      "Leeds           36\n",
      "Liverpool       30\n",
      "Bristol         25\n",
      "Nottingham      21\n",
      "Sheffield       19\n",
      "Cardiff         16\n",
      "Edinburgh       16\n",
      "Cambridge       15\n",
      "Reading         13\n",
      "Southampton     13\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{brittish_cities.shape[0]} Brittish artists\")\n",
    "order = brittish_cities['city'].value_counts().index\n",
    "print(f\"{brittish_cities['city'].nunique()} Brittish cities\\n\")\n",
    "print(brittish_cities['city'].value_counts().head(15))\n",
    "\n",
    "# plt.figure(figsize=(9,45))\n",
    "# sns.countplot(brittish_cities['city'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3099 American artists\n",
      "772 American cities\n",
      "\n",
      "city\n",
      "Los Angeles      301\n",
      "New York City    170\n",
      "Chicago          111\n",
      "San Francisco     90\n",
      "Seattle           76\n",
      "Boston            69\n",
      "Brooklyn          64\n",
      "Philadelphia      52\n",
      "San Diego         48\n",
      "Portland          43\n",
      "Washington        36\n",
      "Austin            33\n",
      "New York          32\n",
      "Atlanta           32\n",
      "Phoenix           29\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f\"{american_cities.shape[0]} American artists\")\n",
    "order = american_cities['city'].value_counts().index\n",
    "print(f\"{american_cities['city'].nunique()} American cities\\n\")\n",
    "print(american_cities['city'].value_counts().head(15))\n",
    "\n",
    "# plt.figure(figsize=(5,55))\n",
    "# sns.countplot(df_artists_origins_coordinates_concat[df_artists_origins_coordinates_concat['country']=='United States']['city'], order=order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
